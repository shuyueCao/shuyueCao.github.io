<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Netty]]></title>
    <url>%2F2019%2F10%2F06%2FNetty%2F</url>
    <content type="text"><![CDATA[Netty架构Netty 是一个异步事件驱动的网络应用程序框架，用于快速开发可维护的高性能协议服务器和客户端。 特点JDK原生NIO程序的问题 NIO 的类库和 API 繁杂，使用麻烦：需要熟练掌握 Selector、ServerSocketChannel、SocketChannel、ByteBuffer 等。 需要具备其他的额外技能做铺垫：例如熟悉 Java 多线程编程，因为 NIO 编程涉及到 Reactor 模式，你必须对多线程和网路编程非常熟悉，才能编写出高质量的 NIO 程序。 可靠性能力补齐，开发工作量和难度都非常大：例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常码流的处理等等。 JDK NIO 的 Bug：臭名昭著的 Epoll Bug，它会导致 Selector 空轮询，最终导致 CPU 100%。 Netty的特点 设计优雅 适用于各种传输类型的统一 API 阻塞和非阻塞 Socket 基于灵活且可扩展的事件模型，可以清晰地分离关注点 高度可定制的线程模型 - 单线程，一个或多个线程池 真正的无连接数据报套接字支持（自 3.1 起）。 灵活的TCP参数配置能力 使用方便 高性能，吞吐量更高：延迟更低；减少资源消耗；最小化不必要的内存复制(零拷贝)。 零拷贝：不需要将数据 buffer 从用户空间拷贝到内存区域 ByteBuf使用直接(堆外)内存，不需要从堆内存拷贝到直接内存 CompositeByteBuf 类可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf, 避免了传统通过内存拷贝的方式将几个小Buffer合并成一个大的Buffer。 通过 FileRegion 包装的FileChannel.tranferTo方法 实现文件传输, 可以直接将文件缓冲区的数据发送到目标 Channel，避免了传统通过循环write方式导致的内存拷贝问题。 通过 wrap 操作, 我们可以将 byte[] 数组、ByteBuf、ByteBuffer等包装成一个 Netty ByteBuf 对象, 进而避免了拷贝操作 无锁化的串行设计理念 高性能的序列化框架 高效的并发编程：采用大量的CAS操作 安全，完整的 SSL/TLS 和 StartTLS 支持。 社区活跃，不断更新 I/O模型阻塞I/O（BIO） 每个请求都需要独立的线程完成数据 Read，业务处理，数据 Write 的完整操作问题。 当并发数较大时，需要创建大量线程来处理连接，系统资源占用较大。 连接建立后，如果当前线程暂时没有数据可读，则线程就阻塞在 Read 操作上，造成线程资源浪费。 I/O复用（NIO）在 I/O 复用模型中，会用到 Select，这个函数也会使进程阻塞，但是和阻塞 I/O 所不同的是这两个函数可以同时阻塞多个 I/O 操作。 而且可以同时对多个读操作，多个写操作的 I/O 函数进行检测，直到有数据可读或可写时，才真正调用 I/O 操作函数。 Netty 的 IO 线程 NioEventLoop 由于聚合了多路复用器 Selector，可以同时并发处理成百上千个客户端连接。 当线程从某客户端 Socket 通道进行读写数据时，若没有数据可用时，该线程可以进行其他任务 线程通常将非阻塞 IO 的空闲时间用于在其他通道上执行 IO 操作，所以单独的线程可以管理多个输入和输出通道。 由于读写操作都是非阻塞的，这就可以充分提升 IO 线程的运行效率，避免由于频繁 I/O 阻塞导致的线程挂起。 一个 I/O 线程可以并发处理 N 个客户端连接和读写操作，这从根本上解决了传统同步阻塞 I/O 一连接一线程模型，架构的性能、弹性伸缩能力和可靠性都得到了极大的提升。 基于buffer 传统的 I/O 是面向字节流或字符流的，以流式的方式顺序地从一个 Stream 中读取一个或多个字节, 因此也就不能随意改变读取指针的位置。 在 NIO 中，抛弃了传统的 I/O 流，而是引入了 Channel 和 Buffer 的概念。在 NIO 中，只能从 Channel 中读取数据到 Buffer 中或将数据从 Buffer 中写入到 Channel。 基于 Buffer 操作不像传统 IO 的顺序操作，NIO 中可以随意地读取任意位置的数据。 线程模型事件驱动模型通常，事件处理模型有两种： 轮询方式，线程不断轮询访问相关事件发生源有没有发生事件，有发生事件就调用事件处理逻辑。 事件驱动方式，发生事件，主线程把事件放入事件队列，在另外线程不断循环消费事件列表中的事件，调用事件对应的处理逻辑处理事件。事件驱动方式也被称为消息通知方式，其实是设计模式中观察者模式的思路。 相对轮询方式的好处 可扩展性好，分布式的异步架构，事件处理器之间高度解耦，可以方便扩展事件处理逻辑 高性能，基于队列暂存事件，能方便并行异步处理事件。 Reactor线程模型Reactor 模型是指通过一个或多个输入同时传递给服务处理器的服务请求的事件驱动处理模式。 服务端程序处理传入多路请求，并将它们同步分派给请求对应的处理线程，Reactor 模式也叫 Dispatcher 模式，即 I/O 多路复用统一监听事件，收到事件后分发(Dispatch 给某进程)，是编写高性能网络服务器的必备技术之一。 2个关键组成 Reactor，Reactor 在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对 IO 事件做出反应。它就像公司的电话接线员，它接听来自客户的电话并将线路转移到适当的联系人。 Handlers，处理程序执行 I/O 事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际官员。Reactor 通过调度适当的处理程序来响应 I/O 事件，处理程序执行非阻塞操作。 3个变种 单 Reactor 单线程 单 Reactor 多线程 主从 Reactor 多线程 可以这样理解，Reactor 就是一个执行 while (true) { selector.select(); …} 循环的线程 Netty线程模型Netty 主要基于主从 Reactors 多线程模型（如下图）做了一定的修改，其中主从 Reactor 多线程模型有多个 Reactor： MainReactor 负责客户端的连接请求，并将请求转交给 SubReactor。 SubReactor 负责相应通道的 IO 读写请求。(与worker threads在同一线程池中) 非 IO 请求（具体逻辑处理）的任务则会直接写入队列，等待 worker threads 进行处理。 异步处理 Netty 中的 I/O 操作是异步的，包括 Bind、Write、Connect 等操作会简单的返回一个 ChannelFuture。 调用者并不能立刻获得结果，而是通过 Future-Listener 机制，用户可以方便的主动获取或者通过通知机制获得 IO 操作结果。 当 Future 对象刚刚创建时，处于非完成状态，调用者可以通过返回的 ChannelFuture 来获取操作执行的状态，注册监听函数来执行完成后的操作。 常见操作 通过 isDone 方法来判断当前操作是否完成。 通过 isSuccess 方法来判断已完成的当前操作是否成功。 通过 getCause 方法来获取已完成的当前操作失败的原因。 通过 isCancelled 方法来判断已完成的当前操作是否被取消。 通过 addListener 方法来注册监听器，当操作已完成(isDone 方法返回完成)，将会通知指定的监听器；如果 Future 对象已完成，则立即通知指定的监听器。 1234567serverBootstrap.bind(port).addListener(future -&gt; &#123; if (future.isSuccess()) &#123; System.out.println(new Date() + ": 端口[" + port + "]绑定成功!"); &#125; else &#123; System.err.println("端口[" + port + "]绑定失败!"); &#125; &#125;); 相比传统阻塞 I/O，执行 I/O 操作后线程会被阻塞住, 直到操作完成；异步处理的好处是不会造成线程阻塞，线程在 I/O 操作期间可以执行别的程序，在高并发情形下会更稳定和更高的吞吐量。 功能特性 传输服务，支持 BIO 和 NIO。 容器集成，支持 OSGI、JBossMC、Spring、Guice 容器。 协议支持，HTTP、Protobuf、二进制、文本、WebSocket 等一系列常见协议都支持。还支持通过实行编码解码逻辑来实现自定义协议。 Protobuf：结构化的数据序列化、反序列化，常用于RPC 系统（Remote Procedure Call Protocol System）和持续数据存储系统。 序列化后体积相比 Json 和 XML 很小，适合网络传输 支持跨平台多语言 消息格式升级和兼容性不错，“向后” 兼容性好 序列化反序列化速度很快，快于 Json 的处理速速 Protobuf 语义更清晰，无需类似 XML 解析器的东西 Core 核心，可扩展事件模型、通用通信 API、支持零拷贝的 ByteBuf 缓冲对象。 模块组件 bootstrap，serverBootstrap：一个 Netty 应用通常由一个 Bootstrap 开始，主要作用是配置整个 Netty 程序，串联各个组件，Netty 中 Bootstrap 类是客户端程序的启动引导类，ServerBootstrap 是服务端启动引导类。 future，channelFuture：他们可以注册一个监听，当操作执行成功或失败时监听会自动触发注册的监听事件。 channel：Netty 网络通信的组件，能够用于执行网络 I/O 操作 NioSocketChannel，异步的客户端 TCP Socket 连接。 NioServerSocketChannel，异步的服务器端 TCP Socket 连接。 NioDatagramChannel，异步的 UDP 连接。 NioSctpChannel，异步的客户端 Sctp 连接。 NioSctpServerChannel，异步的 Sctp 服务器端连接，这些通道涵盖了 UDP 和 TCP 网络 IO 以及文件 IO。 selector：Netty 基于 Selector 对象实现 I/O 多路复用，通过 Selector 一个线程可以监听多个连接的 Channel 事件。 当向一个 Selector 中注册 Channel 后，Selector 内部的机制就可以自动不断地查询(Select) 这些注册的 Channel 是否有已就绪的 I/O 事件（例如可读，可写，网络连接完成等），这样程序就可以很简单地使用一个线程高效地管理多个 Channel 。 NioEventLoop：维护了一个线程和任务队列，支持异步提交执行任务，线程启动时会调用 NioEventLoop 的 run 方法，执行 I/O 任务和非 I/O 任务： I/O 任务，即 selectionKey 中 ready 的事件，如 accept、connect、read、write 等，由 processSelectedKeys 方法触发。 非 IO 任务，添加到 taskQueue 中的任务，如 register0、bind0 等任务，由 runAllTasks 方法触发。 NioEventLoopGroup：要管理 eventLoop 的生命周期，可以理解为一个线程池，内部维护了一组线程，每个线程(NioEventLoop)负责处理多个 Channel 上的事件，而一个 Channel 只对应于一个线程。 ChannelHandler：是一个接口，处理 I/O 事件或拦截 I/O 操作，并将其转发到其 ChannelPipeline(业务处理链)中的下一个处理程序。 ChannelInboundHandler 用于处理入站 I/O 事件。 ChannelOutboundHandler 用于处理出站 I/O 操作。 ChannelInboundHandlerAdapter 用于处理入站 I/O 事件。 ChannelOutboundHandlerAdapter 用于处理出站 I/O 操作。 ChannelDuplexHandler 用于处理入站和出站事件。 ChannelHandlerContext：保存 Channel 相关的所有上下文信息，同时关联一个 ChannelHandler 对象。 ChannelPipeline：保存 ChannelHandler 的 List，用于处理或拦截 Channel 的入站事件和出站操作。 ChannelPipeline 实现了一种高级形式的拦截过滤器模式，使用户可以完全控制事件的处理方式，以及 Channel 中各个的 ChannelHandler 如何相互交互。 每个channel有且仅有一个channelPipeline与之对应 Netty工作架构图 Handler的执行顺序一个ChannelPipeline可以把两种Handler（ChannelInboundHandler和ChannelOutboundHandler）混合在一起，当一个数据流进入ChannelPipeline时，它会从ChannelPipeline头部开始传给第一个ChannelInboundHandler，当第一个处理完后再传给下一个，一直传递到管道的尾部。 与之相对应的是，当数据被写出时，它会从管道的尾部开始，先经过管道尾部的“最后”一个ChannelOutboundHandler，当它处理完成后会传递给前一个ChannelOutboundHandler。 对于inbound event，Netty会自动跳过OutboundHandler,相反若是outbound event，ChannelInboundHandler会被忽略掉。 两种方式发送数据： 把数据直接写入Channel，那么数据流会从Channel的头开始传递 把数据写入ChannelHandlerContext，数据流会流入管道中的下一个Handler SimpleChannelInboundHandler channelRead0()方法，此方法接收到的可能是一些数据片段，比如服务器发送了5个字节数据，Client端不能保证一次全部收到，比如第一次收到3个字节，第二次收到2个字节。 为什么客户端使用SimpleChannelInboundHandler而服务端使用ChannelInboundHandlerAdapter？ SimpleChannelInboundHandler在接收到数据后会自动release掉数据占用的Bytebuffer资源(自动调用Bytebuffer.release()) 何服务器端不能用是因为我们想让服务器把客户端请求的数据发送回去，而服务器端有可能在channelRead方法返回前还没有写完数据，因此不能让它自动release。 WriteAndFlush 标准的pipeline链式结构 数据从head节点流入，先拆包，然后解码成业务对象，最后经过业务Handler处理，调用write，将结果对象写出去。 写的过程先通过tail节点，然后通过encoder节点将对象编码成ByteBuf，最后将该ByteBuf对象传递到head节点，调用底层的Unsafe写到jdk底层管道 Encoder 判断当前Handler是否能处理写入的消息，如果能处理，进入下面的流程，否则，直接扔给下一个节点处理 将对象强制转换成Encoder可以处理的 Response对象 分配一个ByteBuf 调用encoder，即进入到 Encoder 的 encode方法，该方法是用户代码，用户将数据写入ByteBuf 既然自定义java对象转换成ByteBuf了，那么这个对象就已经无用了，释放掉，(当传入的msg类型是ByteBuf的时候，就不需要自己手动释放了) 如果buf中写入了数据，就把buf传到下一个节点，否则，释放buf，将空数据传到下一个节点 最后，当buf在pipeline中处理完之后，释放节点 总结：Encoder节点分配一个ByteBuf，调用encode方法，将java对象根据自定义协议写入到ByteBuf，然后再把ByteBuf传入到下一个节点(可能到head节点) write写队列 调用 assertEventLoop 确保该方法的调用是在reactor线程中 调用 filterOutboundMessage() 方法，将待写入的对象过滤，把非ByteBuf对象和FileRegion过滤，把所有的非直接内存转换成直接内存DirectBuffer 估算出需要写入的ByteBuf的size 调用 ChannelOutboundBuffer 的addMessage(msg, size, promise) 方法 ChannelOutboundBuffer 里面的数据结构是一个单链表结构，每个节点是一个 Entry，Entry 里面包含了待写出ByteBuf 以及消息回调 promise 三个指针 flushedEntry 指针表示第一个被写到操作系统Socket缓冲区中的节点 unFlushedEntry 指针表示第一个未被写入到操作系统Socket缓冲区中的节点 tailEntry指针表示ChannelOutboundBuffer缓冲区的最后一个节点 在调用N次addMessage之后，flushedEntry指针一直指向NULL，而unFushedEntry之后有n个节点，说明write并没有写出到socket缓冲区 flush刷新写队列不管调用channel.flush()，还是ctx.flush()，最终都会落地到pipeline中的head节点 调用current()先拿到第一个需要flush的节点的数据 拿到自旋锁的迭代次数 自旋的方式将ByteBuf写出到JDK NIO的Channel 节点的数据已经写入完毕，接下来就需要删除该节点（逻辑上的删除，只是将flushedEntry指针移到下个节点） 最后调用 recycle方法，将当前节点回收 WriteAndFlush总结 pipeline中的编码器原理是创建一个ByteBuf,将java对象转换为ByteBuf，然后再把ByteBuf继续向前传递 调用write方法并没有将数据写到Socket缓冲区中，而是写到了一个单向链表的数据结构中，flush才是真正的写出 writeAndFlush等价于先将数据写到netty的缓冲区，再将netty缓冲区中的数据写到Socket缓冲区中，写的过程与并发编程类似，用自旋锁保证写成功 netty中的缓冲区中的ByteBuf为DirectByteBuf Netty UDP丢包问题思考（Linux下）https://www.jianshu.com/p/22b0f89937ef]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes容器编排系统]]></title>
    <url>%2F2019%2F10%2F05%2Fkubernetes%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[kubernetes容器编排系统docker容器优势 持续部署与测试：容器消除了线上线下的环境差异，保证了应用生命周期的环境一致性标准化 开发人员使用镜像实现标准开发环境的构建，开发完成后通过封装着完整环境和应用的镜像进行迁移，由此，测试和运维人员可以直接部署软件镜像来进行测试和发布，大大简化了持续集成、测试和发布的过程。 跨云平台支持：适配性高，用户无需再担心受到云平台的捆绑，同时也让应用多平台混合部署成为可能 环境标准化和版本控制：可以使用Gt等工具对容器镜像进行版本控制，相比基于代码的版本控制来说，你还能够对整个应用运行环境实现版本控制，一旦出现故障可以快速回滚。 相比以前的虚拟机镜像，容器压缩和备份速度更快，镜像启动也像启动一个普通进程一样快速。 高资源利用率与隔离：容器容器没有管理程序的额外开销，与底层共享操作系统，性能更加优良，系统负载更低，在同等条件下可以运行更多的应用实例，可以更充分地利用系统资源 同时，容器拥有不错的资源隔离与限制能力，可以精确地对应用分配CPU、内存等资源，保证了应用间不会相互影响。 容器跨平台性与镜像：设定了一整套标准化的配置方法，将应用及其依赖的运行环境打包成镜像，真正实现了“构建次，到处运行”的理念，大大提高了容器的跨平台性。 易于理解且易用 应用镜像仓库：Docker官方构建了一个镜像仓库，为用户提供了一个非常有用的应用商店 kubernetesKubernetes作为容器编排生态圈中重要一员，是Google大规模容器管理系统borg的开源版本实现。 Kubernetes提供应用部署、维护、 扩展机制等功能，利用Kubernetes能方便地管理跨机器运行容器化的应用。当前Kubernetes支持GCE、vShpere、CoreOS、OpenShift、Azure等平台，除此之外，也可以直接运行在物理机上。kubernetes是一个开放的容器调度管理平台，不限定任何一种言语，支持java/C++/go/python等各类应用程序 。 kubernetes是一个完备的分布式系统支持平台，支持多层安全防护、准入机制、多租户应用支撑、透明的服务注册、服务发现、内建负载均衡、强大的故障发现和自我修复机制、服务滚动升级和在线扩容、可扩展的资源自动调度机制、多粒度的资源配额管理能力,完善的管理工具，包括开发、测试、部署、运维监控，一站式的完备的分布式系统开发和支撑平台。 系统架构 masterMaster作为控制节点，调度管理整个系统，包括以下组件： API Server：作为kubernetes系统的入口，封装了核心对象的增删改查操作，以RESTful接口方式提供给外部客户和内部组件调用。它维护的REST对象将持久化到etcd（用于保存集群所有的网络配置和对象的状态信息）。 scheduler：负责集群的资源调度，为新建的pod分配机器（node）。 将待调度的pod（API新创建的Pod、Controller Manager为补足副本而创建的pod等）按照特定的调度算法和调度策略绑定（binding）到集群中的某个合适的node上，并将绑定信息写入etcd中 默认调度流程 预选调度过程，即遍历所有目标node，筛选出符合要求的候选节点。为此kubernetes内置了多种预先策略（xxx predicates）供用户选择。 确定最优节点，在第一步的基础上，采用优先策略（xxx priority）计算出每个候选节点的积分，积分最高的胜出。 随后，目标node上的kublet通过API Server监听到scheduler产生的pod绑定事件，然后获对应的取pod，下载image镜像，并启动容器。 controller manager：负责执行各种控制器，目前有两类 Endpoint Controller：定期关联service和pod(关联信息由endpoint对象维护)，保证service到pod的映射总是最新的。 Replication Controller：定期关联replicationController和pod，保证replicationController定义的副本数量与实际运行pod的数量总是一致的。 nodeNode是运行节点，运行业务容器，包含以下组件： kubelet：负责管控docker，如启动/停止、监控运行状态等 定期从etcd获取分配到本机的pod，并根据pod信息启动或停止相应的容器。 同时，它也会接收apiserver的HTTP请求，汇报pod的运行状态。 kube proxy：负责为pod提供代理 它会定期从etcd获取所有的service，并根据service信息创建代理。当某个客户pod要访问其他pod时，访问请求会经过本机proxy做转发。 基本概念podpod 是 kubernetes 的最基本操作单元。包括一个或多个紧密相关的容器，一个 pod 可以被一个容器化的环境看作应用层的逻辑宿主机（ Logical host ）。一个 pod 中的多个容器应用通常是紧耦合的。Pod 在 node 上被创建、启动或者销毁。 为什么 kubernetes 使用 pod 在容器之上再封装一层？ 一个很重要的原因是,docker 容器之间通信受到 docker 网络机制的限制。在 docker 的，世界中，一个容器需要通过 link 方式才能访问另一个容器提供的服务（端口）。大量容器之间的 link 将是一个非常繁重的工作 通过 pod 的概念将多个容器组合在一个虚拟的“主机”内，可以实现容器之间仅需通过 localhost 就能相互通信了。 一个pod中的应用容器共享一组资源 pid命名空间：pod中的不同应用程序可以看到其他的进程PID 网络命名空间：pod中的多个容器能够访问同一个IP和端口范围 IPC命名空间：pod中的多个容器能够使用systemV ipc 或POSIX消息队列进行通信。 UTS命名空间：pod中的多个容器共享一个主机名。 Volumes(共享存储卷)：pod中的各个容器可以访问在pod级别定义的volumes。 labellabel是kubernetes系统中的一个核心概念。Label以key/value键值对的形式附加到各种对象上，如pod、service、RC、Node等。Label定义了这些对象的可识别属性，用来对它们进行管理和选择。 Resource controller(RC) 用于定义pod副本数量。在master的Controller manager进程通过RC的定义来完成pod的创建、监控、启停等操作。 根据replication controller的定义，kubernetes能够确保在任意时刻都能运行用户指定的pod“副本”（replica）数量。 replication controller 重新调度 弹性伸缩：实现扩大或缩小副本的数量 滚动更新：通过逐个替换pod的方式来辅助服务的滚动更新。推荐的方式是创建一个新的只有一个副本的RC，若新的RC副本数量加1，则旧的RC的副本数量减1，直到这个旧的RC副本数量为零，然后删除该旧的RC。 service在kubernetes的世界里，虽然每个pod都会被分配一个单独的IP地址，但这个IP地址会随着pod的销毁而消失。这就引出一个问题：如果有一组pod组成一个集群来提供服务，那么如何来访问它们呢？ kubernetes的service就是用来解决这个问题的核心概念。一个service可以看作一组提供相同服务的pod的对外访问接口。Service作用于哪些pod是通过label selector 来定义的。 pod的IP地址是docker daemon根据docker0网桥的IP地址段进行分配的，但service的Cluster IP地址是kubernetes系统中的虚拟IP地址，由系统动态分配。 service的ClusterIP地址相对于pod的IP地址来说相对稳定，service被创建时即被分配IP地址，在销毁该service之前，这个IP地址都不会再变化。 由于service对象在Cluster IP Range池中分配到的IP只能在内部访问，所以其他pod都可以无障碍地访问到它。但如果这个service作为前端服务，准备为集群外的客户端提供服务，我们就需要给这个服务提供公共IP了。 Volume(存储卷) volume是pod中能够被多个容器访问的共享目录 与pod生命周期相同，但与容器的生命周期不相关。当容器终止或重启时，volume中的数据也不会丢失 kubernetes支持多种类型的volume，并且一个pod可以同时使用任意多个volume Namespace（命名空间） 通过将系统内部的对象“分配”到不同的namespace中，形成逻辑上分组的不同项目、小组或用户组，便于不同的分组在共享使用整个集群的资源的同时还能分别管理。 如果不特别指明namespace，则用户创建的pod、RC、Service都将被系统创建到名为“default”的namespace中。 节点管理节点管理包含节点的注册、状态上报、Pod管理、容器健康检查、资源监控等部分。]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka]]></title>
    <url>%2F2019%2F10%2F03%2FKafka%2F</url>
    <content type="text"><![CDATA[Kafka架构和原理简介Kafka是一种高性能跨语言的，分布式的，基于发布/订阅的消息系统。主要设计目标如下： 以时间复杂度为O(1)的方式提供消息持久化能力，并保证即使对TB级以上数据也能保证常数时间的访问性能 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输 支持Kafka Server间的消息分区，及分布式消息消费，同时保证每个partition内的消息顺序传输 同时支持离线数据处理和实时数据处理 特性 高吞吐量、低延迟 可扩展：kafka集群支持热扩展 持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失 容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败） 高并发 使用场景 日志收集 消息系统：解耦生产者和消费者、缓存消息等 用户活动跟踪：将用户行为收集，并通过订阅者进行实时监控 运营指标：记录运营监控数据 流式处理：spark streaming 相关术语 Broker：Kafka集群包含一个或多个服务器，这种服务器被称为broker Topic：每条发布到Kafka集群的消息都有一个类别，这个类别被称为topic。 物理上不同topic的消息分开存储 逻辑上一个topic的消息虽然保存于一个或多个broker上，但用户只需指定消息的topic即可生产或消费数据而不必关心数据存于何处 Partition：parition是物理上的概念，每个topic包含一个或多个partition 创建topic时可指定parition数量。 每个partition对应于一个文件夹，该文件夹下存储该partition的数据和索引文件 Producer：负责发布消息到Kafka broker Consumer：消费消息。 每个consumer属于一个特定的consuer group（可为每个consumer指定group name，若不指定group name则属于默认的group） 使用consumer high level API时，同一topic的一条消息只能被同一个consumer group内的一个consumer消费，但多个consumer group可同时消费这一消息。 架构 如上图所示，一个典型的kafka集群中包含若干producer（可以是web前端产生的page view，或者是服务器日志，系统CPU、memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高）， 若干consumer group，以及一个Zookeeper集群。 Kafka通过Zookeeper管理集群配置，选举leader，以及在consumer group发生变化时进行rebalance。 Consumer Group consumer group下可以有一个或多个consumer instance，consumer instance可以是一个进程，也可以是一个线程 允许consumer group对一个topic进行消费，不同的consumer group之间独立消费。 partition为最小的并行消费单位，即一个group内的consumer只能消费不同的partition push/pull producer使用push模式将消息发布到broker consumer使用pull模式从 broker订阅并消费消息。 好处： 消息消费的速率由 Consumer自己决定 push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞 Consumer可以自己控制消费方式——既可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。 Topic/Partition kafka为什么要在topic里加入分区的概念？ topic是逻辑概念，partition是物理概念，consumer并不关心消息处在集群哪个broker，而只关心在哪个topic 如果topic内的消息只存放在一个broker，那么这个broker会成为瓶颈，无法做到水平扩展 物理上把Topic分成一个或多个Partition，每个partition可以被认为是一个无限长度的数组，新数据会顺序追加（顺序写磁盘因此效率很高）进这个数组（通过offset定位）。每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。 问题：Topic有多个Partition，那么消息分配到某个Partition的依据是什么？ key hash 或者round Robin 一个broker可以存放多个partition 分区多副本（副本机制） 通过副本机制实现故障自动转移，当Kafka集群中一个Broker失效情况下仍然保证服务可用 N个replicas中。其中一个replica为leader，其他都为follower，leader处理partition的所有读写请求，与此同时，follower会被动定期地去复制leader上的数据。 问题：kafka 如何确认一个 Follower 是活的？ 和 zookeeper 保持联系。 Follower 复制 Leader 上的消息，且落后的不多（可配置）。 消息同步到所有的 Follower 才认为是提交成功，提交成功才能被消费。所以 Leader 宕机不会造成消息丢失 如果leader发生故障或挂掉，一个新leader被选举并接收客户端的消息成功写入。 Kafak动态维护一个同步备份集合（ISR）。这个集合中的 Follower 都能成为 Leader。 一个写入要同步到所有的 ISR 中才能算做 Commit 成功 同时 ISR 会被持久化到 ZK 中。 消息可靠性 在实际消息传递过程中，可能会出现如下情况： 一个消息发送失败 一个消息被发送多次 kafka如何保证消息可靠性？ 从Producer端看：当一个消息被发送后，Producer会等待broker成功接收到消息的反馈（可通过参数控制等待时间），如果消息在途中丢失或是其中一个broker挂掉，Producer会重新发送（我们知道Kafka有备份机制，可以通过参数控制是否等待所有备份节点都收到消息）。 从Consumer端看：broker端记录了partition中的一个offset值，这个值指向Consumer下一个即将消费的message。当Consumer收到了消息，但却在处理过程中挂掉，此时Consumer可以通过这个offset值重新找到上一个消息再进行处理。 Consumer还有权限控制这个offset值，对持久化到broker端的消息做任意处理。 Zookeeper在kafka集群中的作用 数据发布与订阅中心：即所谓的配置中心，实现配置的集中式管理和动态更新。例如，全局的配置信息，服务服务框架的地址列表 负载均衡 命名服务 分布式通知/协调：这个利用的是zookeeper的watcher注册和异步通知机制，能够很好的实现分布式环境中不同系统间的通知与协调，实现对数据变更的实时处理。 集群管理与master选举 分布式锁：这个主要得益于zookeeper数据的强一致性，利用的是临时节点。 @KafkaListener注解spring-kafka 使用基于@KafkaListener注解，@KafkaListener使用方式如下： 1234@KafkaListener(topics = "xxx")public void process(List&lt;ConsumerRecord&lt;xxx, xxx&gt;&gt; records) &#123; ...&#125; 在注解内指定topic名称，当对应的topic内有新的消息时，process方法会被调用，参数就是topic内新的消息。这个过程是异步进行的。 工作流程 解析@KafkaListener注解 @KafkaListener注解由KafkaListenerAnnotationBeanPostProcessor类解析，后者实现了BeanPostProcessor接口 接口内部有2个方法，分别在bean初始化前后被调用。 KafkaListenerAnnotationBeanPostProcessor postProcessAfterInitialization 注册 解析步骤里，我们可以获取到所有含有@KafkaListener注解的类，之后这些类的相关信息会被注册到 KafkaListenerEndpointRegistry内，包括注解所在的方法，当前的bean等 KafkaListenerEndpointRegistry这个类内部会维护多个Listener Container，每一个@KafkaListener都会对应一个Listener Container。并且每个Container对应一个线程。 监听：注册完成之后，每个Listener Container会开始工作，会新启一个新的线程，初始化KafkaConsumer，监听topic变更等 调用：监听到数据之后，container会组织消息的格式，随后调用解析得到的@KafkaListener注解标识的方法，将组织后的消息作为参数传入方法，执行用户逻辑。]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[海量数据处理]]></title>
    <url>%2F2019%2F09%2F24%2F%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[海量数据处理算法/数据结构基础 Bloom Filter：利用位数组来表示一个集合并判断一个元素是否属于这个集合。 bloom filter若判断元素不在集合，那一定不存在。若判断元素存在集合中，有一定概率判断错误 适用范围：数据字典、数据判重、集合求交 hash 适用范围：快速查找，删除的基本数据结构，通常需要总数据量可以放入内存 Bit-map:用一个bit位来标记某个元素对应的值。 适用范围：可进行数据的快速查找，判重，删除，一般来说数据范围是int的10倍以下 问题实例： 已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。 2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。 扩展为2-bitmap 堆 适用范围：海量数据前n大，并且n比较小，堆可以放入内存 最大堆求前n小，最小堆求前n大，比如求前n小，我们比较当前元素与最大堆里的最大元素，如果它小于最大元素，则应该替换那个最大元素。这样最后得到的n个元素就是最小的n个。 扩展：双堆，一个最大堆与一个最小堆结合，可以用来维护中位数。 问题实例： 100w个数中找最大的前100个数。 用一个100个元素大小的最小堆即可。 trie树 适用范围：数据量大，重复多，但是数据种类小可以放入内存 前缀统计、词频统计 问题实例： 有10个文件，每个文件1G，每个文件的每一行都存放的是用户的query，每个文件的query都可能重复。要你按照query的频度排序。 1000万字符串，其中有些是相同的(重复),需要把重复的全部去掉，保留没有重复的字符串。请问怎么设计和实现？ 寻找热门查询：查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个，每个不超过255字节。 外排序 适用范围：大数据的排序、去重 原理： 按内存大小，将外存上含n个记录的文件分成若干个长度L的子文件或段。依次读入内存并利用有效的内部排序对它们进行排序，并将排序后得到的有序字文件重新写入外存，通常称这些子文件为归并段。 对这些归并段进行逐趟归并，使归并段有小到大，直至得到整个有序稳健为止。 优化方法：置换选择、败者树原理、最优归并树 数据库索引 适用范围：大数据量的增删改查 倒排索引 适用范围：搜索引擎，关键字查询 123456789101112以英文为例，下面是要被索引的文本： T0 = &quot;it is what it is&quot; T1 = &quot;what is it&quot; T2 = &quot;it is a banana&quot;我们就能得到下面的反向文件索引：&quot;a&quot;: &#123;2&#125;&quot;banana&quot;: &#123;2&#125;&quot;is&quot;: &#123;0, 1, 2&#125;&quot;it&quot;: &#123;0, 1, 2&#125;&quot;what&quot;: &#123;0, 1&#125;检索的条件&quot;what&quot;,&quot;is&quot;和&quot;it&quot;将对应集合的交集。 面试问题解决 海量日志数据，提取某日访问百度次数最多的IP。 分而治之+hash IP地址最多有2^32=4G种取值情况 可以考虑采用分而治之的思想，按照IP地址的Hash(IP)%1024值，把海量IP日志分别存储到1024个小文件中。这样，每个小文件最多包含4MB个IP地址 对于每一个小文件，可以构建一个IP为key，出现次数为value的Hash map，同时记录当前出现次数最多的那个IP地址 可以得到1024个小文件中的出现次数最多的IP，再依据常规的排序算法得到总体上出现次数最多的IP； 搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。假设目前有一千万个记录，去重后不超过三百万个，统计最热门的10个查询串 典型的topK算法，hashmap+堆 先对这批海量数据预处理，在O（N）的时间内用Hash表完成统计 借助堆这个数据结构，找出Top K，时间复杂度为O(N*logK) 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。 分而治之+hash统计+堆排序 顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件（记为x0,x1,…x4999）中。这样每个文件大概是200k左右。 对每个小文件，采用trie树/hashMap统计每个文件中出现的词以及相应的频率。 取出出现频率最大的100个词（可以用含100个结点的最小堆），并把100个词及相应的频率存入文件，这样又得到了5000个文件。下一步就是把这5000个文件进行归并（类似于归并排序）的过程了。 有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。 方案1：分而治之+hash统计+堆排序 顺序读取10个文件，按照hash(query)%10的结果将query写入到另外10个文件中。这样新生成的文件每个的大小大约也1G（假设hash函数是随机的）。 找一台内存2G左右的机器，依次对用hash_map(query, query_count)来统计每个query出现的次数。利用快速/堆/归并排序按照出现次数进行排序。将排序好的query和对应的query_cout输出到文件中。这样得到了10个排好序的文件。 对这10个文件进行归并排序（内排序与外排序相结合）。 方案2：hashmap+堆 一般query的总量是有限的，只是重复的次数比较多而已，可能对于所有的query，一次性就可以加入到内存了。这样，我们就可以采用trie树/hash_map等直接来统计每个query出现的次数，然后按出现次数做快速/堆/归并排序就可以了。 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？ 方案1：分而治之+hash统计 可以估计每个文件的大小为5G×64=320G，远远大于内存限制的4G。所以不可能将其完全加载到内存中处理。考虑采取分而治之的方法 遍历文件a，对每个url求取hash(url)%1000，然后根据所取得的值将url分别存储到1000个小文件（记为a0,a1,…,a999）中。这样每个小文件的大约为300M。 遍历文件b，采取和a相同的方式将url分别存储到1000小文件（记为b0,b1,…,b999）。这样处理后，所有可能相同的url都在对应的小文件（a0vsb0,a1vsb1,…,a999vsb999）中，不对应的小文件不可能有相同的url。然后我们只要求出1000对小文件中相同的url即可。 求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。 方案2：bloom filter（允许有一定的错误率） 4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）。 在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。 方案1：2-Bitmap 采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存2^32 * 2 bit=1 GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。 方案2 也可采用与第1题类似的方法，进行划分小文件的方法。然后在小文件中找出不重复的整数，并排序。然后再进行归并，注意去除重复的元素。 腾讯面试题：给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？ 方案1 申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在 方案2 因为2^32为40亿多，所以给定一个数可能在，也可能不在其中；这里我们把40亿个数中的每一个用32位的二进制来表示。 假设这40亿个数开始放在一个文件中，然后将这40亿个数分成两类: 1.最高位为0 2.最高位为1 并将这两类分别写入到两个文件中，其中一个文件中数的个数&lt;=20亿，而另一个&gt;=20亿（这相当于折半了）；与要查找的数的最高位比较并接着进入相应的文件再查找 再然后把这个文件为又分成两类: 1.次最高位为0 2.次最高位为1 并将这两类分别写入到两个文件中，其中一个文件中数的个数&lt;=10亿，而另一个&gt;=10亿（这相当于折半了）； 与要查找的数的次最高位比较并接着进入相应的文件再查找。 ....... 以此类推，就可以找到了,而且时间复杂度为O(logn) 怎么在海量数据中找出重复次数最多的一个？ 先做hash，然后求模映射为小文件，求出每个小文件中重复次数最多的一个，并记录重复次数。然后找出上一步求出的数据中重复次数最多的一个就是所求]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring]]></title>
    <url>%2F2019%2F09%2F23%2FSpring%2F</url>
    <content type="text"><![CDATA[Spring 优点 轻量 控制反转 AOP 容器：Spring 包含并管理应用中对象的生命周期和配置 MVC框架 事务管理：Spring 提供一个持续的事务管理接口，可以扩展到上至本地事务下至全局事务 异常处理： 提供方便的API把具体技术相关的异常（比如由JDBC，Hibernate or JDO抛出的）转化为一致的unchecked 异常 缺点 jsp中要写很多代码、控制器过于灵活，缺少一个公用控制器 不支持分布式，这也是EJB仍然在用的原因之一 IoC 控制反转是一种通过描述并通过第三方去产生或获取特定对象的方式。在Spring中实现控制反转的是IoC容器，其实现方法是DI（依赖注入） 解决了类与类之间的依赖关系。程序员将控制类与类之间依赖的权利交给了IOC 比如说我们现在有两个类A和B，那么我们不需要new A()、或者new B()来创建A和B的对象，Spring会帮我们创建A和B的对象（默认是单例），并且把A和B的对象放入IoC容器中，如果B对象中需要用到A对象的话，那么就要用到DI，Spring会帮我们把A对象注入到B对象中，一般是通过setter方法注入或构造器注入。 在Spring中，有两个主要的IoC容器系列 实现BeanFactory接口的简单容器系列 BeanFactory容器中，不会调用ApplicationContextAware接口的setApplicationContext()方法 BeanPostProcessor接口的postProcessBeforeInitialzation()方法和postProcessAfterInitialization()方法不会自动调用，必须自己通过代码手动注册 BeanFactory容器启动的时候，不会去实例化所有Bean,包括所有scope为singleton且非懒加载的Bean也是一样，而是在调用的时候去实例化 实现ApplicationContext接口的高级容器系列 在BeanFatory容器的基础上增加了事件传播、资源访问和国际化的消息访问等功能 在容器启动时会实例化scope为singleton且非懒加载的bean IoC容器的初始化： 入口是在构造方法中调用refresh开始的 通过ResourceLoader来完成资源文件位置的定位 通过BeanDefinitionReader来完成定义信息的解析和Bean信息的注册，XmlBeanDefinitionReader是BeanDefinitionReader的实现类，通过它来解析xml配置中的bean定义 BeanDefinition的载入：把用户定义好的Bean表示成IoC容器内部的数据结构，即BeanDefinition。 BeanDefinition的注册：把BeanDefinition向IoC容器注册，由BeanDefinitionRegistry实现的registerBeanDefiition方法进行。内部使用ConcurrentHashMap来保存BeanDefiition 在解析元素过程中没有创建和实例化Bean对象，只是创建了Bean对象的定义类BeanDefinition，将元素中的配置信息设置到BeanDefinition中作为记录，当依赖注入时才使用这些记录信息创建和实例化具体的Bean对象。 依赖注入的过程(lazy-init)： 依赖注入的过程是用户第一次向IoC容器索要Bean时触发的，在BeanFatory接口中的getBean方法的实现就是触发依赖注入的地方。 Bean定义为单例模式(Singleton)，则容器在创建之前先从缓存中查找，以确保整个容器中只存在一个实例对象。如果Bean定义的是原型模式(Prototype)，则容器每次都会创建一个新的实例对象。除此之外，Bean定义还可以扩展为指定其生命周期范围 依赖注入主要在两个方法中： createBeanInstance：生成Bean所包含的java对象实例。 用CGLIB来生成 通过BeanUtils，它使用了JVM的反射功能来生成Java对象实例 populateBean ：对Bean属性的依赖注入进行处理 属性值类型不需要转换时，不需要解析属性值，直接准备进行依赖注入。 属性值需要进行类型转换时，如对其他对象的引用等，首先需要解析属性值(resolveValueIfNecessary方法)，然后对解析后的属性值进行依赖注入 setPropertyValues 属性注入 获取到某个Bean的时候也会通过递归的方式来依赖注入依赖的bean 依赖注入的方式 @autowired 注解 setter方法： 要在&lt;bean&gt; 标签中创建一个 &lt;property&gt; 标签 ref指向其他&lt;bean&gt;标签的name属性 构造器注入 不用的形式，而是使用标签 ref指向其他&lt;bean&gt;标签的name属性 静态工厂的方法 工厂初始化之前，工厂中的类就已经被实例化放在工厂容器中 ref指向静态工厂 配置 factory-method=”…”指定调用哪个工厂方法 实例工厂的方法 工厂在构造方法初始化时，将类实例化放在工厂中 先有bean工厂，再bean一个具体类 需要首先new工厂类，再调用普通的实例方法 Spring IoC容器中管理了一系列靠依赖关系联系起来的Bean，程序不需要应用自己手动创建所需的对象，Spring IoC容器会在我们使用的时候自动为我们创建，并且为我们注入好相关的依赖 循环依赖 三级缓存 第一级缓存singletonObjects：放置实例化好的单例对象 第二级缓存earlySingletonObjects：放置提前曝光的单例对象（没有完全装配好） 第三级缓存singletonFactorys：存放的是要被实例化的对象的对象工厂 IOC中的继承和java继承的区别 前者是实例与实例之间参数值的延续，后者则是从一般到特殊的细化。Spring 中的子bean 和父bean 可以是不同类型，但在Java 中的，子类是对父类的加强，是一种特殊的父类 前者是对象与对象之间的关系，后者是类与类之间的关系。spring 中bean 的继承是实例之间的关系，主要表现为参数值的延续:而Java 中的继承是类与类之间的关系，主要表现为方法及属性的延续。 Spring 中子bean 不可作父bean 使用，不具备多态性；而Java 中的子类实例完全可当成父类实例使用。 bean的生命周期 容器启动后，会对scope为singleton且非懒加载的bean进行实例化 按照Bean定义信息配置信息，注入所有的属性 如果实现了BeanNameAware接口，会回调该接口的setBeanName()方法，传入该Bean的id，此时该Bean就获得了自己在配置文件中的id 如果Bean实现了BeanFactoryAware接口，会回调该接口的setBeanFactory()方法，传入该Bean的BeanFactory，这样该Bean就获得了自己所在的BeanFactory 如果Bean实现了ApplicationContextAware接口,会回调该接口的setApplicationContext()方法，传入该Bean的ApplicationContext，这样该Bean就获得了自己所在的ApplicationContext 如果有Bean实现了BeanPostProcessor（实例化后置处理器）接口，则会回调该接口的postProcessBeforeInitialzation()方法 如果Bean实现了InitializingBean接口，则会回调该接口的afterPropertiesSet()方法 如果Bean配置了init-method方法，则会执行init-method配置的方法 如果有Bean实现了BeanPostProcessor接口，则会回调该接口的postProcessAfterInitialization()方法 之后便可以正式使用Bean了，对于scope为singleton的Bean,Spring的ioc容器中会缓存一份该bean的实例，而对于scope为prototype的Bean,每次被调用都会new一个新的对象，期生命周期就交给调用方管理了，不再是Spring容器进行管理了 容器关闭后，如果Bean实现了DisposableBean接口，则会回调该接口的destroy()方法 如果Bean配置了destroy-method方法，则会执行destroy-method配置的方法，至此，整个Bean的生命周期结束 bean的scope singleton：一个容器中只存在一个实例 prototype：每次收到请求都生成一个新的实例 request session globalSession AOP 运用场景：事务管理(数据库事务、编程事务、声明事务Spring AOP)，日志处理，安全验证 AOP有三种织入切面的方法： 其一是编译期织入，这要求使用特殊的Java编译器，AspectJ是其中的代表者； 其二是类装载期织入，而这要求使用特殊的类装载器，AspectJ和AspectWerkz是其中的代表者； 其三为动态代理织入，在运行期为目标类添加增强生成子类的方式，Spring AOP采用动态代理织入切面。 提供了对JDK动态代理的支持以及CGLib的支持。 JDK动态代理只能为接口创建动态代理实例，而不能对类创建动态代理 CGLib动态代理需要依赖asm包，把被代理对象类的class文件加载进来，修改其字节码生成子类。 相关概念 关注点concern： 一个关注点可以是一个特定的问题，概念、或者应用程序的兴趣点。总而言之，应用程序必须达到一个目标 安全验证、日志记录、事务管理都是一个关注点 在oo应用程序中，关注点可能已经被代码模块化了还可能散落在整个对象模型中 连接点join point：程序执行的某个特定位置：如类开始初始化前，类初始化后，类某个方法调用前。一个类或一段代码拥有一些边界性质的特定点，这些代码中的特定点就被称为“连接点”。 切点pointcut：AOP通过“切点”定位特定的连接点，即连接点相当于数据库中的记录，而切点相当于查询条件 一个类中可能有多个方法，每个都是连接点，通过切点定位某一个感兴趣的连接点 一个切点可以匹配多个连接点 增强advice：织入到目标类连接点上的一段程序代码 目标对象target：增强逻辑的织入目标类 引介introduction：引介是一种特殊的增强，它为类添加一些属性和方法。这样，即使一个业务类原本没有实现某个接口，通过AOP的引介功能，我们可以动态的为该事务添加接口的实现逻辑，让业务类成为这个接口的实现类。 切面aspect：切面由切点和增强（引介）组成，它既包括了横切逻辑的定义，也包括了连接点的定义，Spring AOP就是负责实施切面的框架，它将切面所定义的横切逻辑织入到切面所指定的链接点中。 事务管理 spring并不直接管理事务，而是提供了多种事务管理器，将事务管理的职责委托给Hibernate或者JTA等持久化机制所提供的相关平台框架的事务来实现 PlatformTransactionManager接口为各个平台提供了对应的事务管理器 getTransaction() commit() rollback() 优点 为不同的事务API提供一致的编程模型，如JTA、JDBC、Hibernate、JPA Spring MVC工作原理 Http请求：客户端请求提交到前置控制器DispatcherServlet DispatcherServlet寻找处理器Controller：由DispatcherServlet控制器查询一个或多个HandlerMapping，找到处理请求所对应的Controller 处理器Controller执行：DispatcherServlet将请求提交到Controller，Controller调用业务逻辑处理后，返回ModelAndView。 dispatcherServlet借助ViewResoler完成逻辑视图到真实视图对象的解析 dispatcherServlet使用这个view对ModelAndView中的模型数据进行视图渲染，返回给用户 核心组件 DispatcherServlet：前置控制器，负责分发请求 HandlerMapping：映射处理器，负责根据请求找到对应的控制器 Controller：处理请求的控制器 ModelAndView：封装数据信息和视图信息 ViewReslover：视图处理器，通过处理找到对应的页面 怎样实现重定向和转发？ 在返回值的前面加”forword”，就可以实现让结果转发 在返回值的前面加上”redirect”，就可以让返回值重定向。 Spring Boot 主要是简化了spring的难度，简省了繁重的配置，提供了各种容器，开发者能快速上手 优点 独立运行 内嵌了各种servlet容器，Tomcat、Jetty等 不再需要打成war包部署到容器中，Spring Boot只要打成一个可执行的jar包就能独立运行，所有的依赖包都在一个jar包内。 简化配置 spring-boot-starter-web启动器自动依赖其他组件，简少了maven的配置 自动配置 Spring Boot能根据当前类路径下的类、jar包来自动配置bean，如添加一个spring-boot-starter-web启动器就能拥有web的功能，无需其他配置。 无代码生成和XML配置 Spring Boot配置过程中无代码生成，也无需XML配置文件就能完成所有配置工作，这一切都是借助于条件注解完成的 应用监控 Spring Boot提供一系列端点可以监控服务及应用，做健康检测。 核心注解 @SpringBootConfiguration：组合了 @Configuration 注解，实现配置文件的功能。 @EnableAutoConfiguration：打开自动配置的功能，也可以关闭某个自动配置的选项 @ComponentScan：Spring组件扫描 如何理解 Spring Boot 中的 Starters Starters可以理解为启动器，它包含了一系列可以集成到应用里面的依赖包，你可以一站式集成 Spring 及其他技术，而不需要到处找示例代码和依赖包。 SSH/SSM SSH：structs2(控制器)+spring(管理各层组件)+hibernate(持久化层) Struts2是Action类级别 SSM：SpringMVC(控制器)+spring(管理各层组件)+mybatis(持久化层) SpringMVC是方法级别，更容易实现RESTful风格 Structs2工作原理Struts2使用Filter嵌入 客户端初始化一个指向Servlet容器（例如Tomcat）的请求，这个请求经过一系列的过滤器（Filter） 接着FilterDispatcher被调用，FilterDispatcher询问ActionMapper来决定这个请求是否需要调用Action FilterDispatcher把处理权交给ActionProxy，ActionProxy通过Configuration Manager询问框架的配置文件，找到需要调用的Action类 ActionProxy创建一个ActionInvocation的实例 ActionInvocation实例使用命名模式来调用，在调用Action的过程前后，涉及到相关拦截器（Intercepter）的调用 一旦Action执行完毕，ActionInvocation负责根据struts.xml中的配置找到对应的返回结果。返回结果通常是（但不总是，也可 能是另外的一个Action链）一个需要被表示的JSP或者FreeMarker的模版 将处理结果返回给客户端 Servlet 是运行在服务端的java程序，为java程序提供一个统一的web应用的规范 一个http请求到来，容器将请求封装成Servlet中的request对象，在request中可以得到http的所有信息，并将其取出进行操作 最后将数据封装成Servlet中的response对象，容器将response解析后封装成http response Tomcat是一个servlet容器 生命周期 初始化阶段init()：init方法只会被调用一次 Servlet容器启动时自动装载某些servlet 在Servlet容器启动后，客户首次向Servlet发送请求 Servlet类文件被更新后，重新装载 处理客户请求阶段service()：每收到一个客户端请求，服务器就会产生一个新的线程去处理 对于用户的Servlet请求，Servlet容器会创建一个特定于请求的ServletRequest和ServletResponse service()方法会对请求的方法进行匹配 对于tomcat来说，它会将传递来的参数放入一个HashTable中，这是一个String–&gt;String[]的键值映射 终止阶段destroy() 当web应用被终止，或者Servlet容器终止运行，或者Servlet重新装载Servlet新实例时，Servlet容器会调用Servlet的destroy()方法]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java基础]]></title>
    <url>%2F2019%2F03%2F26%2Fjava%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Java反射机制 What? 动态加载对象，并对对象进行剖析 在运行状态中，对于任意一个类，都能知道它的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法 动态获取信息以及动态调用对象方法的功能称为Java反射机制 example 123Class c1 = Code.class;//这说明任何一个类都有一个隐含的静态成员变量class，这种方式是通过获取类的静态成员变量class得到的Class c2 = code1.getClass();//code1是Code的一个对象，这种方式是通过一个类的对象的getClass()方法获得的Class c3 = Class.forName("com.trigl.reflect.Code");//这种方法是Class类调用forName方法，通过一个类的全量限定名获得 相关操作 获取成员方法信息 获取成员变量信息 获取构造函数 12345678910111213Class c = Class.forName("com.tengj.reflect.Person"); //先生成classObject o = c.newInstance(); //newInstance可以初始化一个实例Method method = c.getMethod("fun", String.class, int.class);//获取方法method.invoke(o, "tengj", 10); //通过invoke调用该方法,参数第一个为实例对象，后面为具体参数值Method[] methods = c.getDeclaredMethods(); // 得到该类所有的方法，不包括父类的或者：Method[] methods = c.getMethods();// 得到该类所有的public方法，包括父类的Field[] fields = c.getDeclaredFields();//获取构造函数Constructor constructor = c.getDeclaredConstructor(String.class);constructor.setAccessible(true);//设置是否允许访问，因为该构造器是private的，所以要手动设置允许访问，如果构造器是public的就不需要这行了。 优缺点 优点 提高了程序的灵活性和扩展性：可以实现动态创建对象和编译 底层框架中用的比较多，业务层少用 缺点 性能不好：反射是一种解释操作，用于字段和方法接入时要远远慢于直接代码 程序逻辑有影响：会模糊化程序的内部逻辑 使用场景 实现RPC框架 实现ORM框架 拷贝属性值(BeanUtils.copyProperties) Java代理机制 静态代理：编译时实现 编译后代理类是一个class文件 AspectJ的底层技术是静态代理 通过一个命令来编译，生成一个新的代理类 在编译时增强 动态代理：运行时生成 在运行时动态生成的类字节码，并加载到JVM中 动态代理JDK代理利用反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。 JDK的动态代理只能针对实现了接口的类生成代理 example 12345//Car接口public interface Car &#123; public void run();&#125; 123456789101112131415//Car实现类public class CarImpl implements Car&#123; @Override public void run() &#123; start(); System.out.println("running...."); &#125; @Override public void start() &#123; System.out.println("starting......."); &#125;&#125; 123456789101112131415161718192021//Car代理类import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;//JDK动态代理代理类 public class CarHandler implements InvocationHandler&#123; //真实类的对象 private Object car; //构造方法赋值给真实的类 public CarHandler(Object obj)&#123; this.car = obj; &#125;//代理类执行方法时，调用的是这个方法 public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("before"); Object res = method.invoke(car, args); System.out.println("after"); return res; &#125;&#125; 123456789101112131415161718192021//Main方法import java.lang.reflect.Proxy;public class main &#123; public static void main(String[] args) &#123; CarImpl carImpl = new CarImpl(); CarHandler carHandler = new CarHandler(carImpl); Car proxy = (Car)Proxy.newProxyInstance( main.class.getClassLoader(), //第一个参数，获取ClassLoader carImpl.getClass().getInterfaces(), //第二个参数，获取被代理类的接口 carHandler);//第三个参数，一个InvocationHandler对象，表示的是当我这个动态代理对象在调用方法的时候，会关联到哪一个InvocationHandler对象上 proxy.run(); &#125;&#125;打印结果：beforestarting....running.....after JDK的动态代理依靠接口实现，入参必须有被代理类的接口，也就是carImpl.getClass().getInterfaces(),如果有些类并没有实现接口，则不能使用JDK代理 CGLIB动态代理利用asm开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。 针对类实现代理，对指定的目标类生成一个子类， 并覆盖其中方法实现增强，但因为采用的是继承，所以不能对final修饰的类进行代理 example 12345678910111213//没有实现接口的carpublic class CarNoInterface &#123; public void run() &#123; start(); System.out.println("car running"); &#125; public void start()&#123; System.out.println("starting...."); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536//cglib代理类import java.lang.reflect.Method;import org.springframework.cglib.proxy.Enhancer;import org.springframework.cglib.proxy.MethodInterceptor;import org.springframework.cglib.proxy.MethodProxy;public class CglibProxy implements MethodInterceptor&#123; private Object car; /** * 创建代理对象 * * @param target * @return */ public Object getInstance(Object object) &#123; this.car = object; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(this.car.getClass()); // 回调方法 enhancer.setCallback(this); // 创建代理对象 return enhancer.create(); &#125; @Override public Object intercept(Object obj, Method method, Object[] args,MethodProxy proxy) throws Throwable &#123; System.out.println("before"); proxy.invokeSuper(obj, args); System.out.println("after"); return null; &#125;&#125; 12345678910111213141516171819//main方法import java.lang.reflect.Proxy;public class main &#123; public static void main(String[] args) &#123; CglibProxy cglibProxy = new CglibProxy(); CarNoInterface carNoInterface = (CarNoInterface)cglibProxy.getInstance(new CarNoInterface()); carNoInterface.run(); &#125;&#125;打印结果：beforebeforestarting....aftercar runningafter Spring中两者使用场景 如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP 如果目标对象实现了接口，可以强制使用CGLIB实现AOP 添加CGLIB库，SPRING_HOME/cglib/*.jar 在spring配置文件中加入&lt;aop:aspectj-autoproxy proxy-target-class=”true”/&gt; 如果目标对象没有实现了接口，必须采用CGLIB库，spring会自动在JDK动态代理和CGLIB之间转换 异常 Exception有两个分支，一个是运行时异常RuntimeException，一个是检查异常CheckedException RuntimeException 是那些可能在 Java 虚拟机正常运行期间抛出的异常的超类。 一般包含以下几个方面 错误的类型转换 数组访问越界 访问空指针 如果出现RuntimeException，那么一定是程序员的错误 在定义方法时不需要声明会抛出RuntimeException， 在调用这个方法时不需要捕获这个RuntimeException CheckedException 一般是外部错误，这种异常都发生在编译阶段，Java编译器会强制程序去捕获此类异常，即会出现要求你把这段可能出现异常的程序进行try catch 一般包含以下几个方面 试图在文件尾部读取数据 试图打开一个错误格式的URL 试图根据给定的字符串查找class对象，而这个字符串表示的类并不存在 定义方法时必须声明所有可能会抛出的exception； 在调用这个方法时，必须捕获它的checked exception，不然就得把它的exception传递下去 一个方法必须声明所有的可能抛出的受检异常；未检查异常要么不可控制（Error），要么应该避免（RuntimeException）。如果方法没有声明所有的可能发生的受检异常，编译器就会给出错误信息。 Throwable类常用方法 public string getMessage()：返回异常发生时的详细信息 public string toString()：返回异常发生时的简要描述 public string getLocalizedMessage()：返回异常对象的本地化信息。 使用Throwable的子类覆盖这个方法，可以声称本地化信息。 如果子类没有覆盖该方法，则该方法返回的信息与getMessage（）返回的结果相同 public void printStackTrace()：在控制台上打印Throwable对象封装的异常信息 ==、equal和hashcode==它的作用是判断两个对象的地址是不是相等。即，判断两个对象是不是同一个对象。(基本数据类型==比较的是值，引用数据类型==比较的是内存地址) equal它的作用也是判断两个对象是否相等。但它一般有两种使用情况： 类没有覆盖 equals() 方法。则通过 equals() 比较该类的两个对象时，等价于通过“==”比较这两个对象。 类覆盖了 equals() 方法。一般，我们都覆盖 equals() 方法来两个对象的内容相等；若它们的内容相等，则返回 true (即，认为这两个对象相等)。 hashcodehashCode() 的作用是获取哈希码，也称为散列码；它实际上是返回一个int整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。hashCode() 定义在JDK的Object.java中，这就意味着Java中的任何类都包含hashCode() 函数。 为什么要有hashcode？ 以hashSet为例 当你把对象加入 HashSet 时，HashSet 会先计算对象的 hashcode 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashcode 值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。 但是如果发现有相同 hashcode 值的对象，这时会调用 equals（）方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。 大大减少了 equals 的次数，相应就大大提高了执行速度。 与equals的区别 如果两个对象equals相等，那么他们的hashcode一定相等 如果两个对象的hashcode相等，它们的equals不一定相等 如果两个对象的hashcode不相等，他们的equals一定不相等 因此，equals 方法被覆盖过，则 hashCode 方法也必须被覆盖 final关键字final关键字主要用在三个地方：变量、方法、类。 final变量 基本数据类型的变量，则其数值一旦在初始化之后便不能更改 引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象 final修饰类 表明这个类不能被继承 final类中的所有成员方法都会被隐式地指定为final方法 final方法 使用final方法的原因 是把方法锁定，以防任何继承类修改它的含义 效率 类中所有的private方法都隐式地指定为final Transient关键字 transient关键字的作用是：阻止实例中那些用此关键字修饰的变量序列化 当对象被反序列化时，被transient修饰的变量值不会被持久化和恢复 transient只能修饰变量，不能修饰类和方法]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[项目]]></title>
    <url>%2F2019%2F03%2F06%2F%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[DevOps工具链DevOps 通过高度自动化工具与流程来使得软件构建、测试、发布更加快捷、频繁和可靠 将开发、运维一体化 可以把 DevOps 看作开发（软件工程）、技术运营和质量保障（QA）三者的交集。 传统的软件组织将开发、IT 运营和质量保障设为各自分离的部门， 按照从前的工作方式，开发和部署，不需要 IT 支持或者 QA 深入的跨部门的支持；而现在却需要极其紧密的多部门协作。 而 DevOps 考虑的还不止是软件部署，它是一套针对这几个部门间沟通与协作问题的流程和方法。 好处 代码的提交直接触发：消除等待时间，快速反馈 每个变化对应一个交付管道：使问题定位和调试变得简单 全开发流程高效自动化：稳定，快速，交付结果可预测 持续进行自动化回归测试：提升交付质量 持续集成 频繁地（一天多次）将代码集成到主干 让产品可以快速迭代，同时还能保持高质量 持续交付 频繁地将软件的新版本，交付给质量团队或者用户，以供评审。 持续部署 持续交付的下一步，指的是代码通过评审以后，自动部署到生产环境。 工具链 代码托管：gitlab 为什么不使用github？ gitlab对仓库有更多的控制，可以设置仓库权限是公用的还是私有的 每一次的提交或者 Merge Request 的合并都可以触发pipeline 持续集成 gitlabCI：集成较好， 界面美观优雅， 使用简单 gitlab runner进行构建任务，gitlabCI负责管理各个项目的构建状态 runner需要注册到CI中，可以安装到不同的机器上，因此构建任务期间不会影响gitlab的性能 pipeline：相当于一次构建任务，里面可以包含多个流程，比如自动构建、自动进行单元测试、自动进行代码检查等流程 stages： build, test, deploy jobs 包含实时构建日志，容易追踪 Jenkins 通过gitlab的webhook设置，自动触发构建工作，就不需要人工干预了 jenkins在项目配置时可以配置远程构建触发器，设置好jenkins的回调url后就可以让jenkins进行自动构建。 jenkins将代码打成docker镜像，push到docker-registry 静态代码检查：sonarqube Sonar GitLab Plugin 插件 该插件会针对每次提交修改的文件，添加注释行，同时添加本次提交的代码检测结果的评论 配合 gitlab-ci 完成每次 commit 时，添加的代码检测 Pipelines stage 流程，来控制代码检测流程是否通过 检查范围： 不遵循代码标准 重复 潜在的缺陷 质量糟糕的复杂度分布 注释不足或过多 缺乏单元测试 糟糕的设计 PMD,checkstyle，findbugs等代码规则检测工具规范代码编写/检测出潜在的缺陷 可以很方便地统计并展示单元测试覆盖率 项目部署：docker 使用GitLab runner 来 build docker image上传到仓库中 为了要让 runner 可以调用 docker 命令, 需要把 gitlab-runner 这个用户加入 docker 所在组.]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库]]></title>
    <url>%2F2019%2F03%2F03%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[Redis key-value类型的内存(缓存)数据库 整个数据库加载到内存中操作，定期flush到硬盘上进行保存 单线程 CPU不是瓶颈，单线程容易实现 集群是master/slave模式 为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有N-1个复制品 异步复制 Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。 与memchached的区别 memchached仅支持string类型，Redis支持更丰富的数据类型且能提供对他们的原子操作 Redis速度更快 Redis可以持久化 支持的数据类型和底层实现 在Redis中，所有key-value对都存储在一个hash table中 Hash table是一个二维结构 一个一维固定长度的数组，每个槽位上保存一个dictEntry对象。key计算hash值后按照这个定长数组求模，结果相同的key-balue通过链表保存在同一个槽位上，这样便形成了一个二维结构 String 能存为整数则存为整数，不能则存为原始字符串 一个字符串类型的值能存储的最大容量是512M List 使用 zip List结构 zip list通过一个连续的内存块实现list结构，其中的每个entry节点头部保存前后节点长度信息，实现双向链表功能 当list内容较多时，使用双向链表 hash 新建的Hash类型也使用zip list存储value 保存数据过多时，转而使用hash table set 创如果value能够表示为整数，则使用intset类型保存value。intset使用和ziplist相似的实现方式保存整数 数据量大时，切换为使用hash table 使用场景 会话缓存 队列 发布/订阅 排行榜/计数器 如何做内存优化？ 使用hashes(散列表)，散列表（是说散列表里面存储的数少）使用的内存非常小 比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key,而是应该把这个用户的所有信息存储到一张散列表里面. Redis是单线程，如何提高CPU利用率？ 可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用 持久化 如何进行？ bgsave 做镜像全量持久化 fork 和 cow，创建子进程进行bgsave操作，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来 耗费较长时间，不够实时，在停机的时候会导致大量丢失数据 aof 做增量持久化 在 redis 实例重启时，会使用 bgsave 持久化文件重新构建内存，再使用 aof 重放近期的操作指令来实现完整恢复重启之前的状态。 方式 RDB持久化方式能够在指定的时间间隔能对数据进行快照存储 AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据 AOF命令以redis协议追加保存每次写的操作到文件末尾 Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大 定时生成RDB快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外， 使用RDB还可以避免之前提到的AOF程序的bug。 集群方案 twemproxy，类似代理。设置好它下属的多个redis实例后，使用时在本需要连接redis的地方改为连接twemproxy，它会以一个代理的身份接收请求并使用一致性hash算法(对2^32取模)，将请求转接到具体redis 使用方式简便(相对redis只需修改连接端口)，对旧项目扩展的首选 twemproxy自身单端口实例的压力，使用一致性hash后，对redis节点数量改变时候的计算值的改变，数据无法自动移动到新的节点。 codis，基本和twemproxy一致的效果，但它支持在 节点数量改变情况下，旧节点数据可恢复到新hash节点 redis cluster3.0自带的集群，分布式算法不是一致性hash，而是hash槽的概念，以及自身支持节点设置从节点 同步机制 主从同步，从从同步 第一次同步时，主节点做一次 bgsave，并同时将后续修改操作记录到内存buffer，待完成后将RDB文件全量同步到复制节点，复制节点接受完成后将RDB镜像加载到内存 加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放 分区 实现方案 客户端分区：在客户端就已经决定数据会被存储到哪个redis节点或者从哪个redis节点读取。大多数客户端已经实现了客户端分区。 代理分区：客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据 查询路由(Query routing) ：客户端随机地请求任意一个redis实例，然后由Redis将请求转发给正确的Redis节点。 缺点： 涉及多个key的操作通常不会被支持，同时操作多个key,则不能使用Redis事务 数据处理会变复杂：备份必须从不同的Redis实例和主机同时收集RDB / AOF文件 分区时动态扩容或缩容可能非常复杂，Redis集群在运行时增加或者删除Redis节点，能做到最大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持这种特性 常见性能问题和解决方案 Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2 &lt;- Slave3…这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。 缓存雪崩 由于原有缓存失效，新缓存未到期间(例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力 解决方案 加锁排队：只是为了减轻数据库的压力，并没有提高系统吞吐量。假设在高并发下，缓存重建期间key是锁着的，这是过来1000个请求999个都在阻塞的。同样会导致用户等待超时 给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存 缓存穿透 用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询） 解决方案 布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力 如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。 缓存预热 系统上线后，提前将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存 解决方案 直接写个缓存刷新页面，上线时手工操作 数据量不大，可以在项目启动的时候自动进行加载 定时刷新缓存 缓存更新 除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种： 定时清理过期的缓存（维护大量缓存的key非常麻烦） 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存（逻辑相对较复杂） 缓存降级 缓存如何解决缓存一致性问题 先删除缓存，再更新数据库 线程A删除缓存—&gt;线程B查询数据—&gt;发现缓存数据不存在—&gt;线程B查询数据库得到旧值—&gt;写入缓存—&gt;线程A将新值更新到数据库。这样一来缓存中的数据仍然是旧值。 如果B执行的是更新操作，那么A的更新操作就会被抹去，这就是更新数据库事务原子性问题，需要使用分布式锁来解决 先更新数据库，再删除缓存 数据安全无法保证：原本顺序应为A先执行，后B执行，数据库的记录是B执行后的记录，但是变为，请求A Update 数据库 —&gt; 请求B Update 数据库 —&gt; 请求B Update 缓存 —&gt; 请求A Update 缓存。 这就导致缓存和数据库中的数据不一致，从而缓存中的数据成为了脏数据。 且写入写入操作多于读操作，就会频繁的刷新缓存，但是这些数据根本没有被读过。这样就会浪费服务器的资源。 这种情况下只需要线程B延时删除缓存就好。另外在数据库主从同步的情况下，延时删除还能防止数据更新还未从主数据库同步到从数据库的情况。 延时双删策略 先淘汰缓存，再写数据库，休眠一段时间，再淘汰缓存，可以将这段时间内造成的脏数据删除 设计为延时双删的目的在于当最后一次延时删除缓存失败的情况发生，至少一致性策略只会退化成先删缓存再更新数据的策略。 在主从同步完成之前线程查询到的值仍旧是旧值 队列删除缓存 在把数据更新到数据库后，把删除缓存的消息加入到队列中，如果队列执行失败，就再次加入到队列执行直到成功为止。这样，只要队列消息能够保证安全，那么缓存就一定会被刷新 基于业务代码，耦合度很高 binlog订阅删除缓存 整体技术思路： 读Redis：热数据基本都在Redis 写MySQL：增删改查都是操作MySQL 更新Redis数据：订阅MySQL的数据操作记录binlog（canal中间件），来更新到Redis 分为两部分： 全量更新 增量更新(实时更新) 一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息通过消息队列推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。 这种同步机制类似于MySQL的主从备份机制 如何扩容？ 被当做缓存：一致性哈希实现动态扩容 MySQL存储引擎https://draveness.me/mysql-innodb InnoDB 所有的数据都被逻辑地存放在表空间中，表空间（tablespace）是存储引擎中最高的存储逻辑单位，在表空间的下面又包括段（segment）、区（extent）、页（page） 页作为磁盘管理的最小单位,在页中数据按行存储。 MySQL 使用 InnoDB 存储表时，会将表的定义和数据索引等信息分开存储 B+ 树索引并不能找到一个给定键对应的具体值，它只能找到数据行对应的页，然后数据库把整个页读入到内存中，并在内存中查找具体的数据行。 聚集索引/主键索引 存放着一条行记录的全部信息 辅助索引 只包含索引列和一个用于查找对应行记录的主键值。 InnoDB与MYlSAM区别两者都是MySQL中最常用的两个表类型 MyISAM类型不支持事务处理等高级处理，而InnoDB类型支持(提交、回滚和崩溃恢复能力) MyISAM类型的表强调的是性能，其执行速度比InnoDB类型更快 InnoDB的数据文件本身就是索引文件，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址 InnoDB 中不保存表的具体行数，也就是说，执行select count(*) from table时，InnoDB要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当count(*)语句包含 where条件时，两种表的操作是一样的。 两种类型最主要的差别就是Innodb 支持事务处理与外键完整性约束和行级锁，所以MyISAM往往就容易被人认为只适合在小项目中使用,但是如果项目要求99.9%的稳定性，方便的扩展性和高可用性来说的话，MyISAM绝对是首选 MySQL主从同步 基于二进制日志机制，主服务器使用二进制日志来记录数据库的变动情况，从服务器通过读取和执行该日志文件来保持和主服务器的数据一致 MySQL是异步复制的，MySQL cluster是同步复制的 优点 可以作为一种备份机制，相当于热备份 可以用来做读写分离，均衡数据库负载 方法 tatement Based Replication（SBR）基于SQL语句的复制 当使用二进制日志时，主服务器会把SQL语句写入到日志中，然后从服务器会执行该日志 日志文件更小 记录了所有的语句，可以用来日后审计 Insert … select语句会执行大量的行级锁表 Update语句会执行大量的行级锁表来扫描整个表 Row Based Replication（RBR）基于行的复制 主服务器把表的行变化作为事件写入到二进制日志中，主服务器把代表了行变化的事件复制到从服务中 所有的数据变化都是被复制，这是最安全的复制方式 更少的行级锁表 日志会很大 索引 索引 原理 对要查询的字段建立索引其实就是把该字段按照一定的方式排序；建立的索引只对该字段有用，如果查询的字段改变，那么这个索引也就无效了 优点 加快数据检索速度，提高对数据访问效率 提高数据查询性能 缺点 占用大量硬盘空间 数据的增删改等更新操作，需要维护索引时间，降低更新速度 适用场合 主键列中创建索引 多表连接时连接列创建索引 where子句查询的列 需要经常GROUP BY和ORDER BY的列 类型 主键索引 普通索引/单列索引 多列索引/复合索引 使用复合索引时遵循最左前缀原则 最左前缀原则 b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+树是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道第一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。 最左优先，先要看第一列，在第一列满足的条件下再看左边第二列，以此类推 eg: 多列字段做索引，state/city/zipCode，想要索引生效的话，只能使用如下的组合：state/city/zipCode，state/city，state。其他方式（如city，city/zipCode），则索引不会生效 MySQL索引 B+树 特点 非叶子节点的子树指针与关键字个数相同 非叶子节点不存储数据，只存储指针索引(稀疏索引)；叶子节点存储所有关键字数据(稠密索引)，不存储指针 在经典B+树基础上增加了顺序访问指针，每个叶子节点都有指向相邻下一个叶子节点的指针 提高区间访问的性能 更适合文件系统 为什么说B+树比B树更适合数据库索引？ B+树的磁盘读写代价更低 B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了 B+树的查询效率更加稳定 任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。 方便扫库 由于B+树的数据都存储在叶子结点中，分支结点均为索引，只需要扫一遍叶子结点即可 范围扫描更简单 内部节点可以定位更多叶子节点 MyISAM中的B+树 叶子节点的数据区域存储的是数据记录的地址 在使用索引查询数据时，会先根据索引查找到数据地址，再根据地址查询到具体的数据 主键索引和辅助索引没有太多区别 InnoDB中的B+树 主键索引的叶子节点的数据区域存储的是数据记录 辅助索引存储的是主键值 Innodb的一个表一定要有主键索引，如果一个表没有手动建立主键索引，Innodb会查看有没有唯一索引，如果有则选用唯一索引作为主键索引，如果连唯一索引也没有，则会默认建立一个隐藏的主键索引（用户不可见）。 Innodb的主键索引要比MyISAM的主键索引查询效率要高（少一次磁盘IO），并且比辅助索引也要高很多。所以，我们在使用Innodb作为存储引擎时，我们最好： 手动建立主键索引 尽量利用主键索引查询 SQL优化 重写order by语句以使用索引 SELECT子句中避免使用 ‘ * ‘ 减少访问数据库的次数 用Where子句替换HAVING子句/order by 通过内部函数提高SQL效率 用EXISTS替代IN、用NOT EXISTS替代NOT IN 使用索引 避免在索引列上使用NOT 避免在索引列上使用计算 varchar 和char的区别 varchar(n) char(n) 可变长度，最多2^16−1个字符，2^16−1个字节 固定长度，最多2^8−1个字符，2^8−1个字节 varchar只会占用实际字符应该占用的字节空间L+1(L=0到255)或L+2(L&gt;255)，并且实际字节空间L+1&lt;=255,或者L+2&lt;=65535 char不管实际value都会占用n个字符的空间 上限为65535字节，text同 上限为255字节 不会截断尾部空格 在存储的时候会截断尾部的空格 char（n）和varchar（n）中括号中n代表字符的个数，并不代表字节个数，所以当使用了中文的时候(UTF8)意味着可以插入m个中文，但是实际会占用3m个字节，m∗3&lt;=255，m∗3&lt;=65535。 超过char和varchar的n设置之后，字符串会被截断 UTF-8中，中文占3个字符，英文占1个字符 事务 概念 指访问并可能更新数据库中各种数据项的一个程序执行单元 对数据库进行读或写的一个操作序列 特性 原子性(A):事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。 一致性(C):事务应确保数据库的状态从一个一致状态转变为另一个一致状态。 隔离性(I):一个事务的执行不应影响其他事务的执行 持久性(D):一个事务一旦提交，他对数据库的修改应该永久保存在数据库中。 事务隔离级别 脏读 当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。 不可重复读 指在一个事务内，多次读同一数据。两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的 幻读 第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。 同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象 发生了幻觉一样。 级别 Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。 四级封锁协议：其他事务不能 读写 该表中的任何数据 Repeatable read (可重复读)：可避免脏读、不可重复读的发生。 MySQL默认隔离级别 三级封锁协议：一级封锁协议加上事务T在读取数据R之前必须先对其加S锁，直到事务结束才释放 Read committed (读已提交)：可避免脏读的发生。 二级封锁协议：一级封锁协议加上事务T在读取数据R之前必须先对其加S锁，读完后即可释放S锁 （瞬间S锁）。 Read uncommitted (读未提交)：最低级别，任何情况都无法保证。 一级封锁协议：事务T在修改数据R之前必须先对其加X锁，直到事务结束才释放。 MVCC(多版本并发控制) InnoDB的一致性的非锁定读就是通过在MVCC实现的，Mysql的大多数事务型存储引擎实现的都不是简单的行级锁。基于提升并发性能的考虑，它们一般都同时实现了多版本并发控制（MVCC）。但是MVCC在各个数据库中的实现并不统一。 InnoDB：通过在每行记录后面保存两个隐藏的列来实现的，这两个列分别保存了这个行的创建时间和行的删除时间。 事务以排他锁的形式修改原始数据 把修改前的数据存放于undo log，通过回滚指针与主数据关联 修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback） 乐观锁和悲观锁 123456789101.悲观锁 1、排它锁，当事务在操作数据时把这部分数据进行锁定，直到操作完毕后再解锁，其他事务操作才可操作该部分数据。这将防止其他进程读取或修改表中的数据。 2、实现：大多数情况下依靠数据库的锁机制实现 实现方式： 一般使用 select ...for update 对所选择的数据进行加锁处理，例如select * from account where name=”Max” for update， 这条sql 语句锁定了account 表中所有符合检索条件（name=”Max”）的记录。本次事务提交之前（事务提交时会释放事务过程中的锁），外界无法修改这些记录。2.乐观锁 实现方式： 1、如果有人在你之前更新了，你的更新应当是被拒绝的，可以让用户重新操作。 2、实现：大多数基于数据版本（Version）记录机制实现 具体可通过给表加一个版本号或时间戳字段实现，当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断当前版本信息与第一次取出来的版本值大小，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据，拒绝更新，让用户重新操作。 MVCC解决的问题是读写互相不阻塞的问题，每次更新都产生一个新的版本，读的话可以读历史版本。 锁机制可以控制并发操作，但是其系统开销较大，而MVCC可以在大多数情况下代替行级锁，使用MVCC能降低其系统开销。 MVCC的实现，是通过保存数据在某一个时间点的快照来实现的。因此每一个事务无论执行多长时间看到的数据，都是一样的。所以MVCC实现可重复读。 快照读：select语句默认，不加锁，MVCC实现可重复读，使用的是MVCC机制读取undo中的已经提交的数据。所以它的读取是非阻塞的 当前读：select语句加S锁或X锁；所有的修改操作加X锁，在select for update 的时候，才是当前读。 在事务隔离级别为RC和RR级别下， InnoDB存储引擎使用的才是多版本并发控制。 乐观锁与MVCC的区别？ innodb 则只对读无锁，写操作仍是上锁的悲观并发控制；但postgres 对写操作也是乐观并发控制；在表中保存同一行数据记录的多个不同版本，每次写操作，都是创建，而回避更新； 可见 MVCC 中的写操作仍可以按悲观并发控制实现，而 CAS 的写操作只能是乐观并发控制。 MVCC 在语境中倾向于 “对多行数据打快照造平行宇宙”，然而 CAS 一般只是保护单行数据而已 锁(InnoDB) 种类 排他锁/写锁/x锁 事务T可以修改A也可以读A，其他事务不能再对A加任何锁，直到事务T释放A上的锁 共享锁/读锁/s锁 其他事务可以读A，而在事务T释放A上的S锁之前不能对A进行修改 现象 死锁 互相等待 形成条件 互斥：排它性 请求和保持：对自己已获得的其它资源保持不释放 不剥夺：不能被剥夺，只能在使用完时由自己释放 循环等待 预防和解除 预防：破坏四个条件之一 避免：银行家算法 解除 剥夺资源 活锁 某一个事务T可能饿死(永远等待) 避免活锁的简单方法是采用先来先服务的策略。 并发控制机制 乐观锁：是一种思想 会先尝试对资源进行修改，在写回时判断资源是否进行了改变，如果没有发生改变就会写回，否则就会进行重试，在整个的执行过程中其实都没有对数据库进行加锁 悲观锁：是一种锁 在获取资源前对资源进行加锁，确保同一时刻只有有限的线程能够访问该资源，其他想要尝试获取资源的操作都会进入等待状态，直到该线程完成了对资源的操作并且释放了锁后，其他线程才能重新操作资源 乐观锁不会存在死锁的问题，但是由于更新后验证，所以当冲突频率和重试成本较高时更推荐使用悲观锁，而需要非常高的响应速度并且并发量非常大的时候使用乐观锁就能较好的解决问题 锁的算法 记录锁(record lock):加到索引记录上的锁 间隙锁(gap lock):对索引记录中的一段连续区域的锁 当使用类似 SELECT * FROM users WHERE id BETWEEN 10 AND 20 FOR UPDATE; 的 SQL 语句时，就会阻止其他事务向表中插入 id = 15 的记录，因为整个范围都被间隙锁锁定了 间隙锁是存储引擎对于性能和并发做出的权衡，并且只用于某些事务隔离级别 虽然间隙锁中也分为共享锁和互斥锁，不过它们之间并不是互斥的，也就是不同的事务可以同时持有一段相同范围的共享锁和互斥锁，它唯一阻止的就是其他事务向这个范围中添加新的记录 Next-key lock:是前两者的结合 Next-Key 锁锁定的是当前值和前面的范围。 当我们更新一条记录，比如 SELECT * FROM users WHERE age = 30 FOR UPDATE;，InnoDB 不仅会在范围(21, 30] 上加 Next-Key 锁，还会在这条记录后面的范围 (30, 40] 加间隙锁，所以插入 (21, 40] 范围内的记录都会被锁定。 解决幻读的问题 分布式事务https://zhuanlan.zhihu.com/p/41725894 CAP定理 一致性(Consistence):等同于所有节点访问同一份最新的数据副本 可用性(Availability):每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据 分区容错性(Partition tolerance):以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择 分布式系统只能满足三项中的两项而不可能满足全部三项 BASE理论 基本可用(BasicallyAvailable):分布式系统在出现不可预知故障的时候，允许损失部分可用性 响应时间上的损失 功能上的损失：正常情况下，在一个电子商务网站上进行购物，消费者几乎能够顺利地完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。 软状态(Softstate):允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据听不到的过程存在延时。 最终一致性(Eventuallyconsistent):需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性 分布式解决方案 二阶段提交（2PC） 参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作 补偿事务（TCC） 针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作 降低锁冲突、提高吞吐量成。 与2PC相比实现以及流程相对简单了一些 会造成代码量庞大，耦合性高 有局限性，因为有很多的业务是无法很简单的实现回滚的 本地消息表 消息生产方，需要额外建一个消息表，并记录消息发送状态。消息表和业务数据要在一个事务里提交，也就是说他们要在一个数据库里面。然后消息会经过MQ发送到消息的消费方。如果消息发送失败，会进行重试发送。 消息消费方，需要处理这个消息，并完成自己的业务逻辑。此时如果本地事务处理成功，表明已经处理成功了，如果处理失败，那么就会重试执行。如果是业务上面的失败，可以给生产方发送一个业务补偿消息，通知生产方进行回滚等操作。 消息队列 消息队列 优点 解耦： 将消息写入消息队列，需要消息的系统自己从消息队列中订阅，从而系统A不需要做任何修改 异步： 将消息写入消息队列，非必要的业务逻辑以异步的方式运行，加快相应速度(邮件和验证码) 流量削锋： 系统A慢慢的按照数据库能处理的并发量，从消息队列中慢慢拉取消息。在生产中，这个短暂的高峰期积压是允许的 缓冲 缺点 系统可用性降低 系统复杂性增加：考虑一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等 类型 ActiveMQ：主从 RabbitMQ：主从 RocketMQ：分布式 Kafka：分布式发布-订阅系统 如何保证消息队列是高可用的？ Kafka为例 一个topic分为多个partition，每个partition有多个副本，消息存储在 Broker的某一Topic的某一Partition中，同时存在多个副本 leader选举，选举的partition leader负责读写，其他的副本作为follower从leader同步消息 如何保证消息不被重复消费？ 造成重复消费的原因：因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将消息分发给其他的消费者。 针对业务场景 eg:拿到这个消息做数据库的insert操作，给这个消息做一个唯一的主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。 eg：拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作 如何保证消息的可靠性传输？ 生产者丢数据：RabbitMQ提供transaction和confirm模式来确保生产者不丢消息 发送消息前开启事务，然后发送，出现异常则回滚，成功则提交事务 消息队列丢数据：持久化磁盘 消费者丢数据：手动确认消息(RabbitMQ会自动确认消息然后删除) 如何保证消息的消费顺序？ 通过算法将需要保持先后顺序的消息放到同一个消息队列中，然后只用一个消费者去消费该队列 保证入队有序就行，出队以后的顺序交给消费者自己去保证 SQL注入 通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令 如何防止？ PreparedStatement预编译 提高代码的可读性和可维护性、提高性能以及安全性 原理：sql注入只对sql语句的准备(编译)过程有破坏作用，preparedStatement已经准备好了，不再对sql语句进行解析 使用正则表达式过滤传入的参数 字符串过滤 jsp中调用该函数检查是否包函非法字符 jsp页面判断代码 框架MyBatis MyBatis 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架。 MyBatis 避免了几乎所有的 JDBC 代码和手工设置参数以及抽取结果集。使用简单的 XML 或注解来配置和映射基本体，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。 优点 简单易学：没有任何第三方依赖，最简单安装只要两个jar文件+配置几个sql映射文件 灵活：不会对应用程序或者数据库的现有设计强加任何影响。 sql写在xml里，便于统一管理和优化。 解除sql与程序代码的耦合，提高了可维护性 提供映射标签，支持对象与数据库的orm字段关系映射 提供对象关系映射标签，支持对象关系组建维护 提供xml标签，支持编写动态sql。 缺点 编写SQL语句时工作量很大，尤其是字段多、关联表多时。 SQL语句依赖于数据库，导致数据库移植性差，不能更换数据库。 框架还是比较简陋，功能尚有缺失，虽然简化了数据绑定代码，但是整个底层数据库查询实际还是要自己写的，工作量也比较大，而且不太容易适应快速数据库修改。 二级缓存机制不佳 原理 应用程序根据XML配置文件创建SqlSessionFactory，SqlSessionFactory在根据配置，配置来源于两个地方，一处是配置文件，一处是Java代码的注解，获取一个SqlSession。SqlSession包含了执行sql所需要的所有方法，可以通过SqlSession实例直接运行映射的sql语句，完成对数据的增删改查和事务提交等，用完之后关闭SqlSession。 hibernate Hibernate是开源的一个ORM（对象关系映射）框架，是对JDBC的进一步封装 核心：面向对象、关系映射以及数据持久化 优点 更加对象化：只需要操作对象就可以 移植性：做了持久层的封装，所写代码都具有可复用性 没有侵入性(轻量级)：Hibernate不需要继承任何类，不需要实现任何接口。这样的对象叫POJO对象。 代码测试方便 提高效率，提高生产力 缺点 使用数据库特性的语句，将很难调优 对大批量数据更新存在问题 系统中存在大量的攻击查询功能 hibernate与mybatis的对比 Hibernate的真正掌握要比Mybatis困难，Hibernate比mybatis更加重量级一些。 Mybatis需要手动编写SQL语句，Hibernate也可以自己写SQL语句来指定需要查询的字段，但这样破坏了Hibernate封装以及简洁性。 mybatis由于所有SQL都是依赖数据库书写，所以扩展性，迁移性比较差 hibernate有更好的二级缓存机制，可以使用第三方缓存，MyBatis本身提供的缓存机制不佳 总结： 对于数据的操作，hibernate是面向对象的，而MyBatis是面向关系的。 Mybatis：小巧、方便、高效、简单、直接、半自动化 Hibernate：强大、方便、高效、复杂、间接、全自动化 JPA Spring Data JPA是Spring Data的子模块。使用Spring Data，使得基于”repositories”概念的JPA实现更简单和容易。 JPA默认使用hibernate作为ORM实现，所以，一般使用Spring Data JPA即会使用hibernate。]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java多线程]]></title>
    <url>%2F2019%2F02%2F28%2Fjava%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[线程创建线程 继Thread类 实现Runnable接口 实现Callable接口(比runnable多一个返回值) Java不支持多继承，但可以实现多个接口。 start()方法会启动一个新线程，并包含run()方法。而run()只会执行run方法，不会启动新线程 线程的状态 初始态new：创建一个Thread对象，但还未调用start()启动线程时，线程处于初始态。 运行态runnable 就绪态：线程已经获得执行所需要的资源，只需要分配CPU。 就绪态的线程都放在就绪队列中 运行态：获得CPU执行权，正在执行。 每个CPU每个时刻只能有一条运行态的线程 阻塞态 running状态的线程请求某一资源失败时进入阻塞态 在java中专指请求锁失败的时候进入的状态 由一个阻塞队列存放所有阻塞态的线程 一旦请求成功，进入runnable就绪队列等待执行 等待态 线程调用wait、join、park函数时进入 等待队列存放 需要等待其他线程的通知才能继续运行 进入等待态的线程会释放CPU执行权，并释放资源（如：锁） 超时等待态 运行中的线程调用sleep(time)、wait、join、parkNanos、parkUntil时进入 和等待态一样是主动进入，进入后需要其他线程唤醒 与等待态区别：到了超时时间后自动进入阻塞队列开始竞争锁 终止态：线程执行结束 waiting和blocked的区别 waiting是指线程正在等待其他线程发来的通知（notify），收到通知后可能变为runnable，也可能会再次获取锁，进而被阻塞住 blocked是指线程正在等待获取锁 synchronized会导致线程进入Blocked状态，Object.wait()导致线程进入Waiting状态，Waiting线程被其他线程调用Object.notify()唤醒之后，重新获取对象上的锁的时候也会进入Blocked状态 tips wait方法会释放CPU执行权和占有的锁 wait和notify必须配套使用，即必须使用同一把锁调用 wait和notify必须放在一个同步块中 调用wait和notify的对象必须是他们所处同步块的锁对象 sleep(time)方法仅释放CPU使用权，锁仍然占用；线程被放入超时等待队列，与yield相比它会使线程较长时间得不到运行 yield方法仅释放CPU使用权，锁仍然占用，线程会被放入就绪队列，会在短时间内再次执行 一个线程执行yield()方法暂停后，CPU决定接下来有哪一个线程执行，可以是其他线程，也可以是原来的那个线程。 join方法：等待调用join()方法的线程执行结束，程序才会继续执行下去 这个方法适用于：一个执行程序必须等待另一个线程的执行结果才能够继续运行的情况。 join()方法只有在start()方法之后才可以生效 线程的interrupt 在java的线程Thread类中有三个方法 interrupt：置线程的中断状态 作用是中断此线程（此线程不一定是当前线程，而是指调用该方法的Thread实例所代表的线程），但实际上只是给线程设置一个中断标志，线程仍会继续运行。 isInterrupt：线程是否中断 作用是只测试此线程是否被中断 ，不清除中断状态 interrupted：返回线程的上次的中断状态，并清除中断状态 作用是测试当前线程是否被中断（检查中断标志），返回一个boolean并清除中断状态，第二次再调用时中断状态已经被清除，将返回一个false。 一般来说，阻塞函数，如：Thread.sleep、Thread.join、Object.wait等在检查到线程的中断状态时，会抛出InterruptedException，同时会清除线程的中断状态 对于InterruptedException的处理，可以有两种情况： 外层代码可以处理这个异常，直接抛出这个异常即可 如果不能抛出这个异常，比如在run()方法内，因为在得到这个异常的同时，线程的中断状态已经被清除了，需要保留线程的中断状态，则需要调用Thread.currentThread().interrupt() Thread.interrupted()在jdk库的源代码中比较常用，因为它既可以得到上一次线程的中断标志值，又可以同时清除线程的中断标志，一举两得，但同时也有坏处，就是这个函数有清除中断状态的副作用，不容易理解。 可以这么理解，通过中断机制也可以实现线程的终止 中断机制就是来结束那些阻塞的线程的，因为阻塞线程回去检查中断标志位，又中断就抛异常来结束线程的运行 线程池 为什么要用线程池？ 降低消耗。降低创建和销毁线程造成的消耗 提高响应速度。任务到达时，任务可以不需要等到线程创建就能立即执行 提高线程的可管理性 参数 corePoolSize：线程池核心线程数量 如果池中线程数量少于核心线程池数量，则直接新建线程处理当前任务 当池中无空闲线程时，新任务将被添加到阻塞队列 核心线程池空闲不会被回收。 maximumPoolSize：线程池最大线程数量 当阻塞队列已满，并且有新任务还在入队时，创建新的线程处理，直到线程数大于maximumPoolSize 超出corePoolSize部分的线程超过空闲时间后会被回收 当线程已经超出maximumPoolSize，并且阻塞队列已满，则通过handler所指定的策略来处理任务。 keepAliveTime：线程存活时间 当线程超出corePoolSize时生效 workQueue：阻塞队列（存储等待执行的任务） 阻塞队列与普通队列的区别在于，当队列是空的时，从队列中获取元素的操作将会被阻塞，或者当队列是满时，往队列里添加元素的操作会被阻塞 实现方式 ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。 LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。 LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。 LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。 PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。 DelayQueue：一个使用优先级队列实现的无界阻塞队列。 threadFactory：线程工厂，用来创建线程 拒绝策略 ThreadPoolExecutor.AbortPolicy：丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 ThreadPoolExecutor FixedThreadPool：维持固定nThreads个线程的线程池 使用无界的异步阻塞队列LinkedBlockingQueue作为任务队列。 CachedThreadPool：维持最少0、最多Integer.MAX_VALUE个线程的线程池 限制线程可缓存60s，超时销毁 使用无界的同步队列SynchronousQueue作为任务队列。 SingleThreadExecutor：维持固定1个线程的FixedThreadPool。 ScheduledThreadPoolExecutor：维持固定corePoolSize个线程的线程池 使用无界的延迟队列DelayedWorkQueue作为任务队列。 SingleThreadScheduledExecutor：维持固定1个线程的ScheduledThreadPool。 ThreadLocal 用于线程间的数据隔离 使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本 内部使用ThreadLocalMap实现 Wait/Notify/NotifyAll wait( )，notify( )，notifyAll( )都不属于Thread类，而是属于Object基础类 why？ wait():线程执行wait()时，会把当前的锁释放，然后让出CPU，进入等待状态。 notify():随机唤醒一个正在等待该锁的对象 notifyAll():唤醒所有等待该锁的对象，但这些对象会竞争，只有一个获得该锁 其他的对象不会返回等待状态，除非再次调用wait()方法 会一直等到当前拥有锁的对象释放锁，然后再次竞争 锁的类型乐观锁/悲观锁 乐观锁：认为对于同一个数据的并发操作，是不会发生修改的 更新数据的时候，会采用尝试更新，不断重试的方式更新数据 CAS算法，典型例子为原子类 适合读操作非常多的场景 悲观锁：认为对于同一个数据的并发操作，一定是会发生修改的 采取加锁的形式 适合写操作非常多的场景 CAS(CompareAndSwap)算法 CAS指令执行时，当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做。整个比较并替换的操作是一个原子操作。 优点： 比加锁效率更高：因为对Atomic 变量进行操作时没有阻塞线程，而使用同步代码块时会阻塞线程，并且会造成程序的复杂性增高 缺点： 循环时间长开销大 只能保证一个共享变量的原子操作 ABA问题 如果内存地址V初次读取的值是A，并且在准备赋值的时候检查到它的值仍然为A；但是在这个过程中它的值曾经被改成了B，后来又被改回为A，那CAS操作就会误认为它从来没有被改变过。 解决方式： 带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的版本来保证CAS的正确性。 公平锁/非公平锁 公平锁：多个线程在等待同一个锁时，必须按照申请锁的先后顺序来一次获得锁 非公平锁 可能导致饿死 可重入锁/不可重入锁 可重入锁：同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。 eg: synchronized void setA() throws Exception{ Thread.sleep(1000); setB(); } synchronized void setB() throws Exception{ Thread.sleep(1000); } 不可重入锁：对于上面的例子可能造成死锁 分段锁 是一种设计,目的是细化锁的粒度 jdk7中ConcurrentHashMap就是通过分段锁来实现高效的并发操作 自旋锁 指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁 优点：减少线程上下文切换的消耗 缺点 循环会消耗CPU。 饥饿问题 如何实现自旋锁? public class SpinLock { private AtomicReference&lt;Thread&gt; cas = new AtomicReference&lt;Thread&gt;(); public void lock() { Thread current = Thread.currentThread(); // 利用CAS while (!cas.compareAndSet(null, current)) { // DO nothing } } public void unlock() { Thread current = Thread.currentThread(); cas.compareAndSet(current, null); } } 锁优化 减少锁持有的时间：对一个方法加锁，不如对方法中需要同步的几行代码加锁 减小锁粒度：ConcurrentHashMap采取对segment加锁而不是整个map加锁，提高并发性 锁分离：分为读锁和写锁 锁粗化：在一个间隔性地需要执行同步语句的线程中，如果在不连续的同步块间频繁加锁解锁是很耗性能的，因此把加锁范围扩大，把这些不连续的同步语句进行一次性加锁解锁。虽然线程持有锁的时间增加了，但是总体来说是优化了的 锁消除 JVM中：偏向锁/轻量级锁/重量级锁/自旋锁/自适应自旋锁 synchronized关键字 非公平锁、可重入锁、互斥锁 使用方式 ACC_SYNCHRONIZED 访问标志区分一个方法是否同步方法 修饰实例方法，对当前实例加锁，进入同步代码之前需要获得当前实例的锁 修饰静态方法，对当前类对象加锁，进入同步代码之前需要获得当前类对象的锁。 修饰代码块，对指定对象加锁，进入同步代码之前需要获得指定对象的锁。 通过monitorenter和monitorexit JVM对synchronized关键字的优化（状态） 偏向锁：指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。 降低获取锁的代价。 轻量级锁：指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁 不会阻塞，提高性能。 重量级锁：当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁 重量级锁会让其他申请的线程进入阻塞，性能降低。 自旋锁 锁消除：即时编译时通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁 与LOCK的区别 对于synchronized,如果多个线程都只是进行读操作，所以当一个线程在进行读操作时，其他线程只能等待无法进行读操作。Lock可以提高多个线程进行读操作的效率 Lock可以知道线程有没有成功获取到锁。synchronized不行 采用synchronized不需要用户去手动释放锁，而Lock则必须要用户去手动释放锁，如果没有主动释放锁，就有可能导致出现死锁现象。 Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现； Lock可以让等待锁的线程响应中断，而synchronized却不行 synchronized是同步阻塞，使用的是悲观并发策略，lock是同步非阻塞，采用的是乐观并发策略 ReenTrantLock 与synchronized一样都可重入，同一线程可以多次获得同一个锁 实现了Lock接口 ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 ReenTrantLock提供了一个Condition（条件）类，用来实现分组唤醒需要唤醒的线程们，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。 volatile作用 JVM提供的最轻量级的同步机制 一个变量使用volatile之后，具备两种特性： 保证此变量对所有线程的可见性：使用volatile关键字会强制将修改的值立即写入主存 符合以下两条规则才能保证原子性： 对变量的写操作不依赖于当前值 该变量没有包含在具有其他变量的不变式中。 禁止指令重排序优化 eg: //1 volatile boolean shutdownRequested; public void shutdown() { shutdownRequested = true; } public void doWork() { while (!shutdownRequested) { //do stuff } } //2 public class ChessyCounter{ @GuardedBy(&quot;this&quot;) private volatile int value; //读操作，没有synchronized，提高性能 public int getValue(){ return value } //写操作，必须synchronized。因为x++不是原子操作 public synchronized int increment() { return value++; } } //锁一次只允许一个线程访问值，volatile 允许多个线程执行读操作 //使用锁进行所有变化的操作，使用 volatile 进行只读操作。 与synchronized区别 synchronized关键字解决的是执行控制的问题，volatile关键字解决的是内存可见性的问题 volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别 volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性 volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。 BIO/NIO/AIO基础概念 同步和异步：是针对应用程序和内核的交互而言的 同步：用户进程触发IO操作并等待或者轮询的去查看IO操作是否就绪 异步：用户进程触发IO操作以后便开始做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知 阻塞和非阻塞：是针对于进程在访问数据的时候 阻塞方式：读取或者写入函数将一直等待 非阻塞方式：读取或者写入函数会立即返回一个状态值 三者区别 BIO:：同步阻塞 服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销 可以通过线程池机制改善 用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行 Java自己处理IO读写，Java调用会一直阻塞到读写完成才返回 适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中 NIO：同步非阻塞 服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理 用户进程发起一个IO操作以后边可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费 Java自己处理IO读写，但是不能读写时Java调用会马上返回，当IO事件分发器会通知可读写时再继续进行读写，不断循环直到读写完成 适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器 AIO：异步非阻塞 服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理 用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了 Java将IO读写委托给OS处理，需要将数据缓冲区地址和大小传给OS 适用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统]]></title>
    <url>%2F2019%2F02%2F27%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[进程/线程1. 进程线程区别与联系 区别： 进程是资源分配的最小单位；线程是CPU调度的最小单位 进程切换消耗资源更大 线程的划分尺度小于进程，导致多线程并发性更高 线程拥有自己独立的栈和栈指针等信息 多线程程序的并发性高 联系： 一个程序至少有一个进程，一个进程至少有一个线程 进程在执行过程中拥有独立的内存单元，而多个线程共享所在进程的内存 进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。 2. 进程间通信方式 管道：半双工，是数据只能单向流动 无名管道：只能在具有亲缘关系的进程间使用，一般指父子 有名管道：允许无亲缘关系进程间的通信。 缓冲区有限 四次数据拷贝 用户空间buf拷贝到内核中 内核将数据拷贝到内存中 内存到内核 内核到用户空间的buf 只能承载无格式字节流 信号量 消息队列 可以实现任意进程间的通信，通过系统调用函数 来实现消息发送和接收之间的同步，无需考虑同步问题，方便 信息的复制需要额外消耗CPU的时间，不适宜于信息量大或操作频繁的场合 四次数据拷贝 共享内存：同一块物理内存被映射到进程A、B各自的进程地址空间 两次数据拷贝，一次从输入文件到共享内存区，另一次从共享内存区到输出文件 共享内存时保持共享区域直到通信完毕，共享内容在解除映射时才写回文件 效率高，读写内存 共享内存段被映射进进程空间之后，存在于进程空间的数据段 套接字：可用于不同机器间的进程通信，用socket实现 3. 线程间通信方式 锁 信号量semaphore：同一时刻访问此资源的最大线程数量 信号signal：通过通知操作的方式来保持多线程同步 4. 进程的几种状态 就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源 运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数 阻塞状态： 进程等待某种条件，在条件满足之前无法执行 就绪→执行；执行→就绪；执行→阻塞；阻塞→就绪 5. 进程调度策略 FCFS先来先服务：没有考虑优先级 短作业优先：不利于长作业 高响应比优先：响应比计算系统开销，增加系统开销 时间片轮转 多级反馈队列 6. 进程同步机制 信号量 管程 内存1. 段页区别 段是信息的逻辑单位，它是根据用户的需要划分的，因此段对用户是可见的 页是信息的物理单位，是为了管理主存的方便而划分的，对用户是透明的。 段的大小不固定，有它所完成的功能决定 页的大小固定，由系统决定. 段向用户提供二维地址空间，在标识一个地址时，即需给出段名，又需给出段内地址 页向用户提供的是一维地址空间 段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制 页式虚拟存储系统存在内部碎片；段式虚拟存储系统，存在外部碎片]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络]]></title>
    <url>%2F2019%2F02%2F23%2F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[HTTP(无状态的协议)/HTTPS1. 两者区别？ HTTP是不安全的，HTTPS是安全的 OSI模型中，HTTP在应用层，HTTPS的安全传输机制在传输层 HTTP无法加密，HTTPS对传输的数据进行加密 HTTP不用证书，而HTTPS需要CA机构颁发的SSL证书 HTTPS就是HTTP加上加密处理（一般是SSL安全通信线路）+认证+消息完整性保护 2. HTTPS工作原理 双向认证 SSL 协议的具体通讯过程，服务器和用户双方必须都有证书 客户端发起HTTPS请求，服务器返回自己的证书、对称加密算法种类等信息 客户端判断服务器的CA证书是否由信任的CA中心签发，是则验证证书中的信息，不是则询问是否继续访问 客户端发送客户端证书，服务器进行相同的身份认证 服务器选择一种加密方案，使用客户端公钥加密后通知客户端 客户端通过私钥解密后得知服务器选择的加密方案，选择一个通话秘钥key，用服务器公钥加密后发给服务器 服务器收到后用私钥解密，获得通话秘钥key 接下来的数据传输都用该对称秘钥key进行加密 通过非对称秘钥机制保证双方身份认证，完成建立连接，在实际数据通信中通过对称秘钥机制保障数据安全性 双向认证 有两个或两个以上的证书，一个是服务端证书，另一个或多个是客户端证书。 一般用于企业应用对接 单向认证 客户端保存着服务端的证书并信任该证书即可 https一般是单向认证，这样可以让绝大部分人都可以访问你的站点。 3. GET与POST方法的区别？ GET重点在从服务器获取资源，POST重点在向服务器发送数据 get传输数据是通过URL请求，以field（字段）= value的形式，置于URL后，并用”?”连接，多个请求数据间用”&amp;”连接，如http://127.0.0.1/Test/login.action?name=admin&amp;password=admin 这个过程用户是可见的；post传输数据通过Http的post机制，将字段与对应值封存在请求实体中发送给服务器，这个过程对用户是不可见的； POST比GET更安全 GET产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而POST产生两个，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。 4. forward和redirect的区别 转发forward： 是服务器请求资源,服务器直接访问目标地址的URL,把那个URL的响应内容读取过来,然后把这些内容再发给浏览器 浏览器不知道服务器发送的内容从哪里来,因为这个跳转过程在服务器实现，所以客户端并不知道这个跳转动作，它的地址栏还是原来的地址 重定向： 服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址.所以地址栏显示的是新的URL 转发是服务器行为，重定向是客户端行为。 5. HTTP常见状态码 1xx:表示服务器已接收了客户端请求，客户端可继续发送请求 100：继续，允许客户端继续发送 101：转换协议 2xx:成功状态码 200：OK 202：接受，请求还未处理完 3xx:要完成请求，需要进一步操作。 通常，这些状态代码用来重定向 300：多重选择，表示被请求的文件可以在多个地方得到 4xx：用户指定客户端的错误 400：错误请求，语法错误 401：未授权 403：禁止，表示除非拥有授权，否则服务器拒绝提供所请求的资源 404：无法找到资源 5xx:用户指定服务器错误 500：服务器内部错误 502：错误的网关 504：网关超时 RESTful架构 特点 用URL描述资源 使用HTTP方法描述行为。使用HTTP状态码来表示不同的结果 使用json交互数据 是一种风格 面向资源 WebSocket 只需要服务器和浏览器通过HTTP协议进行一个握手的动作，然后单独建立一条TCP的通信通道进行数据的传送 长连接 WebSocket API是 HTML5 标准的一部分 原理 浏览器、服务器建立TCP连接，三次握手。这是通信的基础，传输控制层，若失败后续都不执行。 TCP连接成功后，浏览器通过HTTP协议向服务器传送WebSocket支持的版本号等信息。（开始前的HTTP握手） 服务器收到客户端的握手请求后，同样采用HTTP协议 回馈数据。 当收到了连接成功的消息后，通过TCP通道进行传输通信 与Http的联系 相同点： 都基于TCP，都是可靠性传输协议 都是应用层协议 不同点： WebSocket是双向通信协议(全双工) ，模拟Socket协议，可以双向发送或接受信息。HTTP是单向的。 WebSocket是需要握手进行建立连接的 WebSocket在建立握手时，数据是通过HTTP传输的。但是建立之后，在真正传输时候是不需要HTTP协议的。 与socket的联系 socket 是位于应用层和传输控制层之间(会话层)的一组接口，是为了方便使用TCP或UDP而抽象出来的一层 门面模式，把复杂的TCP/IP协议族隐藏在Socket接口后面 当两台主机通信时，必须通过Socket连接 Socket是传输控制层协议，WebSocket是应用层协议 TCP / UDP（传输层）1. TCP三次握手过程 主机A发送SYN包(同步序列号)到服务器 (SYN_SENT)，等待B确认 B收到后确认A的SYN (SYN_RCVD)，同时自己也发送一个SYN+ACK包 (ESTABLISHED) A收到SYN+ACK包后，向B发送ACK包 (ESTABLISHED)。完成三次握手，开始传输数据 三次握手特点：没有应用层的数据 三次握手漏洞： SYN FLOOD攻击：DDoS攻击，数据报特征是大量syn包，并且缺少最后一步的ACK回复。 解决办法： 无效连接监控：半开连接数和不活动连接数到达一定值时候，就释放系统资源 延缓TCB方法 Syn Cookie：用一种特殊的算法生成sequence number，算法考虑到对方的信息和己方信息，收到对方的ACK报文后，验证之后才决定是否生成TCB 2. TCP关闭：四次握手 A将FIN控制位置为1 (FIN_WAIT_1)，提出停止TCP的请求 (CLOSE_WAIT) B收到后对其作出响应，将ACK置为1 B将FIN置为1 (FIN_WAIT_2)，提出反方向的关闭请求 (LAST_ACK) A对B的请求进行确认 (TIME_WAIT)，将ACK置为1 (CLOSED) TIME_WAIT 状态是在服务端发送FIN，客户回复ACK后,为什么需要2MSL时间(报文最大生存时间)？ 为了保证最后一个ACK因丢失，而等待重发的时间 保证残留网络报不会被新连接接收而产生数据错乱。保证所有残留的网络报在自己关闭前都已经超时 3. TCP头部 16位 源端口 16位 目标端口 32位 序列号 32位 确认号 4位 头部长度：指示何处数据开始 16位 窗口大小 16位 校验和 16位 紧急指针 4. TCP如何保证可靠性传输 将数据截成合理长度 超时重发 推迟验证(对于收到的请求会给出确认响应，响应前会进行完整校验) 如果收到的检验和有差错，TCP将丢弃这个报文，并且不确认收到此报文段。然后发送数据端会超时重发 对失序数据进行重排序 丢弃重复数据 流量控制 TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据。 5.TCP粘包问题 粘包问题：发送方发送的若干包数据到接收方接收时粘成一包，从缓冲区来看，后一包的头紧接着前一包数据的尾 可能发生的场景：需要在连接后一段时间内发送不同结构数据 出现原因 发送端需要等缓冲区满才发送出去，造成粘包 接收方不及时接收缓冲区的包，造成多个包接收 不是所有的粘包现象都需要处理，若传输的数据为不带结构的连续流数据（如文件传输），则不必把粘连的包分开（简称分包）。 解决措施： 对于发送方引起的粘包：编程设置，使用TCP强制数据立即传送的指令（但是关闭了优化算法） 对于接收方引起的粘包：优化程序设计，提高接收进程优先级等（但是无法完全避免粘包现象） 由接收方控制，将一包数据按结构字段，人为控制分多次接收然后合并（效率极低） nagle算法 为了尽可能发送大块数据,避免网络中充斥着许多小数据块。 将多次间隔较小、数据量小的数据，合并成一个大的数据块，然后进行封包 6. TCP流量控制/拥塞控制 流量控制：滑动窗口 让发送方的发送速率不要太快，要让接收方来得及接收 拥塞控制：防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载 拥塞：对资源的需求超过了可用资源，造成网络性能降低 慢开始：由小到大逐渐增大拥塞窗口数值(发送方的发送窗口=拥塞窗口) 拥塞避免算法：比慢开始算法的拥塞窗口增长速率缓慢 一旦出现拥塞，将窗口大小立即置为1，执行慢开始算法 快重传和快恢复 接收方每收到一个失序的报文段后就立即发出重复确认 发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必等重传计时器到期 当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限减半，把拥塞窗口设置为慢开始门限减半后的数值，并执行拥塞避免算法 7. TCP和UDP区别 面向连接与无连接 对系统资源的要求(TCP较多，UDP少) 面向字节流和面向报文 TCP提供流量控制/拥塞控制，UDP无拥塞控制 TCP仅支持一对一 TCP保证数据正确性，UDP可能丢包，TCP保证数据顺序，UDP不保证 UDP适应于对实时要求较高、不允许有较大时延的情况，如航空信息应用。 TCP/IP的四个层次 网络接口层： 最底层，负责接收IP数据报并通过网络发送之，或者从网络上接收物理帧，抽出IP数据报，交给IP层。 网络层： 负责相邻计算机之间的通信 处理来自传输层的分组发送请求，收到请求后，将分组装入IP数据报，填充报头，选择去往信宿机的路径，然后将数据报发往适当的网络接口 处理输入数据报：首先检查其合法性，然后进行寻径——假如该数据报已到达信宿机，则去掉报头，将剩下部分交给适当的传输协议；假如该数据报尚未到达信宿，则转发该数据报 处理路径、流控、拥塞问题 传输层： 提供应用程序间的通信 格式化信息流 提供可靠传输：必须确认，丢失重发 应用层： 向用户提供一组常用的应用程序，比如电子邮件、文件传输访问、远程登录 eg: 应用层将一串应用数据流传送给传输层 传输层将应用层的数据流截成分组，并加上TCP报头形成TCP段，送交网络层 网络层给TCP段加上包括源、目的主机IP地址的IP报头，生成一个IP数据包，并将IP数据包送交给链路层 链路层在其MAC帧的数据部分装上IP数据包，再加上源、目的主机的MAC地址和帧头，并根据其目的MAC地址，将MAC帧发往目的主机或IP路由器 在目的主机，链路层将MAC帧的帧头去掉，并将IP数据包送交给网络层 网络层检查IP报头，如果报头中校验和与计算结果不一致，则丢弃该IP数据包；若校验和与计算结果一致，则去掉IP报头，将TCP段送交传输层 传输层检查顺序号，判断是否是正确的TCP分组，然后检查TCP报头数据。如正确，则向源主机发确认信息；若不正确或丢包，则向源主机要求重发信息 在目的主机，传输层去掉TCP报头，将排好顺序的分组组成应用数据流送给应用程序 RPC框架 像调用本地的函数一样去调远程函数，基于TCP SOA 面向服务的架构 DNS1. 从输入URL到页面加载发生了什么？ DNS解析： 浏览器缓存 → 操作系统缓存 → 本地hosts文件 → 本地DNS服务器 → 递归搜索UDP协议( . -&gt; .com -&gt; google.com. -&gt; www.google.com.。) TCP连接 发送http请求，服务器返回一个重定向地址 浏览器跟踪重定向地址 服务器处理http请求并返回http报文 浏览器解析、渲染页面 Session / Cookie Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中 服务器在创建了Session的同时，会为该Session生成唯一的Session id，而这个Session id在随后的请求中会被用来重新获得已经创建的Session；在Session被创建之后，就可以调用Session相关的方法往Session中增加内容了，而这些内容只会保存在服务器中，发到客户端的只有Session id；当客户端再次发送请求的时候，会将这个Session id带上，服务器接受到请求之后就会依据Session id找到相应的Session，从而再次使用之。正式这样一个过程，用户的状态也就得以保持了。 Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式 第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在 Cookie 里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器 常见应用场景：自动登录 安全性较低，以明文形式存放在浏览器中 cookie增多会增加网络带宽，session增多会占用服务器性能 cookie被禁用？ URL重写 每次HTTP交互，URL后面都会被附加上一个诸如 sid=xxxxx 这样的参数]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM整理]]></title>
    <url>%2F2019%2F01%2F19%2FJVM%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[JVM运行内存的分类 程序计数器 线程私有 当前线程所执行的字节码的行号指示器，用于记录正在执行的虚拟机字节指令地址 如果正在执行的是native方法，则为空 虚拟机栈 线程私有 每个方法被执行的时候都会同时创建一个栈帧用于存放局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程 生命周期与线程相同 为java方法服务 native方法栈 与java虚拟机栈相似 区别：为native方法服务 java堆 线程共享 JVM所管理的内存中最大的一块，在虚拟机启动时创建 唯一目的：存放对象实例、数组 GC回收的主要区域 方法区 线程共享 存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据 回收目标：主要是常量池的回收和类型的卸载 Java四大引用 强引用 如果一个对象具有强引用，那垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题 例子：Object obj = new Object(); 这里obj 就是引用，new Object() 对象实例存储在堆内存，obj引用的是对象实例的内存地址。 软引用 可以和一个引用队列（ReferenceQueue) 联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中 用来描述可用但不是必须存活的对象；在内存溢出之前，虚拟机尝试对这些对象进行回收。如果回收之后内存还是不够才会出现内存溢出情况。 弱引用 与软引用的区别：只具有弱引用的对象拥有更短暂的生命周期 被弱引用关联的对象只能生存到下一次垃圾回收发生之前。 只要垃圾回收机制在工作，无论内存是否足够，都会回收掉这部分对象。 虚引用 虚引用在任何时候都可能被垃圾回收器回收。一个对象是否被虚引用关联，完全不对其生存周期构成影响。 主要用来跟踪对象被垃圾回收器回收的活动，被回收时会收到一个系统通知。 必须 和引用队列 （ReferenceQueue）联合使用。 当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。 不能通过一个虚引用获取到一个对象实例 GC回收机制Java中对象是采用new或者反射的方法创建的，这些对象的创建都是在堆（Heap）中分配的，所有对象的回收都是由Java虚拟机通过垃圾回收机制完成的。 GC为了能够正确释放对象，会监控每个对象的运行状况，对他们的申请、引用、被引用、赋值等状况进行监控。 程序员不用担心内存管理，GC会自动进行管理。 GC标记对象的方法 引用计数法 给对象添加一个引用计数器,没当被引用的时候,计数器的值就加一。引用失效的时候减一,当计数器的值为 0 的时候就表示该对象可以被 GC 回收了， 弊端： A-&gt;B,B-&gt;A,那么 AB 将永远不会被回收了。也就是引用有环的情况 根搜索算法(可达性算法) GC Roots Tracing 通过一个叫 GC Roots 的对象作为起点,从这些结点开始向下搜索,搜索所走过的路径称为引用链,当一个对象没有与任何的引用链相连的时候则该对象就可以被回收。 根搜索算法中不可达的对象并非“非死不可”,真正宣告一个对象死亡需要两次标记过程。 第一次标记：判断是否有必要执行finalize方法 第二次标记：第一次标记过且有必要执行finalize()方法的对象，此时是对象唯一逃出去（不被回收）的机会，通过与任意对象建立关联即可，这时对象将会被移出“将被回收”的队列 GC回收的Roots包括： java虚拟机栈中引用的对象 eg: 方法里面定义这种局部变量 User user= new User(); native方法栈中引用的对象 方法区中常量引用的对象 eg: private static final User user = new User(); 方法区中静态属性引用的对象 eg: private static User user = new User(); finalize方法 gc只能清除在堆上分配的内存，而不能清除栈上分配的内存，对这类对象回收需要使用finalize方法 finalize()方法只会被调用一次，GC在回收对象之前调用该方法。 finalize方法中，可将待回收对象赋值给GC Roots可达的对象引用，从而达到对象再生的目的 finalize()是由JVM自动调用的，你可以用System.gc()，但JVM不一定会立刻执行，每个虚拟机会根据自己的策略执行。JVM感觉内存空间有限时，才会开始执行finalize() 回收算法 标记-清除 缺点：产生内存碎片 复制算法 按照容量划分二个大小相等的内存区域，当一块用完的时候将活着的对象复制到另一块上，然后再把已使用的内存空间一次清理掉 缺点：内存缩小为原来的一半 标记-整理 标记出没有用的对象，让所有存活的对象都向一端移动，然后直接清除掉端边界以外的内存 优点：解决了清除算法的内存碎片问题和复制算法的效率低下问题 分代收集算法 根据对象存活周期的不同将内存划分为几块，一般是新生代和老年代。 新生代采用复制算法，老年代采用标记-整理算法 Minor GC &amp; Full GC Minor GC通常发生在新生代的Eden区，在这个区的对象生存期短，往往发生GC的频率较高，回收速度比较快，一般采用复制回收算法 Full GC/Major GC 发生在老年代，一般情况下，触发老年代GC的时候不会触发Minor GC，所采用的是标记-清除算法/标记-整理算法 内存分配与回收策略 结构（堆大小 = 新生代 + 老年代） 新生代(1/3)(初始对象，生命周期短)：Eden 区、survivior from、survivior to（8 : 1 : 1） 老年代(2/3)(长时间存在的对象) 一般小型的对象都会在 Eden 区上分配，如果Eden区无法分配，则触发一次Minor GC,把Eden和survivor from区活着的对象放到survivor to中，然后把from和to交换位置，保证to的区域一直为空 如果survivor to不可以放入，那么直接把它们放入到老年代中，并清除Eden和survivor from，这个过程也称为分配担保（Full GC） 大对象、长期存活的对象则直接进入老年代 动态对象年龄判定 GC垃圾收集器 Serial New收集器：单线程，针对新生代的收集器，采用的是复制算法 Parallel New（并行）收集器：多线程，新生代采用复制算法，老年代采用标记整理 Parallel Scavenge（并行）收集器：多线程，针对新生代，采用复制算法 Serial Old（串行）收集器：单线程，新生代采用复制，老年代采用标记整理 Parallel Old（并行）收集器：多线程，针对老年代，标记整理 CMS收集器：基于标记-清除 G1收集器(JDK)：整体上是基于标记整理，局部采用复制 综上：新生代基本采用复制算法，老年代采用标记整理算法。cms采用标记清理 如何减少GC次数？ 对象尽量不要显式设置为null：有利于 GC 收集器判定垃圾,从而提高了 GC 的效率 少用system.gc 少用静态变量：静态变量是全局变量，不会被GC回收，但一直占用内存 尽量使用 StringBuffer,而不用 String 来累加字符串：StringBuffer是可变长的,它在原有基础上进行扩增,不会产生中间对象 使用软引用类型 SafePoint 当线程运行到这些位置时它的状态是确定的,比如记录OopMap的状态，从而确定GC Root的信息 这个点, 所有GC Root的状态都是已知并且heap里的对象是一致的; 在这个点进行GC时, 所有的线程都需要block住, 这就是(STW)Stop The World 假如一个java线程分配了一个对象A, 该对象的地址存在某个寄存器中, 然后线程的cpu时间片到期被切换出去, 同时GC的线程开始扫描存活对象, 由于没有路径到这个地址还在寄存器中的对象, 这个对象被认为是garbage, 回收了. 然后睡眠的java线程醒来了, 把寄存器中的对象地址赋值给了存活对象的某个字段, over… 所以safepoint下, heap是静止的, 并且所有活着的对象都可以被找到 如何达到safepoint？ Hotspot采用主动检测的方式使得其他线程停下来 解释执行： 指定点执行检测代码，java方法返回和跳转指令(if或者循环里面)的地方会进行检测. 编译执行： polling page访问异常触发：在需要safepoint时, 会修改该页面的权限为不可访问, 这样编译的代码在访问这个页面时, 会触发段违规异常(SEGEV). 而hotspot在启动时捕获了这个异常, 当意识到是访问polling page导致时, 则主动挂起. Oopmap 在HotSpot中，对象的类型信息里有记录自己的OopMap，记录了在该类型的对象内什么偏移量上是什么类型的数据。 在safepoint会记录Oopmap 平时这些OopMap都是压缩了存在内存里的；在GC的时候才按需解压出来使用 Java类加载机制 虚拟机把描述类的数据文件（字节码）加载到内存，并对数据进行验证、准备、解析以及类初始化，最终形成可以被虚拟机直接使用的java类型 类的生命周期 加载过程 通过一个类的全限定名来获取其定义的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在Java堆中生成一个代表这个类的java.lang.Class对象，作为对方法区中这些数据的访问入口。 验证过程 确保Class文件的字节流中包含的信息符合当前虚拟机的要求 准备过程 正式为类属性分配内存并设置类属性初始值的阶段，这些内存都将在方法区中进行分配 解析阶段 虚拟机将常量池内的符号引用替换为直接引用的过程 初始化阶段 类初始化阶段是类加载过程的最后一步。初始化阶段就是执行类构造器方法的过程 使用阶段 卸载阶段 Java类加载器 负责加载所有的类，同一个类(一个类用其全限定类名(包名加类名)标志)只会被加载一次 Bootstrap ClassLoader: 启动类加载器，负责加载java的核心类，它不是java.lang.ClassLoader的子类，而是由JVM自身实现 Extension ClassLoader: 扩展类加载器，扩展类加载器的加载路径是JDK目录下jre/lib/ext,实际上扩展类加载器的父类加载器是根加载器，只是根加载器并不是Java实现的 System ClassLoader:系统(应用)类加载器： 它负责在JVM启动时加载来自java命令的-classpath选项、java.class.path系统属性或CLASSPATH环境变量所指定的jar包和类路径。 双亲委派模型 工作原理 如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行。如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器。 如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载。 除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器 优点 Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以 避免类的重复加载 考虑到安全因素，java核心api中定义类型不会被随意替换 eg:假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class JAVA内存模型(JMM) 主要目标 定义程序中各个变量的访问规则 保证了有序性 线程对变量的所有操作（读取、 赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量 先行发生原则happens-before 如果说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、 发送了消息、 调用了方法等。]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构和排序算法]]></title>
    <url>%2F2019%2F01%2F12%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[基本排序算法 稳定性 排序前后两个相等的数相对位置不变，则算法稳定。 插入排序 直接插入排序 折半插入排序（二分法插入） 希尔排序：不稳定 直接插入排序稳定，算法复杂度：O(n²) 1234567891011public void insertionSort(int[] a) &#123; for (int i = 1; i &lt; a.length; i++) &#123; int temp = a[i]; int j = i - 1; while (j &gt;= 0 &amp;&amp; a[j] &gt; temp) &#123; a[j + 1] = a[j]; j--; &#125; a[j + 1] = temp; &#125;&#125; 折半插入排序（此处描述的是二分法查找算法）稳定，查找算法复杂度：O(logN)；排序算法复杂度：O(NlogN) 要求：1.存储在数组中（链表中不适合） 2.有序排列 在算法中属于分治算法 123456789101112131415161718192021222324252627282930313233343536373839404142434445 //递归实现 public int binarySearchRecursion(int[] array, int low, int high, int target) &#123; if (low &gt; high) return -1; int mid = (low + high) / 2; if (target &lt; array[mid]) return binarySearchRecursion(array, low, mid - 1, target); if (target &gt; array[mid]) return binarySearchRecursion(array, mid + 1, high, target); return array[mid];&#125;//非递归实现public int binarySearch(int[] array, int low, int high, int target) &#123; while (low &lt;= high) &#123; int mid = (low + high) / 2; if (target &lt; array[mid]) high = mid - 1; else if (target &gt; array[mid]) low = mid + 1; else return mid; &#125; return -1;&#125;//二分法插入public void binaryInsert(int[] array,int target)&#123; int low =0; int high = array.length-1; int[] res = new int[array.length+1]; while (low&lt;=high)&#123; int mid = (low+high)/2; if (array[mid]&lt; target) low = mid+1; else high = mid-1; &#125; for (int i=0;i&lt;low;i++) res[i]=array[i]; res[low] = target; for (int i=low+1;i&lt;res.length;i++) res[i]=array[low++]; &#125; 交换排序 冒泡排序 快速排序(不稳定) 冒泡排序稳定，算法复杂度：O(n²)；最好情况下O(n) 123456789101112public void bubbleSort(int[] a) &#123; for (int i = 0; i &lt; a.length; i++) &#123; for (int j = 1; j &lt; a.length - i; j++) &#123; if (a[j] &lt; a[j - 1]) &#123; int temp = a[j]; a[j] = a[j - 1]; a[j - 1] = temp; &#125; &#125; &#125;&#125;//算法还可以改进，从两头向中间逼近，可以加快速度 快速排序不稳定，算法复杂度：O(NlogN) 在所有同数量级的排序方法中，平均性能最好 12345678//递归实现public void quickSortRecursion(int[] arr, int low, int high) &#123; if (low &lt; high) &#123; int pivot = partition(arr, low, high); quickSortRecursion(arr, low, pivot - 1); quickSortRecursion(arr, pivot + 1, high); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334private int partition(int[] arr, int low, int high) &#123; int pivot = arr[low]; while (low &lt; high) &#123; while (low &lt; high &amp;&amp; arr[high] &gt; pivot) high--; arr[low] = arr[high]; while (low &lt; high &amp;&amp; arr[low] &lt; pivot) low++; arr[high] = arr[low]; &#125; arr[low] = pivot; return low;&#125;//非递归实现public void quickSort(int[] arr, int low, int high) &#123; Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); if (low &lt; high) &#123; stack.push(high); stack.push(low); while (!stack.empty()) &#123; int l = stack.pop(); int r = stack.pop(); int pivot = partition(arr, l, r); if (l &lt; pivot - 1) &#123; stack.push(pivot - 1); stack.push(l); &#125; if (r &gt; pivot + 1) &#123; stack.push(r); stack.push(pivot + 1); &#125; &#125; &#125;&#125; 选择排序 直接选择排序：不稳定 直接选择最小(最大)的记录与第一个记录交换位置，再对余下的n-1个进行同样操作 算法复杂度：O(n²) 存在重复做比较的情况 锦标赛排序（树形）：稳定 N个关键码两两比较，得到 n/2 个比较的优胜者(关键码小者)保留下来, 再对这 n/2个对象再进行关键码的两两比较, ……直至选出一个最小的关键码为止。 算法复杂度：O(NlogN) 堆排序：不稳定 算法复杂度：O(NlogN) 堆排序1234567891011121314151617181920212223242526272829303132333435363738394041//堆排序public void heapsort(int[] arr) &#123; for (int i = arr.length / 2; i &gt;= 0; i--) adjustHeap(arr, i, arr.length); for (int i = arr.length - 1; i &gt; 0; i--) &#123; swap(arr, 0, i); adjustHeap(arr, 0, i); &#125;&#125;/** 构建最大堆的过程 * @param arr 数组 * @param i 需要构建堆的根节点的序号 * @param n 数组长度 **/public void adjustHeap(int[] arr, int i, int n) &#123; int father; int child; for (father = arr[i]; leftChild(i) &lt; n; i = child) &#123; child = leftChild(i); // 如果左子树小于右子树，则需要比较右子树和父节点 if (child != n - 1 &amp;&amp; arr[child] &lt; arr[child + 1]) child++;//序号+1，指向右子树 // 如果父节点小于孩子结点，则需要交换 if (father &lt; arr[child]) &#123; arr[i] = arr[child]; &#125; else break;//是最大堆，无需破坏 &#125; arr[i] = father;&#125;private int leftChild(int i) &#123; return 2 * i + 1;&#125;private void swap(int[] arr, int index1, int index2) &#123; int tmp = arr[index1]; arr[index1] = arr[index2]; arr[index2] = tmp;&#125; 归并排序稳定，算法复杂度：O(NlogN) 在算法中属于分治算法 123456789//递归public void MergeSort(int[] arr, int left, int right) &#123; int mid = (left + right) / 2; if (left &lt; right)&#123; MergeSort(arr, left, mid); MergeSort(arr, mid + 1, right); merge(arr, left, mid, right); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344//merge函数实际上是将两个有序数组合并成一个有序数组//因为数组有序，合并很简单，只要维护几个指针就可以了private void merge(int[] arr, int left, int mid, int right) &#123; //temp数组用于暂存合并的结果 int[] temp = new int[right - left + 1]; //左半边的指针 int head1 = left; //右半边的指针 int head2 = mid+1; //合并后数组的指针 int index = 0; //将记录由小到大地放进temp数组 for(; head1 &lt;= mid &amp;&amp; head2 &lt;= right; index++) &#123; if(arr[head1] &lt; arr[head2]) temp[index] = arr[head1++]; else temp[index] = arr[head2++]; &#125; //接下来两个while循环是为了将剩余的（比另一边多出来的个数）放到temp数组中 while(head1 &lt;= mid) temp[index++] = arr[head1++]; while(head2 &lt;= right) temp[index++] = arr[head2++]; //将temp数组中的元素写入到待排数组中 for(int i = 0; i &lt; temp.length; i++) arr[left + i] = temp[i];&#125;//非递归private void MergeSort(int[] arr) &#123; int len = arr.length; int step = 1; //每一个区间的长度，1,2,4,8... while (step &lt;= len) &#123; int offset = 2 * step; for (int i = 0; i &lt; len; i += offset) merge(arr, i, Math.min(i + step - 1, len - 1), Math.min(i + offset - 1, len - 1)); step = offset; &#125;&#125; 基数排序 桶排序：不稳定 算法复杂度：O(n+radix) 空间复杂度：O(n+2radix) 解决Hash冲突 线性探测 二次探测 双散列 d = hash1(k) = k % len(tableSize) c = hash2(k) = R - (k % R) ;R为&lt;tableSize的质数 d+c,d+2c,d+3c….. 再散列 当表项数 &gt; 表的70% 时,可再散列. 即, 取比(2*原表长=14)大的质数17再散列 数据结构红黑树 在平衡二叉搜索树的基础上增加了着色相关的性质，这些性质保证了红黑树始终是logN的高度，从而保证了红黑树的查找、插入、删除的时间复杂度最坏为O(logN) 性质 每个结点要么是红的要么是黑的 根节点是黑的 每个叶结点(叶结点即指树尾端NIL指针或NULL结点NIL指针)都是黑的 如果一个结点是红的，那么它的两个儿子都是黑的 对于任意结点而言，其到叶结点NIL指针的每条路径都包含相同数目的黑结点 多用在内部排序，即全放在内存中的 TreeMap 就是采用红黑树存储的 MapHashMap 使用数组+链表方式实现 无序 put方法 根据当前 key 的 hashcode 定位到具体的桶中，然后再计算index 如果没有冲突就直接存 如果有冲突，以链表的形式存在后面 如果冲突导致链表过长，就把链表转为红黑树 如果节点已经存在就替换old value(保证key的唯一性) 如果桶满了，就要resize() get方法 如果是桶中的第一个节点，则直接返回value 如果有冲突，则通过key.equals(k)去查找对应的entry 若为树，O(logN) 若为链表，O(n) 1.7与1.8的区别 1.7 1.8 存储结构 数组+链表 数组+链表+红黑树 扩容后存储位置的计算方式 按照原方法(hashCode–&gt;扰动处理) 扩容后的位置=原位置or原位置+扩容量 转移数据方式 头插法(将原位置的数据后移1位再插入：逆序&amp;环形链表死循环问题) 尾插法 插入数据时机&amp;位置重计算时机 扩容前插入、转移数据时统一计算 扩容后插入、单独计算(即转移数据时无统一计算) LinkedHashMap 底层使用哈希表与双向链表来保存所有元素 重新定义了数组中保存的元素 Entry，该 Entry 除了保存当前对象的引用外，还保存了其上一个元素 before 和下一个元素 after 的引用 此链表定义了迭代顺序，该迭代顺序可以是插入顺序或者是访问顺序。 可以按照插入顺序访问 12345678910111213public static void main(String[] args) &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put("apple", "苹果"); map.put("watermelon", "西瓜"); map.put("banana", "香蕉"); map.put("peach", "桃子"); Iterator iter = map.entrySet().iterator(); while (iter.hasNext()) &#123; Map.Entry entry = (Map.Entry) iter.next(); System.out.println(entry.getKey() + "=" + entry.getValue()); &#125;&#125; 1234apple=苹果watermelon=西瓜banana=香蕉peach=桃子 按照访问顺序访问：调用get方法后，会将这次访问的元素移至链表头部，不断访问可以形成按访问顺序排序的链表。 12345678910111213141516public static void main(String[] args) &#123; Map&lt;String, String&gt; map = new LinkedHashMap&lt;String, String&gt;(16,0.75f,true); map.put("apple", "苹果"); map.put("watermelon", "西瓜"); map.put("banana", "香蕉"); map.put("peach", "桃子"); map.get("banana"); map.get("apple"); Iterator iter = map.entrySet().iterator(); while (iter.hasNext()) &#123; Map.Entry entry = (Map.Entry) iter.next(); System.out.println(entry.getKey() + "=" + entry.getValue()); &#125;&#125; 1234watermelon=西瓜peach=桃子banana=香蕉apple=苹果 允许使用 null 值和 null 键 注意，此实现不是同步的。如果多个线程同时访问链接的哈希映射，而其中至少一个线程从结构上修改了该映射，则它必须保持外部同步。 实现LRU cache 使用LinkedHashMap类有两个好处 一是它本身已经实现了按照访问顺序的存储，也就是说，最近读取的会放在最前面，最最不常读取的会放在最后（当然，它也可以实现按照插入顺序存储） 第二，LinkedHashMap 本身有一个方法用于判断是否需要移除最不常读取的数，但是，原始方法默认不需要移除（这时LinkedHashMap 相当于一个linkedlist），所以，我们需要 override 这样一个方法，使得当缓存里存放的数据个数超过规定个数后，就把最不常用的移除掉。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127import java.util.LinkedHashMap;import java.util.Collection;import java.util.Map;import java.util.ArrayList;/** * An LRU cache, based on &lt;code&gt;LinkedHashMap&lt;/code&gt;. * * &lt;p&gt; * This cache has a fixed maximum number of elements (&lt;code&gt;cacheSize&lt;/code&gt;). * If the cache is full and another entry is added, the LRU (least recently * used) entry is dropped. * * &lt;p&gt; * This class is thread-safe. All methods of this class are synchronized. * * &lt;p&gt; * Author: Christian d'Heureuse, Inventec Informatik AG, Zurich, Switzerland&lt;br&gt; * Multi-licensed: EPL / LGPL / GPL / AL / BSD. */public class LRUCache&lt;K, V&gt; &#123; private static final float hashTableLoadFactor = 0.75f; private LinkedHashMap&lt;K, V&gt; map; private int cacheSize; /** * Creates a new LRU cache. 在该方法中，new LinkedHashMap&lt;K,V&gt;(hashTableCapacity, * hashTableLoadFactor, true)中，true代表使用访问顺序 * * @param cacheSize * the maximum number of entries that will be kept in this cache. */ public LRUCache(int cacheSize) &#123; this.cacheSize = cacheSize; int hashTableCapacity = (int) Math .ceil(cacheSize / hashTableLoadFactor) + 1; map = new LinkedHashMap&lt;K, V&gt;(hashTableCapacity, hashTableLoadFactor, true) &#123; // (an anonymous inner class) private static final long serialVersionUID = 1; @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123; return size() &gt; LRUCache.this.cacheSize; &#125; &#125;; &#125; /** * Retrieves an entry from the cache.&lt;br&gt; * The retrieved entry becomes the MRU (most recently used) entry. * * @param key * the key whose associated value is to be returned. * @return the value associated to this key, or null if no value with this * key exists in the cache. */ public synchronized V get(K key) &#123; return map.get(key); &#125; /** * Adds an entry to this cache. The new entry becomes the MRU (most recently * used) entry. If an entry with the specified key already exists in the * cache, it is replaced by the new entry. If the cache is full, the LRU * (least recently used) entry is removed from the cache. * * @param key * the key with which the specified value is to be associated. * @param value * a value to be associated with the specified key. */ public synchronized void put(K key, V value) &#123; map.put(key, value); &#125; /** * Clears the cache. */ public synchronized void clear() &#123; map.clear(); &#125; /** * Returns the number of used entries in the cache. * * @return the number of entries currently in the cache. */ public synchronized int usedEntries() &#123; return map.size(); &#125; /** * Returns a &lt;code&gt;Collection&lt;/code&gt; that contains a copy of all cache * entries. * * @return a &lt;code&gt;Collection&lt;/code&gt; with a copy of the cache content. */ public synchronized Collection&lt;Map.Entry&lt;K, V&gt;&gt; getAll() &#123; return new ArrayList&lt;Map.Entry&lt;K, V&gt;&gt;(map.entrySet()); &#125; // Test routine for the LRUCache class. public static void main(String[] args) &#123; LRUCache&lt;String, String&gt; c = new LRUCache&lt;String, String&gt;(3); c.put("1", "one"); // 1 c.put("2", "two"); // 1 2 c.put("3", "three"); // 1 2 3 c.put("4", "four"); // 2 3 4 if (c.get("2") == null) throw new Error(); // 3 4 2 c.put("5", "five"); // 4 2 5 c.put("4", "second four"); // 2 5 4 // Verify cache content. if (c.usedEntries() != 3) throw new Error(); if (!c.get("4").equals("second four"))// 2 5 4 throw new Error(); if (!c.get("5").equals("five"))// 2 4 5 throw new Error(); if (!c.get("2").equals("two"))//4 5 2 throw new Error(); // List cache content. for (Map.Entry&lt;String, String&gt; e : c.getAll()) System.out.println(e.getKey() + " : " + e.getValue()); &#125;&#125; HashSet 基于HashMap实现 同样无法保证顺序 使用成员对象来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()方法用来判断对象的相等性，如果两个对象不同的话，那么返回false 比hashmap来说比较慢 LinkedHashSetHashMap与Hashtable的区别 HashMap允许将null作为一个entry的key或者value，而Hashtable不允许 HashMap不是线程安全的，而Hashtable是线程安全的 HashTable 的方法是 Synchronize 的，而 HashMap 不是，在多个线程访问 Hashtable 时，不需要自己为它的方法实现同步，而 HashMap 就必须为之提供外同步 ConcurrentHashMap jdk7中ConcurrentHashMap就是通过分段锁来实现高效的并发操作 ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。 需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道放在哪个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入 统计size的时候，即获取hashmap全局信息的时候，需要获取所有的分段锁才能统计 jdk8中改为CAS+synchronized操作，底层使用数组+链表+红黑树 并不是直接改为红黑树，而是将treeNode封装到treeBin对象中 ConcurrentHashMap 不允许空值 核心方法 initTable():在插入元素时发生，只能由一个线程完成 sizeCtl:CAS算法进行判断 扩容transfer(): step1:单线程进行，构建一个nextTable，容量为原来的两倍。 step2:允许多线程，将原来的table中的数据复制到nextTable中 Hashtable与ConcurrentHashMap的区别 Hashtable的synchronized是针对整张Hash表的，即每次锁住整张表让线程独占，ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了分段锁技术 ListArrayList 内部通过动态数组实现 当插入或删除元素时，需要对数组进行复制、移动，代价较高 适合查找和遍历 Vector 线程安全的ArrayList 访问比ArrayList慢 如果集合中的元素的数目大于目前集合数组的长度时，vector增长率为目前数组长度的100%,而arraylist增长率为目前数组长度的50%.如在集合中使用数据量比较大的数据，用vector有一定的优势。 LinkedList 是一个继承于AbstractSequentialList的双向链表。它也可以被当作堆栈、队列或双端队列进行操作。 它包含一个非常重要的内部类：Entry。Entry是双向链表节点所对应的数据结构，它包括的属性有：当前节点所包含的值，上一个节点，下一个节点。 适合删除、插入]]></content>
      <categories>
        <category>算法</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法整理]]></title>
    <url>%2F2018%2F12%2F24%2F%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[常用算法(一) 穷举法(二) 贪婪算法在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的是在某种意义上的局部最优解。 贪婪算法不能保证全局最优，所以使用贪心算法的前提是，局部最优策略能导致全局最优解。同时贪心算法必须满足无后效性，即某个状态以后的状态不会影响以前的状态。 适用情况局部最优策略能导致全局最优解 基本思路 建立数学模型来描述问题 把求解的问题分成若干个子问题 对每一子问题求解，得到子问题的局部最优解 把局部最优解合成原来问题的一个解 经典问题 霍夫曼编码 最小生成树 0/1背包问题 (三) 动态规划 动态规划过程是：每次决策依赖于当前状态，又随即引起状态的转移。一个决策序列就是在变化的状态中产生出来的。 与分治法最大的差别是：适合于用动态规划法求解的问题，经分解后得到的子问题往往不是互相独立的（即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解）。 适用情况 最优化原理：问题的最优解所包含的子问题的解也是最优的 无后效性：某阶段状态一旦确定，就不受这个状态以后决策的影响 有重叠子问题：子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到。 基本思路初始状态→│决策１│→│决策２│→…→│决策ｎ│→结束状态 划分：划分后的阶段一定要是有序的或者是可排序的 确定状态和状态变量：要满足无后效性 确定决策并写出状态转移方程：状态转移就是根据上一阶段的状态和决策来导出本阶段的状态 寻找边界条件 经典问题 N级台阶问题 最长递增子序列 (四) 分治算法把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题……直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。 适用情况 问题的复杂性随问题的规模递增 最优子结构性质 利用该问题分解出的子问题的解可以合并为该问题的解 如果不满足第三条，可以用贪心算法Or动态规划算法 子问题之间相互独立 基本思路分解-解决-合并 ###经典问题 快速排序 归并排序 二分查找 (五) 回溯法回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。 **深度优先搜索策略** 基本思路 确定问题的解空间 确定节点的扩展搜索规则 以深度优先方式搜索解空间，并在搜索过程中用剪枝函数避免无效搜索 (六) 分支界限算法回溯法的求解目标是找出T中满足约束条件的所有解，而分支限界法的求解目标则是找出满足约束条件的一个解，或是在满足约束条件的解中找出使某一目标函数值达到极大或极小的解，即在某种意义下的最优解。 **广度优先搜索策略** 分支搜索算法 FIFO搜索 LIFO搜索 优先队列式搜索]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务框架]]></title>
    <url>%2F2018%2F12%2F20%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[微服务框架Dubbohttps://github.com/Snailclimb/JavaGuide/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/dubbo.md 分布式服务框架，RPC调用 SOA Dubbo中，先通过路由，从多个 Provider 中按照路由规则，选出一个子集。再根据负载均衡从子集中选出一个 Provider 进行本次调用。如果调用失败了，根据集群容错策略，进行重试或定时重发或快速失败等。 为什么使用dubbo？ 远程接口是基于Java Interface，并且依托于spring框架方便开发。可以方便的打包成单一文件，独立进程运行，和现在的微服务概念一致。 可以为我们解决服务之间互相是如何调用的 负载均衡 服务访问压力以及时长统计、资源调度和治理：实时管理集群容量，提高集群利用率 服务降级：某个服务挂掉之后调用备用服务 负载均衡策略 随机：默认策略，按权重设置随机概率 轮询(不推荐)：按公约后的权重设置轮循比率 存在慢的提供者累积请求的问题 最少活跃调用数，相同活跃数的随机。活跃数指调用前后计数差。使慢的 Provider 收到更少请求，因为越慢的 Provider 的调用前后计数差会越大。 一致性哈希：相同参数的请求总是落在同一台机器上 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动 容错策略Dubbo 定义了集群接口 Cluster 以及及 Cluster Invoker。集群 Cluster 用途是将多个服务提供者合并为一个 Cluster Invoker，并将这个 Invoker 暴露给服务消费者。这样一来，服务消费者只需通过这个 Invoker 进行远程调用即可，至于具体调用哪个服务提供者，以及调用失败后如何处理等问题，现在都交给集群模块去处理 Failover Cluster：默认机制，失败自动切换，当出现失败，重试其它服务器。 通常用于读操作，但重试会带来更长延迟 Failfast Cluster：快速失败，只发起一次调用，失败立即报错。 通常用于非幂等性的操作，如新增记录 Failsafe Cluster：失败安全，出现异常时，直接忽略。 通常用于写入审计日志等操作 Failback Cluster：失败自动恢复，后台记录失败请求，定时重发 通常用于消息通知操作 Forking Cluster：并行调用多个服务器，只要一个成功即返回。 通常用于实时性要求较高的读操作，但需要浪费更多服务资源 Broadcast Cluster ：广播调用所有提供者，逐个调用，任意一台报错则报错。(2.1.0开始支持) 通常用于通知所有提供者更新缓存或日志等本地资源信息 dubbo健壮性的体现 zookeeper注册中心宕掉，一段时间内服务消费方还是能够调用提供方的服务的，实际上它使用的本地缓存进行通讯 监控中心宕掉不影响使用，只是丢失部分采样数据 数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务 注册中心对等集群，任意一台宕掉后，将自动切换到另一台 注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯 服务提供者无状态，任意一台宕掉后，不影响使用 服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复 服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。所以，我们可以完全可以绕过注册中心——采用 dubbo 直连 ，即在服务消费方配置服务提供方的位置信息。 zookeeperhttps://github.com/Snailclimb/JavaGuide/blob/master/%E4%B8%BB%E6%B5%81%E6%A1%86%E6%9E%B6/ZooKeeper.md 高可用的分布式管理与协调框架，只要半数以上节点存活，ZooKeeper 就能正常服务 树型(Znode)的目录服务的数据存储,数据存储在内存中 高性能：在读多于写的应用程序中尤其地高性能，因为写会导致所有的服务器间同步状态 应用场景 配置管理 集群管理：leader选举，集群容错 发布与订阅 数据库切换 分布式日志的收集 Spring Cloud学习资料汇总：http://www.ityouknow.com/springcloud/2016/12/30/springcloud-collect.html 基础组件 路由网关 Zuul：动态路由、过滤、监控、弹性伸缩和安全 服务注册和发现Eureka：提供服务注册和发现功能 Spring Cloud Consul：是一个服务发现与配置工具，与Docker容器可以无缝集成。支持健康检查，并允许HTTP和DNS协议调用API存储键值对。 网络请求RestTemplate：访问RESTful API接口的网络请求框架 负载均衡Ribbon：Ribbon作为服务消费者的负载均衡器，一种是和 RestTemplate结合，一种是和 Feign 相结合，Feign 默认集成了 Ribbon 。 声明式调用Feign：调用 Spring Cloud 服务的工具，让 Java Http 客户端调用过程变的简单。 配置中心config：将配置文件进行统一管理，可以从 Config Server 服务或 Git 仓库读取 熔断器hystrix：提供了熔断器的功能，能够阻止分布式系统中出现联动故障。 服务链路追踪Sleuth：主要功能是在分布式系统中提供服务链路追踪的解决方案。 服务监控Spring boot Admin：管理和监控一个或多个 Spring Boot 程序，使用 Spring Boot Admin 监控 Spring Cloud 微服务。 消费总线Bus：Spring Cloud Bus 将 Spring 的事件处理机制和消息中间件消息的发送和接收整合起来，可以轻松的将分布式应用中连接有消息中间件的多个服务节点连接起来，实现消息互通。 系统保护：为保证服务的安全，微服务系统需要增加安全验证，常用的方式是增加 Spring Security 或Spring OAuth2 框架来保护微服务系统。 Eureka Eureka的自我保护模式Eureka Server在运行期间，会统计心跳失败的比例在15分钟之内是否 低于85%，如果出现低于的情况（实际在 生产环境上通常是由于网络不稳定导致），Eureka Server会将当前的实例注册信息保护起来，同时提 示警告。保护模式主要用于一组客户端和Eureka Server之间存在网络分 区场景下的保护。一旦进入保护模式，Eureka Server将会尝试保护其服务注册表中的信息，不再删除服务注册表中的数据（也就是不会注销任何微服务）。所以Eureka的哲学是，同时保留”好数据“与”坏数据“总比丢掉任何”好数据“要更好，所以这种模式在实践中非常有效。 与Consul/Zookeeper比较 Eureka consul zookeeper 服务健康检查 可配支持 服务状态、内存、硬盘等 (弱)长连接，keepAlive 多数据中心 — 支持 — 一致性 — raft paxos kv存储服务 — 支持 支持 CAP AP CA CP 使用接口 http（sidecar） http和DNS 客户端 自身监控 metrics metrics — 安全 acl/https — acl Consul 强一致性(C)带来的是：服务注册相比 Eureka 会稍慢一些。因为 Consul 的 raft 协议要求必须过半数的节点都写入成功才认为注册成功 。Leader 挂掉时，重新选举期间整个 Consul 不可用。保证了强一致性但牺牲了可用性。 raft：强依赖 Leader 节点的可用性来确保集群数据的一致性。 Eureka 保证高可用(A)和最终一致性：服务注册相对要快，因为不需要等注册信息 replicate 到其它节点，也不保证注册信息是否 replicate 成功 当数据出现不一致时，虽然 A, B 上的注册信息不完全相同，但每个 Eureka 节点依然能够正常对外提供服务，这会出现查询服务信息时如果请求 A 查不到，但请求 B 就能查到。如此保证了可用性但牺牲了一致性。 Eureka 就是个 servlet 程序，跑在 servlet 容器中; Consul 则是 go 编写而成。 为什么不使用Zookeeper？ ZooKeeper是分布式协调服务，它的职责是保证数据（注：配置数据，状态数据）在其管辖下的所有服务之间保持同步、一致；（强一致性） 发现服务的核心应该是需要强调服务的高可用 正确的设置与维护ZooKeeper服务就非常的困难 集群中出现了网络分割的故障（交换机故障导致交换机底下的子网间不能互访）ZooKeeper会将它们都从自己管理范围中剔除出去，外界就不能访问到这些节点了，本身这些节点是“健康”的，能提供服务的 Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zookeeper那样使整个注册服务瘫痪。 consul的优势 由于Consul自身提供了服务端，所以我们不需要像之前实现Eureka的时候创建服务注册中心，直接通过下载consul的服务端程序就可以使用。 Consul内置了服务注册与发现框架（一站式）、具有以下性质(参考上面列表)： 分布式一致性协议实现，raft算法比paxos更直接 健康检查 K/V存储 多数据中心方案，内外网的服务采用不同的端口进行监听。 支持https和dns协议接口 Consul 客户端、服务端还支持跨中心的使用，更加提高了它的高可用性。 Consul工作原理 当 Producer 启动的时候，会向 Consul 发送一个 post 请求，告诉 Consul 自己的 IP 和 Port Consul 接收到 Producer 的注册后，每隔10s（默认）会向 Producer 发送一个健康检查的请求，检验Producer是否健康 当 Consumer 发送 GET 方式请求 /api/address 到 Producer 时，会先从 Consul 中拿到一个存储服务 IP 和 Port 的临时表，从表中拿到 Producer 的 IP 和 Port 后再发送 GET 方式请求 /api/address 该临时表每隔10s会更新，只包含有通过了健康检查的 Producer Feign Client 声明式、模板化的http客户端：封装了Http调用流程，更适合面向接口化的变成习惯 基于面向接口的动态代理方式生成实现类 根据contract协议规则解析接口类的注解信息，解析成内部表现 基于requestbean动态生成request 使用Encoder将bean转换成http报文正文(消息解析和转码逻辑) 拦截器负责对请求和返回进行装饰处理：用户自定义对请求的操作如压缩 日志记录 基于重试器发送http请求：Feign 内置了一个重试器，当HTTP请求出现IO异常时，Feign会有一个最大尝试次数发送请求 底层使用ribbon实现 支持hystrix和它的fallback 两种方式： `@FeignClient.fallback = UserFeignFallback.class`指定一个实现Feign接口的实现类。 实现方式简单，但是获取不到HTTP请求错误状态码和信息 12345678910111213@FeignClient(name = "user",url = "$&#123;user.url&#125;",fallback = UserFeignFallback.class /*fallbackFactory = UserFeignFactory.class*/)public interface UserFeign &#123; @PostMapping void save(User user); @GetMapping("/&#123;id&#125;") User getUserByID(@PathVariable("id") String id); @GetMapping List&lt;User&gt; findAll();&#125; 123456789101112131415161718192021@Componentpublic class UserFeignFallback implements UserFeign &#123; @Override public void save(User user) &#123; &#125; @Override public User getUserByID(String id) &#123; User user = new User(); user.setId("100"); user.setName("fallback 回调用户"); return user; &#125;@Override public List&lt;User&gt; findAll() &#123; return null; &#125;&#125; - `@FeignClient.fallbackFactory = UserFeignFactory.class`指定一个实现`FallbackFactory&lt;T&gt;`工厂接口类 12345678910111213141516@Componentpublic class UserFeignFactory implements FallbackFactory&lt;UserFeign&gt; &#123; private final UserFeignFallback userFeignFallback; public UserFeignFactory(UserFeignFallback userFeignFallback) &#123; this.userFeignFallback = userFeignFallback; &#125; @Override public UserFeign create(Throwable cause) &#123; //打印下异常 cause.printStackTrace(); return userFeignFallback; &#125;&#125; 1234567891011121314@FeignClient(name = "user", url = "$&#123;user.url&#125;",/*fallback = UserFeignFallback.class*/ fallbackFactory = UserFeignFactory.class)public interface UserFeign &#123; @PostMapping void save(User user); @GetMapping("/&#123;id&#125;") User getUserByID(@PathVariable("id") String id); @GetMapping List&lt;User&gt; findAll();&#125; - `ErrorDecoder`接口处理请求错误信息，默认实现`ErrorDecoder.Default`抛出`FeignException`异常。 - `FeignException.status` 方法返回HTTP状态码，`FallbackFactory.create`默认情况下可以强制转换成`FeignException`异常这样就可以获取到HTTP状态码了。 原理：https://www.kancloud.cn/onvertex/boxnew/953655 大意就是，根据@FeignClient 注解生成代理类 123456789101112131415161718192021@Overridepublic &lt;T&gt; T target(Target&lt;T&gt; target) &#123; Class&lt;T&gt; targetType = target.type(); FeignClient feignClient = AnnotatedElementUtils.getMergedAnnotation(targetType, FeignClient.class); String factoryName = feignClient.name(); SetterFactory setterFactoryBean = this.getOptional(factoryName, feignContext, SetterFactory.class); if (setterFactoryBean != null) &#123; this.setterFactory(setterFactoryBean); &#125; // 以下为获取降级策略代码，构建降级，这里去掉了降级非空的非空的校验 Class&lt;?&gt; fallback = feignClient.fallback(); if (fallback != void.class) &#123; return targetWithFallback(factoryName, feignContext, target, this, fallback); &#125; Class&lt;?&gt; fallbackFactory = feignClient.fallbackFactory(); if (fallbackFactory != void.class) &#123; return targetWithFallbackFactory(factoryName, feignContext, target, this, fallbackFactory); &#125; return build().newInstance(target);&#125; 构建feign 客户端执行PigxHystrixInvocationHandler的增强 123456Feign build(@Nullable final FallbackFactory&lt;?&gt; nullableFallbackFactory) &#123; super.invocationHandlerFactory((target, dispatch) -&gt; new PigxHystrixInvocationHandler(target, dispatch, setterFactory, nullableFallbackFactory)); super.contract(new HystrixDelegatingContract(contract)); return super.build(); &#125; PigxHystrixInvocationHandler.getFallback() 获取降级策略 123456789101112@Override @Nullable @SuppressWarnings("unchecked") protected Object getFallback() &#123; // 如果 @FeignClient 没有配置降级策略，使用动态代理创建一个 if (fallbackFactory == null) &#123; fallback = PigxFeignFallbackFactory.INSTANCE.create(target.type(), getExecutionException()); &#125; else &#123; // 如果 @FeignClient配置降级策略，使用配置的 fallback = fallbackFactory.create(getExecutionException()); &#125; &#125; Hystrix具备了服务降级、服务熔断、线程隔离、请求缓存、请求合并以及服务监控等强大功能。 服务降级：主流程走不下去时，就执行另一个方法使其看似正常。 服务熔断：类似保险丝，当一个服务请求并发特别大，服务器已经招架不住了，调用错误率飙升，当错误率达到一定阈值后，就将这个服务熔断熔断之后，后续的请求就不会再请求服务器了，以减缓服务器的压力。 线程隔离：Hystrix 采用了 Bulkhead Partition 舱壁隔离技术（），来将外部依赖进行资源隔离，进而避免任何外部依赖的故障导致本服务崩溃。 Hystrix 对每个外部依赖用一个单独的线程池，这样的话，如果对那个外部依赖调用延迟很严重，最多就是耗尽那个依赖自己的线程池而已，不会影响其他的依赖调用。 请求缓存：减轻服务器压力 请求合并：将处于一个很短时间窗（默认10毫秒）内对同一依赖服务的多个请求进行整合并以批量方式发起请求 服务监控：实时地、累加地记录所有关于HystrixCommand的执行信息，包括执行了每秒执行了多少请求，多少成功，多少失败等等 HystrixCommand采用命令模式包装依赖调用逻辑，每个命令在单独线程中/信号授权下执行。 Zuul 本身就集成了hystrix和ribbon 容错与回退 Zuul的Hystrix监控的粒度是微服务，而不是某个API Zuul提供了一个ZuulFallbackProvider接口实现回退功能 好处 将细粒度的服务组合起来提供一个粗粒度的服务 所有请求都导入一个统一的入口，那么整个服务只需要暴露一个api 对外屏蔽了服务端的实现细节，也减少了客户端与服务器的网络调用次数 功能 客户端负载：Zuul 注册于 Eureka 并集成了 Ribbon 所以自然也是可以从注册中心获取到服务列表进行客户端负载 动态路由：解放运维 监控与审查 身份认证与安全 压力测试：逐渐增加某一个服务集群的流量，以了解服务性能 服务迁移 负载裁剪：为每一个负载类型分配对应的容量，对超过限定值的请求弃用 静态应答处理 Zuul过滤器 pre：路由前。我们可利用这种过滤器实现身份验证、在集群中选择请求的微服务、记录调试信息等。 routing：路由之时。这种过滤器用于构建发送给微服务的请求，并使用Apache HttpClient或Netfilx Ribbon请求微服务。 post：路由之后。这种过滤器可用来为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。 error：其他阶段发生错误时执行该过滤器 Zuul高可用 Eureka 高可用：部署多个 Zuul 节点，并且都注册于 Eureka(有一个严重的缺点：那就是客户端也得注册到 Eureka 上才能对 Zuul 的调用做到负载，这显然是不现实的。) 基于 Nginx 高可用：在调用 Zuul 之前使用 Nginx 之类的负载均衡工具进行负载，这样 Zuul 既能注册到 Eureka ，客户端也能实现对 Zuul 的负载 API网关比较NGINX vs. ZUUL vs. Spring Cloud Gateway vs. Linkerd https://juejin.im/entry/5ad408de6fb9a028cc61af94 Spring Cloud Config 优点 部署极其简单：同一个上线包，无须改动配置，即可在多个环境中(RD/QA/PRODUCTION) 上线 部署动态化：更改配置，无需重新打包或重启，即可实时生效 统一管理：提供web平台，统一管理 多个环境(RD/QA/PRODUCTION)、多个产品 的所有配置 支持微服务架构 服务端：负责将git svn中存储的配置文件发布成REST接口 客户端：可以从服务端REST接口获取配置，客户端并不能主动感知到配置的变化，从而主动去获取新的配置,由消息总线来通知各个Spring Cloud Config的客户端去服务端更新配置。 Spring Cloud Busspring cloud config手动刷新只能针对单个服务。消息总线可以用来广播式自动刷新。通过RabbitMQ或kafka 加 Git的Webhooks來触发配置的更新 Spring Cloud Bus 事件处理机制和消息中间件消息的发送和接收整合起来，主要由发送端、接收端和事件组成。针对不同的业务需求，可以设置不同的事件，发送端发送事件，接收端接受相应的事件，并进行相应的处理，用于实现微服务之间的通信。本质是利用了MQ的广播机制在分布式的系统中传播消息 。]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
</search>
