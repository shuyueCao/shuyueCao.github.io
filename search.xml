<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[spring]]></title>
    <url>%2F2019%2F09%2F14%2Fspring%2F</url>
    <content type="text"><![CDATA[Spring 优点 轻量 控制反转 AOP 容器：Spring 包含并管理应用中对象的生命周期和配置 MVC框架 事务管理：Spring 提供一个持续的事务管理接口，可以扩展到上至本地事务下至全局事务 异常处理： 提供方便的API把具体技术相关的异常（比如由JDBC，Hibernate or JDO抛出的）转化为一致的unchecked 异常 缺点 jsp中要写很多代码、控制器过于灵活，缺少一个公用控制器 不支持分布式，这也是EJB仍然在用的原因之一 IoC 控制反转是一种通过描述并通过第三方去产生或获取特定对象的方式。在Spring中实现控制反转的是IoC容器，其实现方法是DI（依赖注入） 解决了类与类之间的依赖关系。程序员将控制类与类之间依赖的权利交给了IOC 比如说我们现在有两个类A和B，那么我们不需要new A()、或者new B()来创建A和B的对象，Spring会帮我们创建A和B的对象（默认是单例），并且把A和B的对象放入IoC容器中，如果B对象中需要用到A对象的话，那么就要用到DI，Spring会帮我们把A对象注入到B对象中，一般是通过setter方法注入或构造器注入。 在Spring中，有两个主要的IoC容器系列 实现BeanFactory接口的简单容器系列 BeanFactory容器中，不会调用ApplicationContextAware接口的setApplicationContext()方法 BeanPostProcessor接口的postProcessBeforeInitialzation()方法和postProcessAfterInitialization()方法不会自动调用，必须自己通过代码手动注册 BeanFactory容器启动的时候，不会去实例化所有Bean,包括所有scope为singleton且非懒加载的Bean也是一样，而是在调用的时候去实例化 实现ApplicationContext接口的高级容器系列 在BeanFatory容器的基础上增加了事件传播、资源访问和国际化的消息访问等功能 在容器启动时会实例化scope为singleton且非懒加载的bean IoC容器的初始化： 入口是在构造方法中调用refresh开始的 通过ResourceLoader来完成资源文件位置的定位 通过BeanDefinitionReader来完成定义信息的解析和Bean信息的注册，XmlBeanDefinitionReader是BeanDefinitionReader的实现类，通过它来解析xml配置中的bean定义 BeanDefinition的载入：把用户定义好的Bean表示成IoC容器内部的数据结构，即BeanDefinition。 BeanDefinition的注册：把BeanDefinition向IoC容器注册，由BeanDefinitionRegistry实现的registerBeanDefiition方法进行。内部使用ConcurrentHashMap来保存BeanDefiition 在解析元素过程中没有创建和实例化Bean对象，只是创建了Bean对象的定义类BeanDefinition，将元素中的配置信息设置到BeanDefinition中作为记录，当依赖注入时才使用这些记录信息创建和实例化具体的Bean对象。 依赖注入的过程(lazy-init)： 依赖注入的过程是用户第一次向IoC容器索要Bean时触发的，在BeanFatory接口中的getBean方法的实现就是触发依赖注入的地方。 Bean定义为单例模式(Singleton)，则容器在创建之前先从缓存中查找，以确保整个容器中只存在一个实例对象。如果Bean定义的是原型模式(Prototype)，则容器每次都会创建一个新的实例对象。除此之外，Bean定义还可以扩展为指定其生命周期范围 依赖注入主要在两个方法中： createBeanInstance：生成Bean所包含的java对象实例。 用CGLIB来生成 通过BeanUtils，它使用了JVM的反射功能来生成Java对象实例 populateBean ：对Bean属性的依赖注入进行处理 属性值类型不需要转换时，不需要解析属性值，直接准备进行依赖注入。 属性值需要进行类型转换时，如对其他对象的引用等，首先需要解析属性值(resolveValueIfNecessary方法)，然后对解析后的属性值进行依赖注入 setPropertyValues 属性注入 获取到某个Bean的时候也会通过递归的方式来依赖注入依赖的bean 依赖注入的方式 @autowired 注解 setter方法： 要在&lt;bean&gt; 标签中创建一个 &lt;property&gt; 标签 ref指向其他&lt;bean&gt;标签的name属性 构造器注入 不用的形式，而是使用标签 ref指向其他&lt;bean&gt;标签的name属性 静态工厂的方法 工厂初始化之前，工厂中的类就已经被实例化放在工厂容器中 ref指向静态工厂 配置 factory-method=”…”指定调用哪个工厂方法 实例工厂的方法 工厂在构造方法初始化时，将类实例化放在工厂中 先有bean工厂，再bean一个具体类 需要首先new工厂类，再调用普通的实例方法 Spring IoC容器中管理了一系列靠依赖关系联系起来的Bean，程序不需要应用自己手动创建所需的对象，Spring IoC容器会在我们使用的时候自动为我们创建，并且为我们注入好相关的依赖 循环依赖 三级缓存 第一级缓存singletonObjects：放置实例化好的单例对象 第二级缓存earlySingletonObjects：放置提前曝光的单例对象（没有完全装配好） 第三级缓存singletonFactorys：存放的是要被实例化的对象的对象工厂 bean的生命周期 容器启动后，会对scope为singleton且非懒加载的bean进行实例化 按照Bean定义信息配置信息，注入所有的属性 如果实现了BeanNameAware接口，会回调该接口的setBeanName()方法，传入该Bean的id，此时该Bean就获得了自己在配置文件中的id 如果Bean实现了BeanFactoryAware接口，会回调该接口的setBeanFactory()方法，传入该Bean的BeanFactory，这样该Bean就获得了自己所在的BeanFactory 如果Bean实现了ApplicationContextAware接口,会回调该接口的setApplicationContext()方法，传入该Bean的ApplicationContext，这样该Bean就获得了自己所在的ApplicationContext 如果有Bean实现了BeanPostProcessor（实例化后置处理器）接口，则会回调该接口的postProcessBeforeInitialzation()方法 如果Bean实现了InitializingBean接口，则会回调该接口的afterPropertiesSet()方法 如果Bean配置了init-method方法，则会执行init-method配置的方法 如果有Bean实现了BeanPostProcessor接口，则会回调该接口的postProcessAfterInitialization()方法 之后便可以正式使用Bean了，对于scope为singleton的Bean,Spring的ioc容器中会缓存一份该bean的实例，而对于scope为prototype的Bean,每次被调用都会new一个新的对象，期生命周期就交给调用方管理了，不再是Spring容器进行管理了 容器关闭后，如果Bean实现了DisposableBean接口，则会回调该接口的destroy()方法 如果Bean配置了destroy-method方法，则会执行destroy-method配置的方法，至此，整个Bean的生命周期结束 AOP spring AOP的底层实现是动态代理 提供了对JDK动态代理的支持以及CGLib的支持。 JDK动态代理只能为接口创建动态代理实例，而不能对类创建动态代理 CGLib动态代理需要依赖asm包，把被代理对象类的class文件加载进来，修改其字节码生成子类。 AspectJ的底层技术是静态代理 通过一个命令来编译，生成一个新的代理类 在编译时增强 事务管理 spring并不直接管理事务，而是提供了多种事务管理器，将事务管理的职责委托给Hibernate或者JTA等持久化机制所提供的相关平台框架的事务来实现 PlatformTransactionManager接口为各个平台提供了对应的事务管理器 getTransaction() commit() rollback() 优点 为不同的事务API提供一致的编程模型，如JTA、JDBC、Hibernate、JPA Spring MVC工作原理 Http请求：客户端请求提交到前置控制器DispatcherServlet DispatcherServlet寻找处理器Controller：由DispatcherServlet控制器查询一个或多个HandlerMapping，找到处理请求所对应的Controller 处理器Controller执行：DispatcherServlet将请求提交到Controller，Controller调用业务逻辑处理后，返回ModelAndView。 dispatcherServlet借助ViewResoler完成逻辑视图到真实视图对象的解析 dispatcherServlet使用这个view对ModelAndView中的模型数据进行视图渲染，返回给用户 Spring Boot 主要是简化了spring的难度，简省了繁重的配置，提供了各种容器，开发者能快速上手 优点 独立运行 内嵌了各种servlet容器，Tomcat、Jetty等 不再需要打成war包部署到容器中，Spring Boot只要打成一个可执行的jar包就能独立运行，所有的依赖包都在一个jar包内。 简化配置 spring-boot-starter-web启动器自动依赖其他组件，简少了maven的配置 自动配置 Spring Boot能根据当前类路径下的类、jar包来自动配置bean，如添加一个spring-boot-starter-web启动器就能拥有web的功能，无需其他配置。 无代码生成和XML配置 Spring Boot配置过程中无代码生成，也无需XML配置文件就能完成所有配置工作，这一切都是借助于条件注解完成的 应用监控 Spring Boot提供一系列端点可以监控服务及应用，做健康检测。 核心注解 @SpringBootConfiguration：组合了 @Configuration 注解，实现配置文件的功能。 @EnableAutoConfiguration：打开自动配置的功能，也可以关闭某个自动配置的选项 @ComponentScan：Spring组件扫描 如何理解 Spring Boot 中的 Starters Starters可以理解为启动器，它包含了一系列可以集成到应用里面的依赖包，你可以一站式集成 Spring 及其他技术，而不需要到处找示例代码和依赖包。 SSH/SSM SSH：structs2(控制器)+spring(管理各层组件)+hibernate(持久化层) Struts2是Action类级别 SSM：SpringMVC(控制器)+spring(管理各层组件)+mybatis(持久化层) SpringMVC是方法级别，更容易实现RESTful风格 Structs2工作原理Struts2使用Filter嵌入 客户端初始化一个指向Servlet容器（例如Tomcat）的请求，这个请求经过一系列的过滤器（Filter） 接着FilterDispatcher被调用，FilterDispatcher询问ActionMapper来决定这个请求是否需要调用Action FilterDispatcher把处理权交给ActionProxy，ActionProxy通过Configuration Manager询问框架的配置文件，找到需要调用的Action类 ActionProxy创建一个ActionInvocation的实例 ActionInvocation实例使用命名模式来调用，在调用Action的过程前后，涉及到相关拦截器（Intercepter）的调用 一旦Action执行完毕，ActionInvocation负责根据struts.xml中的配置找到对应的返回结果。返回结果通常是（但不总是，也可 能是另外的一个Action链）一个需要被表示的JSP或者FreeMarker的模版 将处理结果返回给客户端 Servlet 是运行在服务端的java程序，为java程序提供一个统一的web应用的规范 一个http请求到来，容器将请求封装成Servlet中的request对象，在request中可以得到http的所有信息，并将其取出进行操作 最后将数据封装成Servlet中的response对象，容器将response解析后封装成http response Tomcat是一个servlet容器 生命周期 初始化阶段init()：init方法只会被调用一次 Servlet容器启动时自动装载某些servlet 在Servlet容器启动后，客户首次向Servlet发送请求 Servlet类文件被更新后，重新装载 处理客户请求阶段service()：每收到一个客户端请求，服务器就会产生一个新的线程去处理 对于用户的Servlet请求，Servlet容器会创建一个特定于请求的ServletRequest和ServletResponse service()方法会对请求的方法进行匹配 对于tomcat来说，它会将传递来的参数放入一个HashTable中，这是一个String–&gt;String[]的键值映射 终止阶段destroy() 当web应用被终止，或者Servlet容器终止运行，或者Servlet重新装载Servlet新实例时，Servlet容器会调用Servlet的destroy()方法]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java基础]]></title>
    <url>%2F2019%2F03%2F26%2Fjava%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Java反射机制 What? 动态加载对象，并对对象进行剖析 在运行状态中，对于任意一个类，都能知道它的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法 动态获取信息以及动态调用对象方法的功能称为Java反射机制 优缺点 优点 提高了程序的灵活性和扩展性：可以实现动态创建对象和编译 底层框架中用的比较多，业务层少用 缺点 性能不好：反射是一种解释操作，用于字段和方法接入时要远远慢于直接代码 程序逻辑有影响：会模糊化程序的内部逻辑 使用场景 实现RPC框架 实现ORM框架 拷贝属性值(BeanUtils.copyProperties) Java代理机制 静态代理：编译时实现 编译后代理类是一个class文件 动态代理：运行时生成 在运行时动态生成的类字节码，并加载到JVM中]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[项目]]></title>
    <url>%2F2019%2F03%2F06%2F%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[DevOps工具链DevOps 通过高度自动化工具与流程来使得软件构建、测试、发布更加快捷、频繁和可靠 将开发、运维一体化 可以把 DevOps 看作开发（软件工程）、技术运营和质量保障（QA）三者的交集。 传统的软件组织将开发、IT 运营和质量保障设为各自分离的部门， 按照从前的工作方式，开发和部署，不需要 IT 支持或者 QA 深入的跨部门的支持；而现在却需要极其紧密的多部门协作。 而 DevOps 考虑的还不止是软件部署，它是一套针对这几个部门间沟通与协作问题的流程和方法。 好处 代码的提交直接触发：消除等待时间，快速反馈 每个变化对应一个交付管道：使问题定位和调试变得简单 全开发流程高效自动化：稳定，快速，交付结果可预测 持续进行自动化回归测试：提升交付质量 持续集成 频繁地（一天多次）将代码集成到主干 让产品可以快速迭代，同时还能保持高质量 持续交付 频繁地将软件的新版本，交付给质量团队或者用户，以供评审。 持续部署 持续交付的下一步，指的是代码通过评审以后，自动部署到生产环境。 工具链 代码托管：gitlab 为什么不使用github？ gitlab对仓库有更多的控制，可以设置仓库权限是公用的还是私有的 每一次的提交或者 Merge Request 的合并都可以触发pipeline 持续集成 gitlabCI：集成较好， 界面美观优雅， 使用简单 gitlab runner进行构建任务，gitlabCI负责管理各个项目的构建状态 runner需要注册到CI中，可以安装到不同的机器上，因此构建任务期间不会影响gitlab的性能 pipeline：相当于一次构建任务，里面可以包含多个流程，比如自动构建、自动进行单元测试、自动进行代码检查等流程 stages： build, test, deploy jobs 包含实时构建日志，容易追踪 Jenkins 通过gitlab的webhook设置，自动触发构建工作，就不需要人工干预了 jenkins在项目配置时可以配置远程构建触发器，设置好jenkins的回调url后就可以让jenkins进行自动构建。 jenkins将代码打成docker镜像，push到docker-registry 静态代码检查：sonarqube Sonar GitLab Plugin 插件 该插件会针对每次提交修改的文件，添加注释行，同时添加本次提交的代码检测结果的评论 配合 gitlab-ci 完成每次 commit 时，添加的代码检测 Pipelines stage 流程，来控制代码检测流程是否通过 检查范围： 不遵循代码标准 重复 潜在的缺陷 质量糟糕的复杂度分布 注释不足或过多 缺乏单元测试 糟糕的设计 PMD,checkstyle，findbugs等代码规则检测工具规范代码编写/检测出潜在的缺陷 可以很方便地统计并展示单元测试覆盖率 项目部署：docker 使用GitLab runner 来 build docker image上传到仓库中 为了要让 runner 可以调用 docker 命令, 需要把 gitlab-runner 这个用户加入 docker 所在组.]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库]]></title>
    <url>%2F2019%2F03%2F03%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[Redis key-value类型的内存(缓存)数据库 整个数据库加载到内存中操作，定期flush到硬盘上进行保存 单线程 CPU不是瓶颈，单线程容易实现 集群是master/slave模式 为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有N-1个复制品 异步复制 Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。 与memchached的区别 memchached仅支持string类型，Redis支持更丰富的数据类型且能提供对他们的原子操作 Redis速度更快 Redis可以持久化 支持的数据类型和底层实现 在Redis中，所有key-value对都存储在一个hash table中 Hash table是一个二维结构 一个一维固定长度的数组，每个槽位上保存一个dictEntry对象。key计算hash值后按照这个定长数组求模，结果相同的key-balue通过链表保存在同一个槽位上，这样便形成了一个二维结构 String 能存为整数则存为整数，不能则存为原始字符串 一个字符串类型的值能存储的最大容量是512M List 使用 zip List结构 zip list通过一个连续的内存块实现list结构，其中的每个entry节点头部保存前后节点长度信息，实现双向链表功能 当list内容较多时，使用双向链表 hash 新建的Hash类型也使用zip list存储value 保存数据过多时，转而使用hash table set 创如果value能够表示为整数，则使用intset类型保存value。intset使用和ziplist相似的实现方式保存整数 数据量大时，切换为使用hash table 使用场景 会话缓存 队列 发布/订阅 排行榜/计数器 如何做内存优化？ 使用hashes(散列表)，散列表（是说散列表里面存储的数少）使用的内存非常小 比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key,而是应该把这个用户的所有信息存储到一张散列表里面. Redis是单线程，如何提高CPU利用率？ 可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用 持久化 如何进行？ bgsave 做镜像全量持久化 fork 和 cow，创建子进程进行bgsave操作，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来 耗费较长时间，不够实时，在停机的时候会导致大量丢失数据 aof 做增量持久化 在 redis 实例重启时，会使用 bgsave 持久化文件重新构建内存，再使用 aof 重放近期的操作指令来实现完整恢复重启之前的状态。 方式 RDB持久化方式能够在指定的时间间隔能对数据进行快照存储 AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据 AOF命令以redis协议追加保存每次写的操作到文件末尾 Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大 定时生成RDB快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外， 使用RDB还可以避免之前提到的AOF程序的bug。 如何解决缓存一致性问题？ 延时双删策略 先淘汰缓存 再写数据库 休眠一段时间，再淘汰缓存，可以将这段时间内造成的脏数据删除 先更新数据库，再删除缓存 如何扩容？ 被当做缓存：一致性哈希实现动态扩容 集群方案 twemproxy，类似代理。设置好它下属的多个redis实例后，使用时在本需要连接redis的地方改为连接twemproxy，它会以一个代理的身份接收请求并使用一致性hash算法(对2^32取模)，将请求转接到具体redis 使用方式简便(相对redis只需修改连接端口)，对旧项目扩展的首选 twemproxy自身单端口实例的压力，使用一致性hash后，对redis节点数量改变时候的计算值的改变，数据无法自动移动到新的节点。 codis，基本和twemproxy一致的效果，但它支持在 节点数量改变情况下，旧节点数据可恢复到新hash节点 redis cluster3.0自带的集群，分布式算法不是一致性hash，而是hash槽的概念，以及自身支持节点设置从节点 同步机制 主从同步，从从同步 第一次同步时，主节点做一次 bgsave，并同时将后续修改操作记录到内存buffer，待完成后将RDB文件全量同步到复制节点，复制节点接受完成后将RDB镜像加载到内存 加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放 分区 实现方案 客户端分区：在客户端就已经决定数据会被存储到哪个redis节点或者从哪个redis节点读取。大多数客户端已经实现了客户端分区。 代理分区：客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据 查询路由(Query routing) ：客户端随机地请求任意一个redis实例，然后由Redis将请求转发给正确的Redis节点。 缺点： 涉及多个key的操作通常不会被支持，同时操作多个key,则不能使用Redis事务 数据处理会变复杂：备份必须从不同的Redis实例和主机同时收集RDB / AOF文件 分区时动态扩容或缩容可能非常复杂，Redis集群在运行时增加或者删除Redis节点，能做到最大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持这种特性 常见性能问题和解决方案 Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2 &lt;- Slave3…这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。 MySQL存储引擎https://draveness.me/mysql-innodb InnoDB 所有的数据都被逻辑地存放在表空间中，表空间（tablespace）是存储引擎中最高的存储逻辑单位，在表空间的下面又包括段（segment）、区（extent）、页（page） 页作为磁盘管理的最小单位,在页中数据按行存储。 MySQL 使用 InnoDB 存储表时，会将表的定义和数据索引等信息分开存储 B+ 树索引并不能找到一个给定键对应的具体值，它只能找到数据行对应的页，然后数据库把整个页读入到内存中，并在内存中查找具体的数据行。 聚集索引/主键索引 存放着一条行记录的全部信息 辅助索引 只包含索引列和一个用于查找对应行记录的主键值。 InnoDB与MYlSAM区别两者都是MySQL中最常用的两个表类型 MyISAM类型不支持事务处理等高级处理，而InnoDB类型支持(提交、回滚和崩溃恢复能力) MyISAM类型的表强调的是性能，其执行速度比InnoDB类型更快 InnoDB的数据文件本身就是索引文件，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址 InnoDB 中不保存表的具体行数，也就是说，执行select count(*) from table时，InnoDB要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当count(*)语句包含 where条件时，两种表的操作是一样的。 两种类型最主要的差别就是Innodb 支持事务处理与外键完整性约束和行级锁，所以MyISAM往往就容易被人认为只适合在小项目中使用,但是如果项目要求99.9%的稳定性，方便的扩展性和高可用性来说的话，MyISAM绝对是首选 MySQL主从同步 基于二进制日志机制，主服务器使用二进制日志来记录数据库的变动情况，从服务器通过读取和执行该日志文件来保持和主服务器的数据一致 MySQL是异步复制的，MySQL cluster是同步复制的 优点 可以作为一种备份机制，相当于热备份 可以用来做读写分离，均衡数据库负载 方法 tatement Based Replication（SBR）基于SQL语句的复制 当使用二进制日志时，主服务器会把SQL语句写入到日志中，然后从服务器会执行该日志 日志文件更小 记录了所有的语句，可以用来日后审计 Insert … select语句会执行大量的行级锁表 Update语句会执行大量的行级锁表来扫描整个表 Row Based Replication（RBR）基于行的复制 主服务器把表的行变化作为事件写入到二进制日志中，主服务器把代表了行变化的事件复制到从服务中 所有的数据变化都是被复制，这是最安全的复制方式 更少的行级锁表 日志会很大 索引 索引 原理 对要查询的字段建立索引其实就是把该字段按照一定的方式排序；建立的索引只对该字段有用，如果查询的字段改变，那么这个索引也就无效了 优点 加快数据检索速度，提高对数据访问效率 提高数据查询性能 缺点 占用大量硬盘空间 数据的增删改等更新操作，需要维护索引时间，降低更新速度 适用场合 主键列中创建索引 多表连接时连接列创建索引 where子句查询的列 需要经常GROUP BY和ORDER BY的列 类型 主键索引 普通索引/单列索引 多列索引/复合索引 使用复合索引时遵循最左前缀原则 最左前缀原则 b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+树是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道第一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。 最左优先，先要看第一列，在第一列满足的条件下再看左边第二列，以此类推 eg: 多列字段做索引，state/city/zipCode，想要索引生效的话，只能使用如下的组合：state/city/zipCode，state/city，state。其他方式（如city，city/zipCode），则索引不会生效 MySQL索引 B+树 特点 非叶子节点的子树指针与关键字个数相同 非叶子节点不存储数据，只存储指针索引(稀疏索引)；叶子节点存储所有关键字数据(稠密索引)，不存储指针 在经典B+树基础上增加了顺序访问指针，每个叶子节点都有指向相邻下一个叶子节点的指针 提高区间访问的性能 更适合文件系统 为什么说B+树比B树更适合数据库索引？ B+树的磁盘读写代价更低 B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了 B+树的查询效率更加稳定 任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。 方便扫库 由于B+树的数据都存储在叶子结点中，分支结点均为索引，只需要扫一遍叶子结点即可 范围扫描更简单 内部节点可以定位更多叶子节点 MyISAM中的B+树 叶子节点的数据区域存储的是数据记录的地址 在使用索引查询数据时，会先根据索引查找到数据地址，再根据地址查询到具体的数据 主键索引和辅助索引没有太多区别 InnoDB中的B+树 主键索引的叶子节点的数据区域存储的是数据记录 辅助索引存储的是主键值 Innodb的一个表一定要有主键索引，如果一个表没有手动建立主键索引，Innodb会查看有没有唯一索引，如果有则选用唯一索引作为主键索引，如果连唯一索引也没有，则会默认建立一个隐藏的主键索引（用户不可见）。 Innodb的主键索引要比MyISAM的主键索引查询效率要高（少一次磁盘IO），并且比辅助索引也要高很多。所以，我们在使用Innodb作为存储引擎时，我们最好： 手动建立主键索引 尽量利用主键索引查询 SQL优化 重写order by语句以使用索引 SELECT子句中避免使用 ‘ * ‘ 减少访问数据库的次数 用Where子句替换HAVING子句/order by 通过内部函数提高SQL效率 用EXISTS替代IN、用NOT EXISTS替代NOT IN 使用索引 避免在索引列上使用NOT 避免在索引列上使用计算 事务 概念 指访问并可能更新数据库中各种数据项的一个程序执行单元 对数据库进行读或写的一个操作序列 特性 原子性(A):事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。 一致性(C):事务应确保数据库的状态从一个一致状态转变为另一个一致状态。 隔离性(I):一个事务的执行不应影响其他事务的执行 持久性(D):一个事务一旦提交，他对数据库的修改应该永久保存在数据库中。 事务隔离级别 脏读 当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。 不可重复读 指在一个事务内，多次读同一数据。两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的 幻读 第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。 同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象 发生了幻觉一样。 级别 Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。 四级封锁协议：其他事务不能 读写 该表中的任何数据 Repeatable read (可重复读)：可避免脏读、不可重复读的发生。 三级封锁协议：一级封锁协议加上事务T在读取数据R之前必须先对其加S锁，直到事务结束才释放 Read committed (读已提交)：可避免脏读的发生。 二级封锁协议：一级封锁协议加上事务T在读取数据R之前必须先对其加S锁，读完后即可释放S锁 （瞬间S锁）。 Read uncommitted (读未提交)：最低级别，任何情况都无法保证。 一级封锁协议：事务T在修改数据R之前必须先对其加X锁，直到事务结束才释放。 锁(InnoDB) 种类 排他锁/写锁/x锁 事务T可以修改A也可以读A，其他事务不能再对A加任何锁，直到事务T释放A上的锁 共享锁/读锁/s锁 其他事务可以读A，而在事务T释放A上的S锁之前不能对A进行修改 现象 死锁 互相等待 形成条件 互斥：排它性 请求和保持：对自己已获得的其它资源保持不释放 不剥夺：不能被剥夺，只能在使用完时由自己释放 循环等待 预防和解除 预防：破坏四个条件之一 避免：银行家算法 解除 剥夺资源 活锁 某一个事务T可能饿死(永远等待) 避免活锁的简单方法是采用先来先服务的策略。 并发控制机制 乐观锁：是一种思想 会先尝试对资源进行修改，在写回时判断资源是否进行了改变，如果没有发生改变就会写回，否则就会进行重试，在整个的执行过程中其实都没有对数据库进行加锁 悲观锁：是一种锁 在获取资源前对资源进行加锁，确保同一时刻只有有限的线程能够访问该资源，其他想要尝试获取资源的操作都会进入等待状态，直到该线程完成了对资源的操作并且释放了锁后，其他线程才能重新操作资源 乐观锁不会存在死锁的问题，但是由于更新后验证，所以当冲突频率和重试成本较高时更推荐使用悲观锁，而需要非常高的响应速度并且并发量非常大的时候使用乐观锁就能较好的解决问题 锁的算法 记录锁(record lock):加到索引记录上的锁 间隙锁(gap lock):对索引记录中的一段连续区域的锁 当使用类似 SELECT * FROM users WHERE id BETWEEN 10 AND 20 FOR UPDATE; 的 SQL 语句时，就会阻止其他事务向表中插入 id = 15 的记录，因为整个范围都被间隙锁锁定了 间隙锁是存储引擎对于性能和并发做出的权衡，并且只用于某些事务隔离级别 虽然间隙锁中也分为共享锁和互斥锁，不过它们之间并不是互斥的，也就是不同的事务可以同时持有一段相同范围的共享锁和互斥锁，它唯一阻止的就是其他事务向这个范围中添加新的记录 Next-key lock:是前两者的结合 Next-Key 锁锁定的是当前值和前面的范围。 当我们更新一条记录，比如 SELECT * FROM users WHERE age = 30 FOR UPDATE;，InnoDB 不仅会在范围(21, 30] 上加 Next-Key 锁，还会在这条记录后面的范围 (30, 40] 加间隙锁，所以插入 (21, 40] 范围内的记录都会被锁定。 解决幻读的问题 分布式事务https://zhuanlan.zhihu.com/p/41725894 CAP定理 一致性(Consistence):等同于所有节点访问同一份最新的数据副本 可用性(Availability):每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据 分区容错性(Partition tolerance):以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择 分布式系统只能满足三项中的两项而不可能满足全部三项 BASE理论 基本可用(BasicallyAvailable):分布式系统在出现不可预知故障的时候，允许损失部分可用性 响应时间上的损失 功能上的损失：正常情况下，在一个电子商务网站上进行购物，消费者几乎能够顺利地完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。 软状态(Softstate):允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据听不到的过程存在延时。 最终一致性(Eventuallyconsistent):需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性 分布式解决方案 二阶段提交（2PC） 参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作 补偿事务（TCC） 针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作 降低锁冲突、提高吞吐量成。 与2PC相比实现以及流程相对简单了一些 会造成代码量庞大，耦合性高 有局限性，因为有很多的业务是无法很简单的实现回滚的 本地消息表 消息生产方，需要额外建一个消息表，并记录消息发送状态。消息表和业务数据要在一个事务里提交，也就是说他们要在一个数据库里面。然后消息会经过MQ发送到消息的消费方。如果消息发送失败，会进行重试发送。 消息消费方，需要处理这个消息，并完成自己的业务逻辑。此时如果本地事务处理成功，表明已经处理成功了，如果处理失败，那么就会重试执行。如果是业务上面的失败，可以给生产方发送一个业务补偿消息，通知生产方进行回滚等操作。 消息队列 消息队列 优点 解耦： 将消息写入消息队列，需要消息的系统自己从消息队列中订阅，从而系统A不需要做任何修改 异步： 将消息写入消息队列，非必要的业务逻辑以异步的方式运行，加快相应速度(邮件和验证码) 流量削锋： 系统A慢慢的按照数据库能处理的并发量，从消息队列中慢慢拉取消息。在生产中，这个短暂的高峰期积压是允许的 缓冲 缺点 系统可用性降低 系统复杂性增加：考虑一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等 类型 ActiveMQ：主从 RabbitMQ：主从 RocketMQ：分布式 Kafka：分布式发布-订阅系统 如何保证消息队列是高可用的？ Kafka为例 一个topic分为多个partition，每个partition有多个副本，消息存储在 Broker的某一Topic的某一Partition中，同时存在多个副本 leader选举，选举的partition leader负责读写，其他的副本作为follower从leader同步消息 如何保证消息不被重复消费？ 造成重复消费的原因：因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将消息分发给其他的消费者。 针对业务场景 eg:拿到这个消息做数据库的insert操作，给这个消息做一个唯一的主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。 eg：拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作 如何保证消息的可靠性传输？ 生产者丢数据：RabbitMQ提供transaction和confirm模式来确保生产者不丢消息 发送消息前开启事务，然后发送，出现异常则回滚，成功则提交事务 消息队列丢数据：持久化磁盘 消费者丢数据：手动确认消息(RabbitMQ会自动确认消息然后删除) 如何保证消息的消费顺序？ 通过算法将需要保持先后顺序的消息放到同一个消息队列中，然后只用一个消费者去消费该队列 保证入队有序就行，出队以后的顺序交给消费者自己去保证 SQL注入 通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令 框架MyBatis MyBatis 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架。 MyBatis 避免了几乎所有的 JDBC 代码和手工设置参数以及抽取结果集。使用简单的 XML 或注解来配置和映射基本体，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。 优点 简单易学：没有任何第三方依赖，最简单安装只要两个jar文件+配置几个sql映射文件 灵活：不会对应用程序或者数据库的现有设计强加任何影响。 sql写在xml里，便于统一管理和优化。 解除sql与程序代码的耦合，提高了可维护性 提供映射标签，支持对象与数据库的orm字段关系映射 提供对象关系映射标签，支持对象关系组建维护 提供xml标签，支持编写动态sql。 缺点 编写SQL语句时工作量很大，尤其是字段多、关联表多时。 SQL语句依赖于数据库，导致数据库移植性差，不能更换数据库。 框架还是比较简陋，功能尚有缺失，虽然简化了数据绑定代码，但是整个底层数据库查询实际还是要自己写的，工作量也比较大，而且不太容易适应快速数据库修改。 二级缓存机制不佳 原理 应用程序根据XML配置文件创建SqlSessionFactory，SqlSessionFactory在根据配置，配置来源于两个地方，一处是配置文件，一处是Java代码的注解，获取一个SqlSession。SqlSession包含了执行sql所需要的所有方法，可以通过SqlSession实例直接运行映射的sql语句，完成对数据的增删改查和事务提交等，用完之后关闭SqlSession。 hibernate Hibernate是开源的一个ORM（对象关系映射）框架，是对JDBC的进一步封装 核心：面向对象、关系映射以及数据持久化 优点 更加对象化：只需要操作对象就可以 移植性：做了持久层的封装，所写代码都具有可复用性 没有侵入性(轻量级)：Hibernate不需要继承任何类，不需要实现任何接口。这样的对象叫POJO对象。 代码测试方便 提高效率，提高生产力 缺点 使用数据库特性的语句，将很难调优 对大批量数据更新存在问题 系统中存在大量的攻击查询功能 hibernate与mybatis的对比 Hibernate的真正掌握要比Mybatis困难，Hibernate比mybatis更加重量级一些。 Mybatis需要手动编写SQL语句，Hibernate也可以自己写SQL语句来指定需要查询的字段，但这样破坏了Hibernate封装以及简洁性。 mybatis由于所有SQL都是依赖数据库书写，所以扩展性，迁移性比较差 hibernate有更好的二级缓存机制，可以使用第三方缓存，MyBatis本身提供的缓存机制不佳 总结： 对于数据的操作，hibernate是面向对象的，而MyBatis是面向关系的。 Mybatis：小巧、方便、高效、简单、直接、半自动化 Hibernate：强大、方便、高效、复杂、间接、全自动化 JPA Spring Data JPA是Spring Data的子模块。使用Spring Data，使得基于”repositories”概念的JPA实现更简单和容易。 JPA默认使用hibernate作为ORM实现，所以，一般使用Spring Data JPA即会使用hibernate。]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java多线程]]></title>
    <url>%2F2019%2F02%2F28%2Fjava%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[线程创建线程 继Thread类 实现Runnable接口 实现Callable接口(比runnable多一个返回值) Java不支持多继承，但可以实现多个接口。 start()方法会启动一个新线程，并包含run()方法。而run()只会执行run方法，不会启动新线程 线程池 为什么要用线程池？ 降低消耗。降低创建和销毁线程造成的消耗 提高响应速度。任务到达时，任务可以不需要等到线程创建就能立即执行 提高线程的可管理性 参数 corePoolSize：线程池核心线程数量 如果池中线程数量少于核心线程池数量，则直接新建线程处理当前任务 当池中无空闲线程时，新任务将被添加到阻塞队列 核心线程池空闲不会被回收。 maximumPoolSize：线程池最大线程数量 当阻塞队列已满，并且有新任务还在入队时，创建新的线程处理，直到线程数大于maximumPoolSize 超出corePoolSize部分的线程超过空闲时间后会被回收 当线程已经超出maximumPoolSize，并且阻塞队列已满，则通过handler所指定的策略来处理任务。 keepAliveTime：线程存活时间 当线程超出corePoolSize时生效 workQueue：阻塞队列（存储等待执行的任务） threadFactory：线程工厂，用来创建线程 相关类 ThreadPoolExecutor ScheduledThreadPoolExecutor ThreadLocal 用于线程间的数据隔离 使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本 Wait/Notify/NotifyAll wait( )，notify( )，notifyAll( )都不属于Thread类，而是属于Object基础类 why？ wait():线程执行wait()时，会把当前的锁释放，然后让出CPU，进入等待状态。 notify():随机唤醒一个正在等待该锁的对象 notifyAll():唤醒所有等待该锁的对象，但这些对象会竞争，只有一个获得该锁 其他的对象不会返回等待状态，除非再次调用wait()方法 会一直等到当前拥有锁的对象释放锁，然后再次竞争 锁的类型乐观锁/悲观锁 乐观锁：认为对于同一个数据的并发操作，是不会发生修改的 更新数据的时候，会采用尝试更新，不断重试的方式更新数据 CAS算法，典型例子为原子类 适合读操作非常多的场景 悲观锁：认为对于同一个数据的并发操作，一定是会发生修改的 采取加锁的形式 适合写操作非常多的场景 CAS(CompareAndSwap)算法 CAS指令执行时，当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做。整个比较并替换的操作是一个原子操作。 优点： 比加锁效率更高：因为对Atomic 变量进行操作时没有阻塞线程，而使用同步代码块时会阻塞线程，并且会造成程序的复杂性增高 缺点： 循环时间长开销大 只能保证一个共享变量的原子操作 ABA问题 如果内存地址V初次读取的值是A，并且在准备赋值的时候检查到它的值仍然为A；但是在这个过程中它的值曾经被改成了B，后来又被改回为A，那CAS操作就会误认为它从来没有被改变过。 解决方式： 带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的版本来保证CAS的正确性。 公平锁/非公平锁 公平锁：多个线程在等待同一个锁时，必须按照申请锁的先后顺序来一次获得锁 非公平锁 可能导致饿死 可重入锁/不可重入锁 可重入锁：同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。 eg: synchronized void setA() throws Exception{ Thread.sleep(1000); setB(); } synchronized void setB() throws Exception{ Thread.sleep(1000); } 不可重入锁：对于上面的例子可能造成死锁 分段锁 是一种设计,目的是细化锁的粒度 jdk7中ConcurrentHashMap就是通过分段锁来实现高效的并发操作 自旋锁 指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁 优点：减少线程上下文切换的消耗 缺点 循环会消耗CPU。 饥饿问题 如何实现自旋锁? public class SpinLock { private AtomicReference&lt;Thread&gt; cas = new AtomicReference&lt;Thread&gt;(); public void lock() { Thread current = Thread.currentThread(); // 利用CAS while (!cas.compareAndSet(null, current)) { // DO nothing } } public void unlock() { Thread current = Thread.currentThread(); cas.compareAndSet(current, null); } } 锁优化 减少锁持有的时间：对一个方法加锁，不如对方法中需要同步的几行代码加锁 减小锁粒度：ConcurrentHashMap采取对segment加锁而不是整个map加锁，提高并发性 锁分离：分为读锁和写锁 锁粗化：在一个间隔性地需要执行同步语句的线程中，如果在不连续的同步块间频繁加锁解锁是很耗性能的，因此把加锁范围扩大，把这些不连续的同步语句进行一次性加锁解锁。虽然线程持有锁的时间增加了，但是总体来说是优化了的 锁消除 JVM中：偏向锁/轻量级锁/重量级锁/自旋锁/自适应自旋锁 synchronized关键字 非公平锁、可重入锁、互斥锁 使用方式 ACC_SYNCHRONIZED 访问标志区分一个方法是否同步方法 修饰实例方法，对当前实例加锁，进入同步代码之前需要获得当前实例的锁 修饰静态方法，对当前类对象加锁，进入同步代码之前需要获得当前类对象的锁。 修饰代码块，对指定对象加锁，进入同步代码之前需要获得指定对象的锁。 通过monitorenter和monitorexit JVM对synchronized关键字的优化（状态） 偏向锁：指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。 降低获取锁的代价。 轻量级锁：指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁 不会阻塞，提高性能。 重量级锁：当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁 重量级锁会让其他申请的线程进入阻塞，性能降低。 自旋锁 锁消除：即时编译时通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁 与LOCK的区别 对于synchronized,如果多个线程都只是进行读操作，所以当一个线程在进行读操作时，其他线程只能等待无法进行读操作。Lock可以提高多个线程进行读操作的效率 Lock可以知道线程有没有成功获取到锁。synchronized不行 采用synchronized不需要用户去手动释放锁，而Lock则必须要用户去手动释放锁，如果没有主动释放锁，就有可能导致出现死锁现象。 Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现； Lock可以让等待锁的线程响应中断，而synchronized却不行 synchronized是同步阻塞，使用的是悲观并发策略，lock是同步非阻塞，采用的是乐观并发策略 ReenTrantLock 与synchronized一样都可重入，同一线程可以多次获得同一个锁 实现了Lock接口 ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 ReenTrantLock提供了一个Condition（条件）类，用来实现分组唤醒需要唤醒的线程们，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。 volatile作用 JVM提供的最轻量级的同步机制 一个变量使用volatile之后，具备两种特性： 保证此变量对所有线程的可见性：使用volatile关键字会强制将修改的值立即写入主存 符合以下两条规则才能保证原子性： 对变量的写操作不依赖于当前值 该变量没有包含在具有其他变量的不变式中。 禁止指令重排序优化 eg: //1 volatile boolean shutdownRequested; public void shutdown() { shutdownRequested = true; } public void doWork() { while (!shutdownRequested) { //do stuff } } //2 public class ChessyCounter{ @GuardedBy(&quot;this&quot;) private volatile int value; //读操作，没有synchronized，提高性能 public int getValue(){ return value } //写操作，必须synchronized。因为x++不是原子操作 public synchronized int increment() { return value++; } } //锁一次只允许一个线程访问值，volatile 允许多个线程执行读操作 //使用锁进行所有变化的操作，使用 volatile 进行只读操作。 与synchronized区别 synchronized关键字解决的是执行控制的问题，volatile关键字解决的是内存可见性的问题 volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别 volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性 volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。 BIO/NIO/AIO基础概念 同步和异步：是针对应用程序和内核的交互而言的 同步：用户进程触发IO操作并等待或者轮询的去查看IO操作是否就绪 异步：用户进程触发IO操作以后便开始做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知 阻塞和非阻塞：是针对于进程在访问数据的时候 阻塞方式：读取或者写入函数将一直等待 非阻塞方式：读取或者写入函数会立即返回一个状态值 三者区别 BIO:：同步阻塞 服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销 可以通过线程池机制改善 用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行 Java自己处理IO读写，Java调用会一直阻塞到读写完成才返回 适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中 NIO：同步非阻塞 服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理 用户进程发起一个IO操作以后边可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费 Java自己处理IO读写，但是不能读写时Java调用会马上返回，当IO事件分发器会通知可读写时再继续进行读写，不断循环直到读写完成 适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器 AIO：异步非阻塞 服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理 用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了 Java将IO读写委托给OS处理，需要将数据缓冲区地址和大小传给OS 适用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统]]></title>
    <url>%2F2019%2F02%2F27%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[进程/线程1. 进程线程区别与联系 区别： 进程是资源分配的最小单位；线程是CPU调度的最小单位 进程切换消耗资源更大 线程的划分尺度小于进程，导致多线程并发性更高 线程拥有自己独立的栈和栈指针等信息 多线程程序的并发性高 联系： 一个程序至少有一个进程，一个进程至少有一个线程 进程在执行过程中拥有独立的内存单元，而多个线程共享所在进程的内存 进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。 2. 进程间通信方式 管道：半双工，是数据只能单向流动 无名管道：只能在具有亲缘关系的进程间使用，一般指父子 有名管道：允许无亲缘关系进程间的通信。 缓冲区有限 四次数据拷贝 用户空间buf拷贝到内核中 内核将数据拷贝到内存中 内存到内核 内核到用户空间的buf 只能承载无格式字节流 信号量 消息队列 可以实现任意进程间的通信，通过系统调用函数 来实现消息发送和接收之间的同步，无需考虑同步问题，方便 信息的复制需要额外消耗CPU的时间，不适宜于信息量大或操作频繁的场合 四次数据拷贝 共享内存：同一块物理内存被映射到进程A、B各自的进程地址空间 两次数据拷贝，一次从输入文件到共享内存区，另一次从共享内存区到输出文件 共享内存时保持共享区域直到通信完毕，共享内容在解除映射时才写回文件 效率高，读写内存 共享内存段被映射进进程空间之后，存在于进程空间的数据段 套接字：可用于不同机器间的进程通信，用socket实现 3. 线程间通信方式 锁 信号量semaphore：同一时刻访问此资源的最大线程数量 信号signal：通过通知操作的方式来保持多线程同步 4. 进程的几种状态 就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源 运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数 阻塞状态： 进程等待某种条件，在条件满足之前无法执行 就绪→执行；执行→就绪；执行→阻塞；阻塞→就绪 5. 进程调度策略 FCFS先来先服务：没有考虑优先级 短作业优先：不利于长作业 高响应比优先：响应比计算系统开销，增加系统开销 时间片轮转 多级反馈队列 6. 进程同步机制 信号量 管程 内存1. 段页区别 段是信息的逻辑单位，它是根据用户的需要划分的，因此段对用户是可见的 页是信息的物理单位，是为了管理主存的方便而划分的，对用户是透明的。 段的大小不固定，有它所完成的功能决定 页的大小固定，由系统决定. 段向用户提供二维地址空间，在标识一个地址时，即需给出段名，又需给出段内地址 页向用户提供的是一维地址空间 段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制 页式虚拟存储系统存在内部碎片；段式虚拟存储系统，存在外部碎片]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络]]></title>
    <url>%2F2019%2F02%2F23%2F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[HTTP(无状态的协议)/HTTPS1. 两者区别？ HTTP是不安全的，HTTPS是安全的 OSI模型中，HTTP在应用层，HTTPS的安全传输机制在传输层 HTTP无法加密，HTTPS对传输的数据进行加密 HTTP不用证书，而HTTPS需要CA机构颁发的SSL证书 HTTPS就是HTTP加上加密处理（一般是SSL安全通信线路）+认证+消息完整性保护 2. HTTPS工作原理 双向认证 SSL 协议的具体通讯过程，服务器和用户双方必须都有证书 客户端发起HTTPS请求，服务器返回自己的证书、对称加密算法种类等信息 客户端判断服务器的CA证书是否由信任的CA中心签发，是则验证证书中的信息，不是则询问是否继续访问 客户端发送客户端证书，服务器进行相同的身份认证 服务器选择一种加密方案，使用客户端公钥加密后通知客户端 客户端通过私钥解密后得知服务器选择的加密方案，选择一个通话秘钥key，用服务器公钥加密后发给服务器 服务器收到后用私钥解密，获得通话秘钥key 接下来的数据传输都用该对称秘钥key进行加密 通过非对称秘钥机制保证双方身份认证，完成建立连接，在实际数据通信中通过对称秘钥机制保障数据安全性 双向认证 有两个或两个以上的证书，一个是服务端证书，另一个或多个是客户端证书。 一般用于企业应用对接 单向认证 客户端保存着服务端的证书并信任该证书即可 https一般是单向认证，这样可以让绝大部分人都可以访问你的站点。 3. GET与POST方法的区别？ GET重点在从服务器获取资源，POST重点在向服务器发送数据 get传输数据是通过URL请求，以field（字段）= value的形式，置于URL后，并用”?”连接，多个请求数据间用”&amp;”连接，如http://127.0.0.1/Test/login.action?name=admin&amp;password=admin 这个过程用户是可见的；post传输数据通过Http的post机制，将字段与对应值封存在请求实体中发送给服务器，这个过程对用户是不可见的； POST比GET更安全 GET产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而POST产生两个，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。 4. forward和redirect的区别 转发forward： 是服务器请求资源,服务器直接访问目标地址的URL,把那个URL的响应内容读取过来,然后把这些内容再发给浏览器 浏览器不知道服务器发送的内容从哪里来,因为这个跳转过程在服务器实现，所以客户端并不知道这个跳转动作，它的地址栏还是原来的地址 重定向： 服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址.所以地址栏显示的是新的URL 转发是服务器行为，重定向是客户端行为。 5. HTTP常见状态码 1xx:表示服务器已接收了客户端请求，客户端可继续发送请求 100：继续，允许客户端继续发送 101：转换协议 2xx:成功状态码 200：OK 202：接受，请求还未处理完 3xx:要完成请求，需要进一步操作。 通常，这些状态代码用来重定向 300：多重选择，表示被请求的文件可以在多个地方得到 4xx：用户指定客户端的错误 400：错误请求，语法错误 401：未授权 403：禁止，表示除非拥有授权，否则服务器拒绝提供所请求的资源 404：无法找到资源 5xx:用户指定服务器错误 500：服务器内部错误 502：错误的网关 504：网关超时 RESTful架构 特点 用URL描述资源 使用HTTP方法描述行为。使用HTTP状态码来表示不同的结果 使用json交互数据 是一种风格 面向资源 WebSocket 只需要服务器和浏览器通过HTTP协议进行一个握手的动作，然后单独建立一条TCP的通信通道进行数据的传送 长连接 WebSocket API是 HTML5 标准的一部分 原理 浏览器、服务器建立TCP连接，三次握手。这是通信的基础，传输控制层，若失败后续都不执行。 TCP连接成功后，浏览器通过HTTP协议向服务器传送WebSocket支持的版本号等信息。（开始前的HTTP握手） 服务器收到客户端的握手请求后，同样采用HTTP协议 回馈数据。 当收到了连接成功的消息后，通过TCP通道进行传输通信 与Http的联系 相同点： 都基于TCP，都是可靠性传输协议 都是应用层协议 不同点： WebSocket是双向通信协议(全双工) ，模拟Socket协议，可以双向发送或接受信息。HTTP是单向的。 WebSocket是需要握手进行建立连接的 WebSocket在建立握手时，数据是通过HTTP传输的。但是建立之后，在真正传输时候是不需要HTTP协议的。 与socket的联系 socket 是位于应用层和传输控制层之间(会话层)的一组接口，是为了方便使用TCP或UDP而抽象出来的一层 门面模式，把复杂的TCP/IP协议族隐藏在Socket接口后面 当两台主机通信时，必须通过Socket连接 Socket是传输控制层协议，WebSocket是应用层协议 TCP / UDP（传输层）1. TCP三次握手过程 主机A发送SYN包(同步序列号)到服务器 (SYN_SENT)，等待B确认 B收到后确认A的SYN (SYN_RCVD)，同时自己也发送一个SYN+ACK包 (ESTABLISHED) A收到SYN+ACK包后，向B发送ACK包 (ESTABLISHED)。完成三次握手，开始传输数据 三次握手特点：没有应用层的数据 三次握手漏洞： SYN FLOOD攻击：DDoS攻击，数据报特征是大量syn包，并且缺少最后一步的ACK回复。 解决办法： 无效连接监控：半开连接数和不活动连接数到达一定值时候，就释放系统资源 延缓TCB方法 Syn Cookie：用一种特殊的算法生成sequence number，算法考虑到对方的信息和己方信息，收到对方的ACK报文后，验证之后才决定是否生成TCB 2. TCP关闭：四次握手 A将FIN控制位置为1 (FIN_WAIT_1)，提出停止TCP的请求 (CLOSE_WAIT) B收到后对其作出响应，将ACK置为1 B将FIN置为1 (FIN_WAIT_2)，提出反方向的关闭请求 (LAST_ACK) A对B的请求进行确认 (TIME_WAIT)，将ACK置为1 (CLOSED) TIME_WAIT 状态是在服务端发送FIN，客户回复ACK后,为什么需要2MSL时间(报文最大生存时间)？ 为了保证最后一个ACK因丢失，而等待重发的时间 保证残留网络报不会被新连接接收而产生数据错乱。保证所有残留的网络报在自己关闭前都已经超时 3. TCP头部 16位 源端口 16位 目标端口 32位 序列号 32位 确认号 4位 头部长度：指示何处数据开始 16位 窗口大小 16位 校验和 16位 紧急指针 4. TCP如何保证可靠性传输 将数据截成合理长度 超时重发 推迟验证(对于收到的请求会给出确认响应，响应前会进行完整校验) 如果收到的检验和有差错，TCP将丢弃这个报文，并且不确认收到此报文段。然后发送数据端会超时重发 对失序数据进行重排序 丢弃重复数据 流量控制 TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据。 5.TCP粘包问题 粘包问题：发送方发送的若干包数据到接收方接收时粘成一包，从缓冲区来看，后一包的头紧接着前一包数据的尾 可能发生的场景：需要在连接后一段时间内发送不同结构数据 出现原因 发送端需要等缓冲区满才发送出去，造成粘包 接收方不及时接收缓冲区的包，造成多个包接收 不是所有的粘包现象都需要处理，若传输的数据为不带结构的连续流数据（如文件传输），则不必把粘连的包分开（简称分包）。 解决措施： 对于发送方引起的粘包：编程设置，使用TCP强制数据立即传送的指令（但是关闭了优化算法） 对于接收方引起的粘包：优化程序设计，提高接收进程优先级等（但是无法完全避免粘包现象） 由接收方控制，将一包数据按结构字段，人为控制分多次接收然后合并（效率极低） nagle算法 为了尽可能发送大块数据,避免网络中充斥着许多小数据块。 将多次间隔较小、数据量小的数据，合并成一个大的数据块，然后进行封包 6. TCP流量控制/拥塞控制 流量控制：滑动窗口 让发送方的发送速率不要太快，要让接收方来得及接收 拥塞控制：防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载 拥塞：对资源的需求超过了可用资源，造成网络性能降低 慢开始：由小到大逐渐增大拥塞窗口数值(发送方的发送窗口=拥塞窗口) 拥塞避免算法：比慢开始算法的拥塞窗口增长速率缓慢 一旦出现拥塞，将窗口大小立即置为1，执行慢开始算法 快重传和快恢复 接收方每收到一个失序的报文段后就立即发出重复确认 发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必等重传计时器到期 当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限减半，把拥塞窗口设置为慢开始门限减半后的数值，并执行拥塞避免算法 7. TCP和UDP区别 面向连接与无连接 对系统资源的要求(TCP较多，UDP少) 面向字节流和面向报文 TCP提供流量控制/拥塞控制，UDP无拥塞控制 TCP仅支持一对一 TCP保证数据正确性，UDP可能丢包，TCP保证数据顺序，UDP不保证 UDP适应于对实时要求较高、不允许有较大时延的情况，如航空信息应用。 TCP/IP的四个层次 网络接口层： 最底层，负责接收IP数据报并通过网络发送之，或者从网络上接收物理帧，抽出IP数据报，交给IP层。 网络层： 负责相邻计算机之间的通信 处理来自传输层的分组发送请求，收到请求后，将分组装入IP数据报，填充报头，选择去往信宿机的路径，然后将数据报发往适当的网络接口 处理输入数据报：首先检查其合法性，然后进行寻径——假如该数据报已到达信宿机，则去掉报头，将剩下部分交给适当的传输协议；假如该数据报尚未到达信宿，则转发该数据报 处理路径、流控、拥塞问题 传输层： 提供应用程序间的通信 格式化信息流 提供可靠传输：必须确认，丢失重发 应用层： 向用户提供一组常用的应用程序，比如电子邮件、文件传输访问、远程登录 eg: 应用层将一串应用数据流传送给传输层 传输层将应用层的数据流截成分组，并加上TCP报头形成TCP段，送交网络层 网络层给TCP段加上包括源、目的主机IP地址的IP报头，生成一个IP数据包，并将IP数据包送交给链路层 链路层在其MAC帧的数据部分装上IP数据包，再加上源、目的主机的MAC地址和帧头，并根据其目的MAC地址，将MAC帧发往目的主机或IP路由器 在目的主机，链路层将MAC帧的帧头去掉，并将IP数据包送交给网络层 网络层检查IP报头，如果报头中校验和与计算结果不一致，则丢弃该IP数据包；若校验和与计算结果一致，则去掉IP报头，将TCP段送交传输层 传输层检查顺序号，判断是否是正确的TCP分组，然后检查TCP报头数据。如正确，则向源主机发确认信息；若不正确或丢包，则向源主机要求重发信息 在目的主机，传输层去掉TCP报头，将排好顺序的分组组成应用数据流送给应用程序 RPC框架 像调用本地的函数一样去调远程函数，基于TCP SOA 面向服务的架构 DNS1. 从输入URL到页面加载发生了什么？ DNS解析： 浏览器缓存 → 操作系统缓存 → 本地hosts文件 → 本地DNS服务器 → 递归搜索UDP协议( . -&gt; .com -&gt; google.com. -&gt; www.google.com.。) TCP连接 发送http请求，服务器返回一个重定向地址 浏览器跟踪重定向地址 服务器处理http请求并返回http报文 浏览器解析、渲染页面 Session / Cookie Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中 服务器在创建了Session的同时，会为该Session生成唯一的Session id，而这个Session id在随后的请求中会被用来重新获得已经创建的Session；在Session被创建之后，就可以调用Session相关的方法往Session中增加内容了，而这些内容只会保存在服务器中，发到客户端的只有Session id；当客户端再次发送请求的时候，会将这个Session id带上，服务器接受到请求之后就会依据Session id找到相应的Session，从而再次使用之。正式这样一个过程，用户的状态也就得以保持了。 Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式 第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在 Cookie 里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器 常见应用场景：自动登录 安全性较低，以明文形式存放在浏览器中 cookie增多会增加网络带宽，session增多会占用服务器性能 cookie被禁用？ URL重写 每次HTTP交互，URL后面都会被附加上一个诸如 sid=xxxxx 这样的参数]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM整理]]></title>
    <url>%2F2019%2F01%2F19%2FJVM%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[JVM运行内存的分类 程序计数器 线程私有 当前线程所执行的字节码的行号指示器，用于记录正在执行的虚拟机字节指令地址 如果正在执行的是native方法，则为空 虚拟机栈 线程私有 每个方法被执行的时候都会同时创建一个栈帧用于存放局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程 生命周期与线程相同 为java方法服务 native方法栈 与java虚拟机栈相似 区别：为native方法服务 java堆 线程共享 JVM所管理的内存中最大的一块，在虚拟机启动时创建 唯一目的：存放对象实例、数组 GC回收的主要区域 方法区 线程共享 存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据 回收目标：主要是常量池的回收和类型的卸载 Java四大引用 强引用 如果一个对象具有强引用，那垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题 例子：Object obj = new Object(); 这里obj 就是引用，new Object() 对象实例存储在堆内存，obj引用的是对象实例的内存地址。 软引用 可以和一个引用队列（ReferenceQueue) 联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中 用来描述可用但不是必须存活的对象；在内存溢出之前，虚拟机尝试对这些对象进行回收。如果回收之后内存还是不够才会出现内存溢出情况。 弱引用 与软引用的区别：只具有弱引用的对象拥有更短暂的生命周期 被弱引用关联的对象只能生存到下一次垃圾回收发生之前。 只要垃圾回收机制在工作，无论内存是否足够，都会回收掉这部分对象。 虚引用 虚引用在任何时候都可能被垃圾回收器回收。一个对象是否被虚引用关联，完全不对其生存周期构成影响。 主要用来跟踪对象被垃圾回收器回收的活动，被回收时会收到一个系统通知。 必须 和引用队列 （ReferenceQueue）联合使用。 当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。 不能通过一个虚引用获取到一个对象实例 GC回收机制Java中对象是采用new或者反射的方法创建的，这些对象的创建都是在堆（Heap）中分配的，所有对象的回收都是由Java虚拟机通过垃圾回收机制完成的。 GC为了能够正确释放对象，会监控每个对象的运行状况，对他们的申请、引用、被引用、赋值等状况进行监控。 程序员不用担心内存管理，GC会自动进行管理。 GC标记对象的方法 引用计数法 给对象添加一个引用计数器,没当被引用的时候,计数器的值就加一。引用失效的时候减一,当计数器的值为 0 的时候就表示该对象可以被 GC 回收了， 弊端： A-&gt;B,B-&gt;A,那么 AB 将永远不会被回收了。也就是引用有环的情况 根搜索算法(可达性算法) GC Roots Tracing 通过一个叫 GC Roots 的对象作为起点,从这些结点开始向下搜索,搜索所走过的路径称为引用链,当一个对象没有与任何的引用链相连的时候则该对象就可以被回收。 根搜索算法中不可达的对象并非“非死不可”,真正宣告一个对象死亡需要两次标记过程。 第一次标记：判断是否有必要执行finalize方法 第二次标记：第一次标记过且有必要执行finalize()方法的对象，此时是对象唯一逃出去（不被回收）的机会，通过与任意对象建立关联即可，这时对象将会被移出“将被回收”的队列 GC回收的Roots包括： java虚拟机栈中引用的对象 eg: 方法里面定义这种局部变量 User user= new User(); native方法栈中引用的对象 方法区中常量引用的对象 eg: private static final User user = new User(); 方法区中静态属性引用的对象 eg: private static User user = new User(); finalize方法 gc只能清除在堆上分配的内存，而不能清除栈上分配的内存，对这类对象回收需要使用finalize方法 finalize()方法只会被调用一次，GC在回收对象之前调用该方法。 finalize方法中，可将待回收对象赋值给GC Roots可达的对象引用，从而达到对象再生的目的 finalize()是由JVM自动调用的，你可以用System.gc()，但JVM不一定会立刻执行，每个虚拟机会根据自己的策略执行。JVM感觉内存空间有限时，才会开始执行finalize() 回收算法 标记-清除 缺点：产生内存碎片 复制算法 按照容量划分二个大小相等的内存区域，当一块用完的时候将活着的对象复制到另一块上，然后再把已使用的内存空间一次清理掉 缺点：内存缩小为原来的一半 标记-整理 标记出没有用的对象，让所有存活的对象都向一端移动，然后直接清除掉端边界以外的内存 优点：解决了清除算法的内存碎片问题和复制算法的效率低下问题 分代收集算法 根据对象存活周期的不同将内存划分为几块，一般是新生代和老年代。 新生代采用复制算法，老年代采用标记-整理算法 Minor GC &amp; Full GC Minor GC通常发生在新生代的Eden区，在这个区的对象生存期短，往往发生GC的频率较高，回收速度比较快，一般采用复制回收算法 Full GC/Major GC 发生在老年代，一般情况下，触发老年代GC的时候不会触发Minor GC，所采用的是标记-清除算法/标记-整理算法 内存分配与回收策略 结构（堆大小 = 新生代 + 老年代） 新生代(1/3)(初始对象，生命周期短)：Eden 区、survivior from、survivior to（8 : 1 : 1） 老年代(2/3)(长时间存在的对象) 一般小型的对象都会在 Eden 区上分配，如果Eden区无法分配，则触发一次Minor GC,把Eden和survivor from区活着的对象放到survivor to中，然后把from和to交换位置，保证to的区域一直为空 如果survivor to不可以放入，那么直接把它们放入到老年代中，并清除Eden和survivor from，这个过程也称为分配担保（Full GC） 大对象、长期存活的对象则直接进入老年代 动态对象年龄判定 GC垃圾收集器 Serial New收集器：单线程，针对新生代的收集器，采用的是复制算法 Parallel New（并行）收集器：多线程，新生代采用复制算法，老年代采用标记整理 Parallel Scavenge（并行）收集器：多线程，针对新生代，采用复制算法 Serial Old（串行）收集器：单线程，新生代采用复制，老年代采用标记整理 Parallel Old（并行）收集器：多线程，针对老年代，标记整理 CMS收集器：基于标记-清除 G1收集器(JDK)：整体上是基于标记整理，局部采用复制 综上：新生代基本采用复制算法，老年代采用标记整理算法。cms采用标记清理 如何减少GC次数？ 对象尽量不要显式设置为null：有利于 GC 收集器判定垃圾,从而提高了 GC 的效率 少用system.gc 少用静态变量：静态变量是全局变量，不会被GC回收，但一直占用内存 尽量使用 StringBuffer,而不用 String 来累加字符串：StringBuffer是可变长的,它在原有基础上进行扩增,不会产生中间对象 使用软引用类型 SafePoint 当线程运行到这些位置时它的状态是确定的,比如记录OopMap的状态，从而确定GC Root的信息 这个点, 所有GC Root的状态都是已知并且heap里的对象是一致的; 在这个点进行GC时, 所有的线程都需要block住, 这就是(STW)Stop The World 假如一个java线程分配了一个对象A, 该对象的地址存在某个寄存器中, 然后线程的cpu时间片到期被切换出去, 同时GC的线程开始扫描存活对象, 由于没有路径到这个地址还在寄存器中的对象, 这个对象被认为是garbage, 回收了. 然后睡眠的java线程醒来了, 把寄存器中的对象地址赋值给了存活对象的某个字段, over… 所以safepoint下, heap是静止的, 并且所有活着的对象都可以被找到 如何达到safepoint？ Hotspot采用主动检测的方式使得其他线程停下来 解释执行： 指定点执行检测代码，java方法返回和跳转指令(if或者循环里面)的地方会进行检测. 编译执行： polling page访问异常触发：在需要safepoint时, 会修改该页面的权限为不可访问, 这样编译的代码在访问这个页面时, 会触发段违规异常(SEGEV). 而hotspot在启动时捕获了这个异常, 当意识到是访问polling page导致时, 则主动挂起. Oopmap 在HotSpot中，对象的类型信息里有记录自己的OopMap，记录了在该类型的对象内什么偏移量上是什么类型的数据。 在safepoint会记录Oopmap 平时这些OopMap都是压缩了存在内存里的；在GC的时候才按需解压出来使用 Java类加载机制 虚拟机把描述类的数据文件（字节码）加载到内存，并对数据进行验证、准备、解析以及类初始化，最终形成可以被虚拟机直接使用的java类型 类的生命周期 加载过程 通过一个类的全限定名来获取其定义的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在Java堆中生成一个代表这个类的java.lang.Class对象，作为对方法区中这些数据的访问入口。 验证过程 确保Class文件的字节流中包含的信息符合当前虚拟机的要求 准备过程 正式为类属性分配内存并设置类属性初始值的阶段，这些内存都将在方法区中进行分配 解析阶段 虚拟机将常量池内的符号引用替换为直接引用的过程 初始化阶段 类初始化阶段是类加载过程的最后一步。初始化阶段就是执行类构造器方法的过程 使用阶段 卸载阶段 Java类加载器 负责加载所有的类，同一个类(一个类用其全限定类名(包名加类名)标志)只会被加载一次 Bootstrap ClassLoader: 启动类加载器，负责加载java的核心类，它不是java.lang.ClassLoader的子类，而是由JVM自身实现 Extension ClassLoader: 扩展类加载器，扩展类加载器的加载路径是JDK目录下jre/lib/ext,实际上扩展类加载器的父类加载器是根加载器，只是根加载器并不是Java实现的 System ClassLoader:系统(应用)类加载器： 它负责在JVM启动时加载来自java命令的-classpath选项、java.class.path系统属性或CLASSPATH环境变量所指定的jar包和类路径。 双亲委派模型 工作原理 如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行。如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器。 如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载。 除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器 优点 Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以 避免类的重复加载 考虑到安全因素，java核心api中定义类型不会被随意替换 eg:假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class JAVA内存模型(JMM) 主要目标 定义程序中各个变量的访问规则 保证了有序性 线程对变量的所有操作（读取、 赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量 先行发生原则happens-before 如果说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、 发送了消息、 调用了方法等。]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构和排序算法]]></title>
    <url>%2F2019%2F01%2F12%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[基本排序算法 稳定性 排序前后两个相等的数相对位置不变，则算法稳定。 插入排序 直接插入排序 折半插入排序（二分法插入） 希尔排序：不稳定 直接插入排序稳定，算法复杂度：O(n²) 1234567891011public void insertionSort(int[] a) &#123; for (int i = 1; i &lt; a.length; i++) &#123; int temp = a[i]; int j = i - 1; while (j &gt;= 0 &amp;&amp; a[j] &gt; temp) &#123; a[j + 1] = a[j]; j--; &#125; a[j + 1] = temp; &#125;&#125; 折半插入排序（此处描述的是二分法查找算法）稳定，查找算法复杂度：O(logN)；排序算法复杂度：O(NlogN) 要求：1.存储在数组中（链表中不适合） 2.有序排列 在算法中属于分治算法 123456789101112131415161718192021222324252627282930313233343536373839404142434445 //递归实现 public int binarySearchRecursion(int[] array, int low, int high, int target) &#123; if (low &gt; high) return -1; int mid = (low + high) / 2; if (target &lt; array[mid]) return binarySearchRecursion(array, low, mid - 1, target); if (target &gt; array[mid]) return binarySearchRecursion(array, mid + 1, high, target); return array[mid];&#125;//非递归实现public int binarySearch(int[] array, int low, int high, int target) &#123; while (low &lt;= high) &#123; int mid = (low + high) / 2; if (target &lt; array[mid]) high = mid - 1; else if (target &gt; array[mid]) low = mid + 1; else return mid; &#125; return -1;&#125;//二分法插入public void binaryInsert(int[] array,int target)&#123; int low =0; int high = array.length-1; int[] res = new int[array.length+1]; while (low&lt;=high)&#123; int mid = (low+high)/2; if (array[mid]&lt; target) low = mid+1; else high = mid-1; &#125; for (int i=0;i&lt;low;i++) res[i]=array[i]; res[low] = target; for (int i=low+1;i&lt;res.length;i++) res[i]=array[low++]; &#125; 交换排序 冒泡排序 快速排序(不稳定) 冒泡排序稳定，算法复杂度：O(n²)；最好情况下O(n) 123456789101112public void bubbleSort(int[] a) &#123; for (int i = 0; i &lt; a.length; i++) &#123; for (int j = 1; j &lt; a.length - i; j++) &#123; if (a[j] &lt; a[j - 1]) &#123; int temp = a[j]; a[j] = a[j - 1]; a[j - 1] = temp; &#125; &#125; &#125;&#125;//算法还可以改进，从两头向中间逼近，可以加快速度 快速排序不稳定，算法复杂度：O(NlogN) 在所有同数量级的排序方法中，平均性能最好 12345678//递归实现public void quickSortRecursion(int[] arr, int low, int high) &#123; if (low &lt; high) &#123; int pivot = partition(arr, low, high); quickSortRecursion(arr, low, pivot - 1); quickSortRecursion(arr, pivot + 1, high); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334private int partition(int[] arr, int low, int high) &#123; int pivot = arr[low]; while (low &lt; high) &#123; while (low &lt; high &amp;&amp; arr[high] &gt; pivot) high--; arr[low] = arr[high]; while (low &lt; high &amp;&amp; arr[low] &lt; pivot) low++; arr[high] = arr[low]; &#125; arr[low] = pivot; return low;&#125;//非递归实现public void quickSort(int[] arr, int low, int high) &#123; Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); if (low &lt; high) &#123; stack.push(high); stack.push(low); while (!stack.empty()) &#123; int l = stack.pop(); int r = stack.pop(); int pivot = partition(arr, l, r); if (l &lt; pivot - 1) &#123; stack.push(pivot - 1); stack.push(l); &#125; if (r &gt; pivot + 1) &#123; stack.push(r); stack.push(pivot + 1); &#125; &#125; &#125;&#125; 选择排序 直接选择排序：不稳定 直接选择最小(最大)的记录与第一个记录交换位置，再对余下的n-1个进行同样操作 算法复杂度：O(n²) 存在重复做比较的情况 锦标赛排序（树形）：稳定 N个关键码两两比较，得到 n/2 个比较的优胜者(关键码小者)保留下来, 再对这 n/2个对象再进行关键码的两两比较, ……直至选出一个最小的关键码为止。 算法复杂度：O(NlogN) 堆排序：不稳定 算法复杂度：O(NlogN) 堆排序1234567891011121314151617181920212223242526272829303132333435363738394041//堆排序public void heapsort(int[] arr) &#123; for (int i = arr.length / 2; i &gt;= 0; i--) adjustHeap(arr, i, arr.length); for (int i = arr.length - 1; i &gt; 0; i--) &#123; swap(arr, 0, i); adjustHeap(arr, 0, i); &#125;&#125;/** 构建最大堆的过程 * @param arr 数组 * @param i 需要构建堆的根节点的序号 * @param n 数组长度 **/public void adjustHeap(int[] arr, int i, int n) &#123; int father; int child; for (father = arr[i]; leftChild(i) &lt; n; i = child) &#123; child = leftChild(i); // 如果左子树小于右子树，则需要比较右子树和父节点 if (child != n - 1 &amp;&amp; arr[child] &lt; arr[child + 1]) child++;//序号+1，指向右子树 // 如果父节点小于孩子结点，则需要交换 if (father &lt; arr[child]) &#123; arr[i] = arr[child]; &#125; else break;//是最大堆，无需破坏 &#125; arr[i] = father;&#125;private int leftChild(int i) &#123; return 2 * i + 1;&#125;private void swap(int[] arr, int index1, int index2) &#123; int tmp = arr[index1]; arr[index1] = arr[index2]; arr[index2] = tmp;&#125; 归并排序稳定，算法复杂度：O(NlogN) 在算法中属于分治算法 123456789//递归public void MergeSort(int[] arr, int left, int right) &#123; int mid = (left + right) / 2; if (left &lt; right)&#123; MergeSort(arr, left, mid); MergeSort(arr, mid + 1, right); merge(arr, left, mid, right); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344//merge函数实际上是将两个有序数组合并成一个有序数组//因为数组有序，合并很简单，只要维护几个指针就可以了private void merge(int[] arr, int left, int mid, int right) &#123; //temp数组用于暂存合并的结果 int[] temp = new int[right - left + 1]; //左半边的指针 int head1 = left; //右半边的指针 int head2 = mid+1; //合并后数组的指针 int index = 0; //将记录由小到大地放进temp数组 for(; head1 &lt;= mid &amp;&amp; head2 &lt;= right; index++) &#123; if(arr[head1] &lt; arr[head2]) temp[index] = arr[head1++]; else temp[index] = arr[head2++]; &#125; //接下来两个while循环是为了将剩余的（比另一边多出来的个数）放到temp数组中 while(head1 &lt;= mid) temp[index++] = arr[head1++]; while(head2 &lt;= right) temp[index++] = arr[head2++]; //将temp数组中的元素写入到待排数组中 for(int i = 0; i &lt; temp.length; i++) arr[left + i] = temp[i];&#125;//非递归private void MergeSort(int[] arr) &#123; int len = arr.length; int step = 1; //每一个区间的长度，1,2,4,8... while (step &lt;= len) &#123; int offset = 2 * step; for (int i = 0; i &lt; len; i += offset) merge(arr, i, Math.min(i + step - 1, len - 1), Math.min(i + offset - 1, len - 1)); step = offset; &#125;&#125; 基数排序 桶排序：稳定 算法复杂度：O(n+radix) 空间复杂度：O(n+2radix) 解决Hash冲突 线性探测 二次探测 双散列 d = hash1(k) = k % len(tableSize) c = hash2(k) = R - (k % R) ;R为&lt;tableSize的质数 d+c,d+2c,d+3c….. 再散列 当表项数 &gt; 表的70% 时,可再散列. 即, 取比(2*原表长=14)大的质数17再散列 数据结构红黑树 在平衡二叉搜索树的基础上增加了着色相关的性质，这些性质保证了红黑树始终是logN的高度，从而保证了红黑树的查找、插入、删除的时间复杂度最坏为O(logN) 性质 每个结点要么是红的要么是黑的 根节点是黑的 每个叶结点(叶结点即指树尾端NIL指针或NULL结点NIL指针)都是黑的 如果一个结点是红的，那么它的两个儿子都是黑的 对于任意结点而言，其到叶结点NIL指针的每条路径都包含相同数目的黑结点 多用在内部排序，即全放在内存中的 TreeMap 就是采用红黑树存储的 MapHashMap 使用数组+链表方式实现 无序 put方法 根据当前 key 的 hashcode 定位到具体的桶中，然后再计算index 如果没有冲突就直接存 如果有冲突，以链表的形式存在后面 如果冲突导致链表过长，就把链表转为红黑树 如果节点已经存在就替换old value(保证key的唯一性) 如果桶满了，就要resize() get方法 如果是桶中的第一个节点，则直接返回value 如果有冲突，则通过key.equals(k)去查找对应的entry 若为树，O(logN) 若为链表，O(n) 1.7与1.8的区别 1.7 1.8 存储结构 数组+链表 数组+链表+红黑树 扩容后存储位置的计算方式 按照原方法(hashCode–&gt;扰动处理) 扩容后的位置=原位置or原位置+扩容量 转移数据方式 头插法(将原位置的数据后移1位再插入：逆序&amp;环形链表死循环问题) 尾插法 插入数据时机&amp;位置重计算时机 扩容前插入、转移数据时统一计算 扩容后插入、单独计算(即转移数据时无统一计算) LinkedHashMap 保存了记录的插入顺序 HashSet 基于HashMap实现 同样无法保证顺序 HashMap与Hashtable的区别 HashMap允许将null作为一个entry的key或者value，而Hashtable不允许 HashMap不是线程安全的，而Hashtable是线程安全的 HashTable 的方法是 Synchronize 的，而 HashMap 不是，在多个线程访问 Hashtable 时，不需要自己为它的方法实现同步，而 HashMap 就必须为之提供外同步 ConcurrentHashMap jdk7中ConcurrentHashMap就是通过分段锁来实现高效的并发操作 ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。 需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道放在哪个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入 统计size的时候，即获取hashmap全局信息的时候，需要获取所有的分段锁才能统计 jdk8中改为CAS+synchronized操作，底层使用数组+链表+红黑树 并不是直接改为红黑树，而是将treeNode封装到treeBin对象中 核心方法 initTable():在插入元素时发生，只能由一个线程完成 sizeCtl:CAS算法进行判断 扩容transfer(): step1:单线程进行，构建一个nextTable，容量为原来的两倍。 step2:允许多线程，将原来的table中的数据复制到nextTable中 Hashtable与ConcurrentHashMap的区别 Hashtable的synchronized是针对整张Hash表的，即每次锁住整张表让线程独占，ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了分段锁技术]]></content>
      <categories>
        <category>算法</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法整理]]></title>
    <url>%2F2018%2F12%2F24%2F%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[常用算法(一) 穷举法(二) 贪婪算法在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的是在某种意义上的局部最优解。 贪婪算法不能保证全局最优，所以使用贪心算法的前提是，局部最优策略能导致全局最优解。同时贪心算法必须满足无后效性，即某个状态以后的状态不会影响以前的状态。 适用情况局部最优策略能导致全局最优解 基本思路 建立数学模型来描述问题 把求解的问题分成若干个子问题 对每一子问题求解，得到子问题的局部最优解 把局部最优解合成原来问题的一个解 经典问题 霍夫曼编码 最小生成树 0/1背包问题 (三) 动态规划 动态规划过程是：每次决策依赖于当前状态，又随即引起状态的转移。一个决策序列就是在变化的状态中产生出来的。 与分治法最大的差别是：适合于用动态规划法求解的问题，经分解后得到的子问题往往不是互相独立的（即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解）。 适用情况 最优化原理：问题的最优解所包含的子问题的解也是最优的 无后效性：某阶段状态一旦确定，就不受这个状态以后决策的影响 有重叠子问题：子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到。 基本思路初始状态→│决策１│→│决策２│→…→│决策ｎ│→结束状态 划分：划分后的阶段一定要是有序的或者是可排序的 确定状态和状态变量：要满足无后效性 确定决策并写出状态转移方程：状态转移就是根据上一阶段的状态和决策来导出本阶段的状态 寻找边界条件 经典问题 N级台阶问题 最长递增子序列 (四) 分治算法把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题……直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。 适用情况 问题的复杂性随问题的规模递增 最优子结构性质 利用该问题分解出的子问题的解可以合并为该问题的解 如果不满足第三条，可以用贪心算法Or动态规划算法 子问题之间相互独立 基本思路分解-解决-合并 ###经典问题 快速排序 归并排序 二分查找 (五) 回溯法回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。 **深度优先搜索策略** 基本思路 确定问题的解空间 确定节点的扩展搜索规则 以深度优先方式搜索解空间，并在搜索过程中用剪枝函数避免无效搜索 (六) 分支界限算法回溯法的求解目标是找出T中满足约束条件的所有解，而分支限界法的求解目标则是找出满足约束条件的一个解，或是在满足约束条件的解中找出使某一目标函数值达到极大或极小的解，即在某种意义下的最优解。 **广度优先搜索策略** 分支搜索算法 FIFO搜索 LIFO搜索 优先队列式搜索]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务框架]]></title>
    <url>%2F2018%2F12%2F20%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[微服务框架Dubbohttps://github.com/Snailclimb/JavaGuide/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/dubbo.md 分布式服务框架，RPC调用 SOA Dubbo中，先通过路由，从多个 Provider 中按照路由规则，选出一个子集。再根据负载均衡从子集中选出一个 Provider 进行本次调用。如果调用失败了，根据集群容错策略，进行重试或定时重发或快速失败等。 为什么使用dubbo？ 远程接口是基于Java Interface，并且依托于spring框架方便开发。可以方便的打包成单一文件，独立进程运行，和现在的微服务概念一致。 可以为我们解决服务之间互相是如何调用的 负载均衡 服务访问压力以及时长统计、资源调度和治理：实时管理集群容量，提高集群利用率 服务降级：某个服务挂掉之后调用备用服务 负载均衡策略 随机：默认策略，按权重设置随机概率 轮询(不推荐)：按公约后的权重设置轮循比率 存在慢的提供者累积请求的问题 最少活跃调用数，相同活跃数的随机。活跃数指调用前后计数差。使慢的 Provider 收到更少请求，因为越慢的 Provider 的调用前后计数差会越大。 一致性哈希：相同参数的请求总是落在同一台机器上 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动 容错策略Dubbo 定义了集群接口 Cluster 以及及 Cluster Invoker。集群 Cluster 用途是将多个服务提供者合并为一个 Cluster Invoker，并将这个 Invoker 暴露给服务消费者。这样一来，服务消费者只需通过这个 Invoker 进行远程调用即可，至于具体调用哪个服务提供者，以及调用失败后如何处理等问题，现在都交给集群模块去处理 Failover Cluster：默认机制，失败自动切换，当出现失败，重试其它服务器。 通常用于读操作，但重试会带来更长延迟 Failfast Cluster：快速失败，只发起一次调用，失败立即报错。 通常用于非幂等性的操作，如新增记录 Failsafe Cluster：失败安全，出现异常时，直接忽略。 通常用于写入审计日志等操作 Failback Cluster：失败自动恢复，后台记录失败请求，定时重发 通常用于消息通知操作 Forking Cluster：并行调用多个服务器，只要一个成功即返回。 通常用于实时性要求较高的读操作，但需要浪费更多服务资源 Broadcast Cluster ：广播调用所有提供者，逐个调用，任意一台报错则报错。(2.1.0开始支持) 通常用于通知所有提供者更新缓存或日志等本地资源信息 dubbo健壮性的体现 zookeeper注册中心宕掉，一段时间内服务消费方还是能够调用提供方的服务的，实际上它使用的本地缓存进行通讯 监控中心宕掉不影响使用，只是丢失部分采样数据 数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务 注册中心对等集群，任意一台宕掉后，将自动切换到另一台 注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯 服务提供者无状态，任意一台宕掉后，不影响使用 服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复 服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。所以，我们可以完全可以绕过注册中心——采用 dubbo 直连 ，即在服务消费方配置服务提供方的位置信息。 zookeeperhttps://github.com/Snailclimb/JavaGuide/blob/master/%E4%B8%BB%E6%B5%81%E6%A1%86%E6%9E%B6/ZooKeeper.md 高可用的分布式管理与协调框架，只要半数以上节点存活，ZooKeeper 就能正常服务 树型(Znode)的目录服务的数据存储,数据存储在内存中 高性能：在读多于写的应用程序中尤其地高性能，因为写会导致所有的服务器间同步状态 应用场景 配置管理 集群管理：leader选举，集群容错 发布与订阅 数据库切换 分布式日志的收集 Spring Cloud学习资料汇总：http://www.ityouknow.com/springcloud/2016/12/30/springcloud-collect.html 基础组件 路由网关 Zuul：动态路由、过滤、监控、弹性伸缩和安全 服务注册和发现Eureka：提供服务注册和发现功能 Spring Cloud Consul：是一个服务发现与配置工具，与Docker容器可以无缝集成。支持健康检查，并允许HTTP和DNS协议调用API存储键值对。 网络请求RestTemplate：访问RESTful API接口的网络请求框架 负载均衡Ribbon：Ribbon作为服务消费者的负载均衡器，一种是和 RestTemplate结合，一种是和 Feign 相结合，Feign 默认集成了 Ribbon 。 声明式调用Feign：调用 Spring Cloud 服务的工具，让 Java Http 客户端调用过程变的简单。 配置中心config：将配置文件进行统一管理，可以从 Config Server 服务或 Git 仓库读取 熔断器hystrix：提供了熔断器的功能，能够阻止分布式系统中出现联动故障。 服务链路追踪Sleuth：主要功能是在分布式系统中提供服务链路追踪的解决方案。 服务监控Spring boot Admin：管理和监控一个或多个 Spring Boot 程序，使用 Spring Boot Admin 监控 Spring Cloud 微服务。 消费总线Bus：Spring Cloud Bus 将 Spring 的事件处理机制和消息中间件消息的发送和接收整合起来，可以轻松的将分布式应用中连接有消息中间件的多个服务节点连接起来，实现消息互通。 系统保护：为保证服务的安全，微服务系统需要增加安全验证，常用的方式是增加 Spring Security 或Spring OAuth2 框架来保护微服务系统。 Eureka Eureka的自我保护模式Eureka Server在运行期间，会统计心跳失败的比例在15分钟之内是否 低于85%，如果出现低于的情况（实际在 生产环境上通常是由于网络不稳定导致），Eureka Server会将当前的实例注册信息保护起来，同时提 示警告。保护模式主要用于一组客户端和Eureka Server之间存在网络分 区场景下的保护。一旦进入保护模式，Eureka Server将会尝试保护其服务注册表中的信息，不再删除服务注册表中的数据（也就是不会注销任何微服务）。所以Eureka的哲学是，同时保留”好数据“与”坏数据“总比丢掉任何”好数据“要更好，所以这种模式在实践中非常有效。 与Consul/Zookeeper比较 Eureka consul zookeeper 服务健康检查 可配支持 服务状态、内存、硬盘等 (弱)长连接，keepAlive 多数据中心 — 支持 — 一致性 — raft paxos kv存储服务 — 支持 支持 CAP AP CA CP 使用接口 http（sidecar） http和DNS 客户端 自身监控 metrics metrics — 安全 acl/https — acl raft：强依赖 Leader 节点的可用性来确保集群数据的一致性。 为什么不使用Zookeeper？ ZooKeeper是分布式协调服务，它的职责是保证数据（注：配置数据，状态数据）在其管辖下的所有服务之间保持同步、一致；（强一致性） 发现服务的核心应该是需要强调服务的高可用 正确的设置与维护ZooKeeper服务就非常的困难 集群中出现了网络分割的故障（交换机故障导致交换机底下的子网间不能互访）ZooKeeper会将它们都从自己管理范围中剔除出去，外界就不能访问到这些节点了，本身这些节点是“健康”的，能提供服务的 Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zookeeper那样使整个注册服务瘫痪。 consul的优势 由于Consul自身提供了服务端，所以我们不需要像之前实现Eureka的时候创建服务注册中心，直接通过下载consul的服务端程序就可以使用。 Consul内置了服务注册与发现框架（一站式）、具有以下性质(参考上面列表)： 分布式一致性协议实现，raft算法比paxos更直接 健康检查 K/V存储 多数据中心方案，内外网的服务采用不同的端口进行监听。 支持https和dns协议接口 Feign Client 声明式、模板化的http客户端 底层使用ribbon实现 支持hystrix和它的fallback Hystrix具备了服务降级、服务熔断、线程隔离、请求缓存、请求合并以及服务监控等强大功能。 Zuul 本身就集成了hystrix和ribbon 容错与回退 Zuul的Hystrix监控的粒度是微服务，而不是某个API Zuul提供了一个ZuulFallbackProvider接口实现回退功能 好处 将细粒度的服务组合起来提供一个粗粒度的服务 所有请求都导入一个统一的入口，那么整个服务只需要暴露一个api 对外屏蔽了服务端的实现细节，也减少了客户端与服务器的网络调用次数 功能 客户端负载：Zuul 注册于 Eureka 并集成了 Ribbon 所以自然也是可以从注册中心获取到服务列表进行客户端负载 动态路由：解放运维 监控与审查 身份认证与安全 压力测试：逐渐增加某一个服务集群的流量，以了解服务性能 服务迁移 负载裁剪：为每一个负载类型分配对应的容量，对超过限定值的请求弃用 静态应答处理 Zuul过滤器 pre：路由前。我们可利用这种过滤器实现身份验证、在集群中选择请求的微服务、记录调试信息等。 routing：路由之时。这种过滤器用于构建发送给微服务的请求，并使用Apache HttpClient或Netfilx Ribbon请求微服务。 post：路由之后。这种过滤器可用来为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。 error：其他阶段发生错误时执行该过滤器 Zuul高可用 Eureka 高可用：部署多个 Zuul 节点，并且都注册于 Eureka(有一个严重的缺点：那就是客户端也得注册到 Eureka 上才能对 Zuul 的调用做到负载，这显然是不现实的。) 基于 Nginx 高可用：在调用 Zuul 之前使用 Nginx 之类的负载均衡工具进行负载，这样 Zuul 既能注册到 Eureka ，客户端也能实现对 Zuul 的负载 API网关比较NGINX vs. ZUUL vs. Spring Cloud Gateway vs. Linkerd https://juejin.im/entry/5ad408de6fb9a028cc61af94 Spring Cloud Config 优点 部署极其简单：同一个上线包，无须改动配置，即可在多个环境中(RD/QA/PRODUCTION) 上线 部署动态化：更改配置，无需重新打包或重启，即可实时生效 统一管理：提供web平台，统一管理 多个环境(RD/QA/PRODUCTION)、多个产品 的所有配置 支持微服务架构 服务端：负责将git svn中存储的配置文件发布成REST接口 客户端：可以从服务端REST接口获取配置，客户端并不能主动感知到配置的变化，从而主动去获取新的配置,由消息总线来通知各个Spring Cloud Config的客户端去服务端更新配置。 Spring Cloud Busspring cloud config手动刷新只能针对单个服务。消息总线可以用来广播式自动刷新。通过RabbitMQ或kafka 加 Git的Webhooks來触发配置的更新 Spring Cloud Bus 事件处理机制和消息中间件消息的发送和接收整合起来，主要由发送端、接收端和事件组成。针对不同的业务需求，可以设置不同的事件，发送端发送事件，接收端接受相应的事件，并进行相应的处理，用于实现微服务之间的通信。本质是利用了MQ的广播机制在分布式的系统中传播消息 。]]></content>
      <categories>
        <category>架构</category>
        <category>面试</category>
      </categories>
  </entry>
</search>
